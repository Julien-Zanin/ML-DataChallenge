{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ebfc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Importation des librairies (section ajoutée pour regrouper tous les imports) ---\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "from datetime import datetime\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configuration de l'affichage\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_context(\"notebook\", font_scale=1.2)\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "\n",
    "# Importation des modules utilitaires\n",
    "from utils.data_registry import DATASETS\n",
    "from utils.benchmarks import get_models, get_unsupervised_models, get_supervised_advanced_models\n",
    "from utils.data_loading import load_datasets\n",
    "from utils.data_preprocessing import normalize_rendements_by_row, create_low_nan_dataset\n",
    "from utils.feature_engineering import add_features, add_financial_features\n",
    "from utils.experiment_runner import run_experiment, display_experiment_result, add_result\n",
    "from utils.data_analysis import (\n",
    "    analyze_distributions,\n",
    "    compare_column_stats,\n",
    "    analyze_normalization,\n",
    "    compare_normalization_impact,\n",
    "    perform_pca_analysis,\n",
    "    analyze_correlations\n",
    ")\n",
    "from utils.feature_selection import (\n",
    "    select_by_correlation,\n",
    "    select_by_f_value,\n",
    "    select_by_mutual_info,\n",
    "    optimize_feature_count,\n",
    "    find_important_features\n",
    ")\n",
    "from utils.model_interpretation import analyze_feature_importance, analyze_with_shap, plot_shap_summary\n",
    "from utils.model_evaluation import optimize_hyperparameters, evaluate_model_performance, plot_confusion_matrix, create_results_summary\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, VotingClassifier\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from sklearn.decomposition import PCA\n",
    "from xgboost import XGBClassifier\n",
    "from IPython.display import display\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create empty results tracker avec les colonnes améliorées\n",
    "results_tracker = pd.DataFrame(columns=[\n",
    "    \"dataset\", \"dataset_description\", \"model\", \"model_description\",\n",
    "    \"features_added\", \"feature_sets\", \"normalize_by_row\", \"accuracy\", \n",
    "    \"precision_weighted\", \"recall_weighted\", \"f1_weighted\",\n",
    "    \"training_time\", \"prediction_time\", \"total_time\", \"notes\"\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "099de837",
   "metadata": {},
   "source": [
    "# Prédiction de la direction des prix sur les marchés financiers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bf5388",
   "metadata": {},
   "source": [
    "## 1. Introduction et présentation du problème"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf0e7952",
   "metadata": {},
   "source": [
    "#\n",
    "### 1.1 Contexte et enjeux\n",
    "\n",
    "Dans le cadre de ce challenge (issu du Collège de France ou du Lab Banque de France), nous disposons de données de marché avec pour objectif de prédire la direction du prix (baisse, stable, hausse) en fin de journée, à partir des rendements du matin.\n",
    " \n",
    "Ce marché américain étant particulièrement liquide, l'enjeu est de pouvoir estimer la tendance entre 14h et 16h pour prendre des décisions d'investissement ou d'arbitrage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9609edc4",
   "metadata": {},
   "source": [
    "\n",
    "### 1.2 Description des données\n",
    "\n",
    "- **Index des données**\n",
    "  - Chaque ligne représente un jour donné et une action donnée (identifiants : `day` et `equity`).\n",
    "  - Les colonnes `r0` à `r52` correspondent aux rendements (en points de base) toutes les 5 minutes entre 9h30 et 14h.\n",
    "\n",
    "- **Variables explicatives**\n",
    "  - Les 53 rendements (`r0, r1, …, r52`), éventuellement d'autres features dérivées.\n",
    "\n",
    "- **Variable cible**\n",
    "  - `reod` {-1, 0, 1} indiquant la tendance de l'actif entre 14h et 16h (baisse, stable ou hausse).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1abdc91",
   "metadata": {},
   "source": [
    "\n",
    "### 1.3 Problématique et défis\n",
    "\n",
    "Notre mission est de prédire la classe de rendement (`reod`) en fin de journée, à partir des données matinales. Les défis principaux sont :\n",
    "\n",
    "- La **taille importante** du dataset (plusieurs centaines de milliers de lignes).\n",
    "- La **présence de valeurs manquantes** (`NaN`).\n",
    "- L'**absence de jours/actions communs** entre le jeu d'entraînement et le jeu de test, ce qui complique l'utilisation directe de `equity` ou `day` en tant que features.\n",
    "- Le **risque de surcoût mémoire** et de temps de calcul avec certains modèles comme les Random Forest.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a56f50f3",
   "metadata": {},
   "source": [
    "# \n",
    "## 2. Exploration des données (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e39e970f",
   "metadata": {},
   "source": [
    "### 2.1 Aperçu des données et analyse des valeurs manquantes\n",
    "\n",
    "Nous commençons par explorer les données d'entraînement pour comprendre leur structure et la distribution des valeurs manquantes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c111b5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des données d'entraînement\n",
    "X = pd.read_csv('input_training.csv')\n",
    "X.sort_values(by=\"ID\", inplace=True)\n",
    "y = pd.read_csv('output/output_training_gmEd6Zt.csv')\n",
    "\n",
    "# Importation des données de test\n",
    "data_test = pd.read_csv('input_test.csv')\n",
    "data_test.sort_values(by=\"ID\", inplace=True)\n",
    "y_test = pd.read_csv(\"output/output_test_random.csv\")\n",
    "\n",
    "# Fusion des données et labels\n",
    "X_train = pd.merge(X, y, on=\"ID\").copy()\n",
    "data_test.sort_values(by=\"ID\", inplace=True)\n",
    "X_test = pd.merge(data_test, y_test, on=\"ID\").copy()\n",
    "\n",
    "# Aperçu des données\n",
    "print(\"\\n--- Aperçu des données d'entraînement ---\")\n",
    "print(f\"Nombre de lignes train: {X_train.shape[0]}, Nombre de colonnes: {X_train.shape[1]}\")\n",
    "print(f\"Nombre de lignes test: {X_test.shape[0]}, Nombre de colonnes: {X_test.shape[1]}\")\n",
    "print(\"\\nPremières lignes:\")\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b1dd7a",
   "metadata": {},
   "source": [
    "### Analyse des valeurs manquantes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b64282",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_rendements = [col for col in X_train.columns if col.startswith(\"r\")]\n",
    "# Analyse du nombre de valeurs manquantes par colonne\n",
    "plt.figure(figsize=(16, 4))\n",
    "\n",
    "missing_values_count = X_train[col_rendements].isna().sum()\n",
    "missing_values_percent = (missing_values_count / len(X_train)) * 100\n",
    "missing_df = pd.DataFrame({\n",
    "    'Nombre de NaN': missing_values_count,\n",
    "    'Pourcentage (%)': missing_values_percent\n",
    "}).sort_values('Nombre de NaN', ascending=False)\n",
    "\n",
    "ax = missing_df['Pourcentage (%)'].plot.bar()\n",
    "plt.title('Pourcentage de valeurs manquantes par colonne de rendement')\n",
    "plt.ylabel('Pourcentage de valeurs manquantes (%)')\n",
    "plt.xlabel('Colonne')\n",
    "plt.xticks(rotation=90)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92a5d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse du nombre de valeurs manquantes par ligne\n",
    "NaN_analysis = pd.DataFrame(index=X_train.index, columns=[\"NaN_count\", \"NaN_percent\"])\n",
    "NaN_analysis[\"NaN_count\"] = X_train[col_rendements].isna().sum(axis=1)\n",
    "nombre_colonnes_rend = len(col_rendements)\n",
    "NaN_analysis[\"NaN_percent\"] = (NaN_analysis[\"NaN_count\"] / nombre_colonnes_rend) * 100\n",
    "\n",
    "# Compter le nombre de lignes avec des NaN\n",
    "nbr_row_na = X_train.isna().any(axis=1).sum()\n",
    "\n",
    "print(f\"Nombre de lignes totales du dataset: {len(X_train)}\")\n",
    "print(f\"Nombre de lignes contenant au moins un NaN: {nbr_row_na}, soit {(nbr_row_na/len(X_train)*100):.2f}%\")\n",
    "print(f\"Nombre de lignes avec plus de 30% de NaN: {len(NaN_analysis[NaN_analysis['NaN_percent']>30])}, soit {len(NaN_analysis[NaN_analysis['NaN_percent']>30])/len(X_train)*100:.2f}%\")\n",
    "print(f\"Nombre de lignes avec plus de 50% de NaN: {len(NaN_analysis[NaN_analysis['NaN_percent']>50])}, soit {len(NaN_analysis[NaN_analysis['NaN_percent']>50])/len(X_train)*100:.2f}%\")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(NaN_analysis[\"NaN_percent\"], bins=50, kde=True)\n",
    "plt.title('Distribution du pourcentage de valeurs manquantes par ligne')\n",
    "plt.xlabel('Pourcentage de valeurs manquantes (%)')\n",
    "plt.ylabel('Nombre de lignes')\n",
    "plt.axvline(x=30, color='r', linestyle='--', label='Seuil de 30%')\n",
    "plt.axvline(x=50, color='g', linestyle='--', label='Seuil de 50%')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4818a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution spatiale des NaN (heatmap)\n",
    "plt.figure(figsize=(20, 10))\n",
    "sample_size = min(1000, len(X_train))  # Limiter à 1000 lignes pour la lisibilité\n",
    "sample_indices = np.random.choice(range(len(X_train)), sample_size, replace=False)\n",
    "sample_data = X_train.iloc[sample_indices][col_rendements].isna()\n",
    "sns.heatmap(sample_data, cbar=False, cmap='viridis')\n",
    "plt.title('Distribution spatiale des valeurs manquantes (échantillon aléatoire)')\n",
    "plt.xlabel('Colonne de rendement')\n",
    "plt.ylabel('Ligne (échantillon)')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb490b08",
   "metadata": {},
   "source": [
    "### 2.2 Distribution des rendements\n",
    "\n",
    "Analysons la distribution des rendements pour identifier d'éventuelles caractéristiques ou anomalies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f0c7b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_rendements.remove(\"reod\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dc23291",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Affichage de la distribution pour quelques rendements représentatifs\n",
    "sample_cols = ['r0', 'r10', 'r25', 'r40', 'r52']\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i, col in enumerate(sample_cols):\n",
    "    plt.subplot(len(sample_cols), 1, i+1)\n",
    "    sns.histplot(X_train[col].dropna(), kde=True, bins=50)\n",
    "    plt.title(f'Distribution de {col}')\n",
    "    plt.xlabel('Rendement (points de base)')\n",
    "    plt.ylabel('Fréquence')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf247e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rendements_stats = X_train[col_rendements].describe().T\n",
    "rendements_stats['missing_percent'] = X_train[col_rendements].isna().mean() * 100\n",
    "rendements_stats = rendements_stats.sort_values('max', ascending=False)\n",
    "rendements_stats.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ef5aa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(rendements_stats.index, rendements_stats['mean'], alpha=0.6)\n",
    "plt.title('Moyenne des rendements par colonne')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Moyenne')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.scatter(rendements_stats.index, rendements_stats['std'], alpha=0.6, color='orange')\n",
    "plt.title('Écart-type des rendements par colonne')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('Écart-type')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edf1e8b5",
   "metadata": {},
   "source": [
    "# \n",
    "### 2.3 Analyse de la variable cible\n",
    "# \n",
    "# Examinons la distribution de notre variable cible `reod` pour vérifier l'équilibre entre les classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b82e921",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution des classes\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "class_counts = X_train['reod'].value_counts().sort_index()\n",
    "ax = sns.barplot(x=class_counts.index, y=class_counts.values)\n",
    "\n",
    "plt.title('Distribution des classes (reod)')\n",
    "plt.xlabel('Classe (-1: Baisse, 0: Stable, 1: Hausse)')\n",
    "plt.ylabel('Nombre d\\'observations')\n",
    "\n",
    "total = len(X_train)\n",
    "for i, v in enumerate(class_counts):\n",
    "    ax.text(i, v + 5000, f'{v} ({v/total*100:.1f}%)', ha='center')\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06dc9001",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyse des rendements par classe pour quelques variables représentatives\n",
    "plt.figure(figsize=(15, 15))\n",
    "\n",
    "for i, col in enumerate(sample_cols):\n",
    "    plt.subplot(len(sample_cols), 1, i+1)\n",
    "    for cls in sorted(X_train['reod'].unique()):\n",
    "        subset = X_train[X_train['reod'] == cls][col].dropna()\n",
    "        sns.kdeplot(subset, label=f'Classe {cls}')\n",
    "    plt.title(f'Distribution de {col} par classe')\n",
    "    plt.xlabel('Rendement (points de base)')\n",
    "    plt.ylabel('Densité')\n",
    "    plt.legend()\n",
    "    \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055ceaff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrélation entre les rendements et la variable cible\n",
    "correlations = X_train[col_rendements + ['reod']].corr()['reod'].drop('reod').sort_values(ascending=False)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.barplot(x=correlations.index, y=correlations.values)\n",
    "plt.title('Corrélation entre les rendements et la variable cible (reod)')\n",
    "plt.xticks(rotation=90)\n",
    "plt.xlabel('Colonne de rendement')\n",
    "plt.ylabel('Coefficient de corrélation')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Top 5 des rendements positivement corrélés avec reod:\")\n",
    "display(correlations.head())\n",
    "\n",
    "print(\"\\nTop 5 des rendements négativement corrélés avec reod:\")\n",
    "display(correlations.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd7b677",
   "metadata": {},
   "source": [
    "## 3. Stratégies d'imputation\n",
    "# \n",
    "# Face au défi des valeurs manquantes, nous testons plusieurs stratégies d'imputation pour compléter les données.\n",
    "# \n",
    "# - 1 :  Forward-fill puis backward-fill (FFBF)\n",
    "# \n",
    "# Cette stratégie propage d'abord les dernières valeurs connues vers l'avant, puis remplit les valeurs restantes en propageant depuis la fin.\n",
    "# \n",
    "# - 2 : Backward-fill puis forward-fill (BFFF)\n",
    "# \n",
    "# Cette stratégie inverse commence par propager depuis la fin, puis remplit les valeurs restantes en propageant depuis le début.\n",
    "# \n",
    "# - 3 : Interpolation linéaire\n",
    "# \n",
    "# Cette méthode crée une ligne droite entre les valeurs connues pour estimer les valeurs manquantes.\n",
    "# \n",
    "# - 4 : Imputation par K plus proches voisins (KNN)\n",
    "# \n",
    "# Cette méthode utilise les K observations les plus similaires pour estimer les valeurs manquantes.\n",
    "# \n",
    "# - 5 : MICE (Multivariate Imputation by Chained Equations)\n",
    "# \n",
    "# Cette méthode avancée utilise des modèles de régression pour estimer les valeurs manquantes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a05ff80d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.1 Chargement des datasets avec différentes stratégies d'imputation\n",
    "print(\"\\n--- Chargement des datasets avec différentes stratégies d'imputation ---\")\n",
    "imputed_datasets = load_datasets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f70a239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.2 Création d'un dataset filtrant les colonnes avec plus de 30% de NaN\n",
    "print(\"\\n--- Création d'un dataset avec moins de 30% de valeurs manquantes ---\")\n",
    "\n",
    "# Charger les données brutes pour appliquer le filtrage\n",
    "X_train_70 = pd.read_csv(r\"processed_data\\X_train_70.csv\")\n",
    "X_test_70 = pd.read_csv(r\"processed_data\\X_test_70.csv\")\n",
    "\n",
    "# Créer un dataset filtré (<30% NaN) avec imputation à zéro\n",
    "X_train_low_nan, X_test_low_nan = create_low_nan_dataset(X_train_70, X_test_70, threshold=0.3)\n",
    "\n",
    "# Enregistrer les datasets pour pouvoir les utiliser avec run_experiment\n",
    "X_train_low_nan.to_csv(\"processed_data/X_train_low_nan.csv\", index=False)\n",
    "X_test_low_nan.to_csv(\"processed_data/X_test_low_nan.csv\", index=False)\n",
    "\n",
    "# Ajouter au registre des datasets\n",
    "from utils.data_registry import add_dataset_with_features\n",
    "add_dataset_with_features(\"low_nan\", \n",
    "                        \"processed_data/X_train_low_nan.csv\", \n",
    "                        \"processed_data/X_test_low_nan.csv\", \n",
    "                        \"Colonnes avec <30% de NaN, imputation à 0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dd7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.3 Analyse des distributions après imputation\n",
    "print(\"\\n--- Analyse des distributions après imputation ---\")\n",
    "analyze_distributions(imputed_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3edad64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.4 Comparaison des statistiques entre les différentes stratégies\n",
    "print(\"\\n--- Comparaison des statistiques entre les stratégies d'imputation ---\")\n",
    "stats_results = compare_column_stats(imputed_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e37b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3.5 Impact des méthodes de normalisation\n",
    "print(\"\\n--- Impact des différentes méthodes de normalisation ---\")\n",
    "normalization_results = analyze_normalization(imputed_datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c64c520a",
   "metadata": {},
   "source": [
    "# \n",
    "## 4. Modèles de référence (benchmarks)\n",
    "# \n",
    "# Nous établissons des modèles de base pour servir de références aux futures améliorations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477c98be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les datasets et modèles disponibles\n",
    "print(\"\\nDatasets disponibles:\")\n",
    "for key, info in DATASETS.items():\n",
    "    print(f\"- {key}: {info['description']}\")\n",
    "\n",
    "print(\"\\nModèles disponibles:\")\n",
    "models = get_models()\n",
    "for key, info in models.items():\n",
    "    if 'description' in info:\n",
    "        print(f\"- {key}: {info['description']}\")\n",
    "    else:\n",
    "        print(f\"- {key}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82145db7",
   "metadata": {},
   "source": [
    "# \n",
    "### 4.1 XGBoost baseline sur différentes stratégies d'imputation\n",
    "# \n",
    "# Nous commençons par évaluer les performances du modèle XGBoost sur les différentes stratégies d'imputation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb81dcca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.1 XGBoost baseline sur données brutes\n",
    "print(\"\\n--- Baseline XGBoost sur données brutes ---\")\n",
    "baseline_result = run_experiment(dataset_key=\"raw\", model_key=\"xgboost_baseline\", add_feat=False)\n",
    "results_tracker = add_result(results_tracker, baseline_result)\n",
    "\n",
    "# Ajouter la colonne normalize_by_row si elle n'existe pas\n",
    "if 'normalize_by_row' not in results_tracker.columns:\n",
    "    results_tracker['normalize_by_row'] = False\n",
    "\n",
    "print(\"\\nRésultats détaillés de l'expérience baseline:\")\n",
    "display_experiment_result(baseline_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f9f5ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.2 Benchmark avec XGBoost sur les différentes stratégies d'imputation\n",
    "print(\"\\n--- Comparaison des stratégies d'imputation avec XGBoost ---\")\n",
    "\n",
    "# Liste des stratégies d'imputation à tester\n",
    "imputation_strategies = [\"raw\", \"ffbf\", \"bfff\", \"interp\", \"knn\", \"mice\", \"low_nan\"]\n",
    "imputation_results = []\n",
    "\n",
    "# 4.2.1 Tester les datasets standards (sans features ni normalisation)\n",
    "for strategy in imputation_strategies:\n",
    "    print(f\"\\nTest de {strategy} sans features ni normalisation...\")\n",
    "    try:\n",
    "        # Sans feature engineering\n",
    "        result_without_features = run_experiment(\n",
    "            dataset_key=strategy, \n",
    "            model_key=\"xgboost_baseline\", \n",
    "            add_feat=False,\n",
    "            normalize_by_row=False\n",
    "        )\n",
    "        results_tracker = add_result(results_tracker, result_without_features)\n",
    "        imputation_results.append(result_without_features)\n",
    "        print(f\"Accuracy: {result_without_features['accuracy']:.4f}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du traitement de {strategy}: {e}\")\n",
    "\n",
    "# 4.2.2 Tester avec normalisation par ligne\n",
    "for strategy in imputation_strategies:\n",
    "    print(f\"\\nTest de {strategy} avec normalisation par ligne...\")\n",
    "    try:\n",
    "        # Avec normalisation par ligne\n",
    "        result_normalized = run_experiment(\n",
    "            dataset_key=strategy, \n",
    "            model_key=\"xgboost_baseline\", \n",
    "            add_feat=False,\n",
    "            normalize_by_row=True\n",
    "        )\n",
    "        results_tracker = add_result(results_tracker, result_normalized)\n",
    "        imputation_results.append(result_normalized)\n",
    "        print(f\"Accuracy: {result_normalized['accuracy']:.4f}\")\n",
    "        \n",
    "        # Calculer l'amélioration due à la normalisation\n",
    "        standard_result = next((r for r in imputation_results \n",
    "                               if r['dataset'] == strategy and not r.get('normalize_by_row', False)), None)\n",
    "        if standard_result:\n",
    "            improvement = result_normalized['accuracy'] - standard_result['accuracy']\n",
    "            print(f\"Amélioration due à la normalisation: {improvement:.4f} ({improvement*100:.2f}%)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors de la normalisation de {strategy}: {e}\")\n",
    "\n",
    "# 4.2.3 Tester les datasets avec features prétraitées\n",
    "for strategy in imputation_strategies:\n",
    "    if strategy == \"low_nan\":\n",
    "        continue  # Pas de version avec features pour low_nan\n",
    "        \n",
    "    print(f\"\\nTest de {strategy} avec features prétraitées...\")\n",
    "    try:\n",
    "        preprocessed_key = f\"{strategy}_with_features\"\n",
    "        \n",
    "        if preprocessed_key in DATASETS:\n",
    "            # Sans normalisation\n",
    "            result_with_features = run_experiment(\n",
    "                dataset_key=preprocessed_key, \n",
    "                model_key=\"xgboost_baseline\", \n",
    "                add_feat=False,\n",
    "                normalize_by_row=False\n",
    "            )\n",
    "            results_tracker = add_result(results_tracker, result_with_features)\n",
    "            imputation_results.append(result_with_features)\n",
    "            print(f\"Accuracy avec features prétraitées: {result_with_features['accuracy']:.4f}\")\n",
    "            \n",
    "            # Avec normalisation par ligne\n",
    "            result_features_normalized = run_experiment(\n",
    "                dataset_key=preprocessed_key, \n",
    "                model_key=\"xgboost_baseline\", \n",
    "                add_feat=False,\n",
    "                normalize_by_row=True\n",
    "            )\n",
    "            results_tracker = add_result(results_tracker, result_features_normalized)\n",
    "            imputation_results.append(result_features_normalized)\n",
    "            print(f\"Accuracy avec features et normalisation: {result_features_normalized['accuracy']:.4f}\")\n",
    "            \n",
    "            # Comparer avec le dataset standard\n",
    "            standard_result = next((r for r in imputation_results \n",
    "                                   if r['dataset'] == strategy and not r.get('normalize_by_row', False)), None)\n",
    "            if standard_result:\n",
    "                improvement_features = result_with_features['accuracy'] - standard_result['accuracy']\n",
    "                print(f\"Amélioration due aux features: {improvement_features:.4f} ({improvement_features*100:.2f}%)\")\n",
    "            \n",
    "            # Comparer normalisation avec/sans features\n",
    "            improvement_norm = result_features_normalized['accuracy'] - result_with_features['accuracy']\n",
    "            print(f\"Amélioration due à la normalisation: {improvement_norm:.4f} ({improvement_norm*100:.2f}%)\")\n",
    "        else:\n",
    "            print(f\"Le dataset prétraité '{preprocessed_key}' n'existe pas dans le registre.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur lors du traitement de {strategy} avec features: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161fe835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.3 Visualisation des résultats des benchmarks\n",
    "print(\"\\n--- Visualisation des résultats des benchmarks ---\")\n",
    "\n",
    "# Créer un DataFrame pour la visualisation\n",
    "summary_df = results_tracker[[\"dataset\", \"dataset_description\", \"model\", \"normalize_by_row\", \n",
    "                             \"features_added\", \"accuracy\", \"f1_weighted\", \"total_time\"]]\n",
    "summary_df = summary_df.sort_values(by=\"accuracy\", ascending=False)\n",
    "\n",
    "# Afficher un tableau des résultats\n",
    "print(\"Top 10 des meilleures configurations:\")\n",
    "display(summary_df.head(10))\n",
    "\n",
    "# Visualiser les résultats par dataset et normalisation\n",
    "plt.figure(figsize=(14, 8))\n",
    "summary_plot_data = summary_df.copy()\n",
    "summary_plot_data[\"dataset_norm\"] = summary_plot_data[\"dataset\"] + \\\n",
    "                                    summary_plot_data[\"normalize_by_row\"].apply(lambda x: \" (normalisé)\" if x else \"\")\n",
    "\n",
    "# Filtrer pour n'inclure que XGBoost\n",
    "xgb_data = summary_plot_data[summary_plot_data[\"model\"] == \"xgboost_baseline\"]\n",
    "\n",
    "# Barplot des résultats\n",
    "sns.barplot(x=\"dataset_norm\", y=\"accuracy\", data=xgb_data)\n",
    "plt.title('Performances de XGBoost sur différentes stratégies d\\'imputation')\n",
    "plt.xlabel('Dataset (stratégie d\\'imputation)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38d9f57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.4 Test avec régression logistique sur les meilleurs datasets\n",
    "print(\"\\n--- Test avec régression logistique sur quelques datasets ---\")\n",
    "\n",
    "# Sélectionner quelques datasets pour la comparaison\n",
    "selected_datasets = [\"ffbf\", \"bfff\", \"interp\"]\n",
    "\n",
    "for dataset_key in selected_datasets:\n",
    "    try:\n",
    "        # Test avec régression logistique\n",
    "        result = run_experiment(\n",
    "            dataset_key=dataset_key,\n",
    "            model_key=\"logistic\",\n",
    "            add_feat=True,\n",
    "            normalize_by_row=False\n",
    "        )\n",
    "        results_tracker = add_result(results_tracker, result)\n",
    "        print(f\"Régression logistique sur {dataset_key}: Accuracy = {result['accuracy']:.4f}\")\n",
    "        \n",
    "        # Comparer avec XGBoost\n",
    "        xgb_result = next((r for r in imputation_results \n",
    "                           if r['dataset'] == dataset_key and not r.get('normalize_by_row', False)), None)\n",
    "        if xgb_result:\n",
    "            diff = result['accuracy'] - xgb_result['accuracy']\n",
    "            print(f\"Différence par rapport à XGBoost: {diff:.4f} ({diff*100:.2f}%)\")\n",
    "    except Exception as e:\n",
    "        print(f\"Erreur avec logistique sur {dataset_key}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9b0317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.5 Résumé des performances des modèles de référence\n",
    "print(\"\\n--- Résumé des performances des modèles de référence ---\")\n",
    "\n",
    "# Créer un DataFrame pour comparer les modèles\n",
    "model_comparison = summary_df[[\"model\", \"dataset\", \"normalize_by_row\", \"accuracy\", \"f1_weighted\"]]\n",
    "model_comparison = model_comparison.sort_values(by=\"accuracy\", ascending=False)\n",
    "\n",
    "# Visualiser la comparaison entre XGBoost et régression logistique\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.barplot(x=\"dataset\", y=\"accuracy\", hue=\"model\", data=model_comparison)\n",
    "plt.title('Comparaison des modèles sur différentes stratégies d\\'imputation')\n",
    "plt.xlabel('Dataset (stratégie d\\'imputation)')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.legend(title=\"Modèle\")\n",
    "plt.grid(axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Meilleur résultat\n",
    "best_result = summary_df.iloc[0]\n",
    "print(f\"\\nMeilleur résultat:\")\n",
    "print(f\"Dataset: {best_result['dataset']} - {best_result['dataset_description']}\")\n",
    "print(f\"Modèle: {best_result['model']}\")\n",
    "print(f\"Normalisation: {best_result['normalize_by_row']}\")\n",
    "print(f\"Features ajoutées: {best_result['features_added']}\")\n",
    "print(f\"Accuracy: {best_result['accuracy']:.4f}\")\n",
    "print(f\"F1 score pondéré: {best_result['f1_weighted']:.4f}\")\n",
    "print(f\"Temps total: {best_result['total_time']:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de7012d",
   "metadata": {},
   "source": [
    "## 5. Analyse approfondie et optimisation des modèles\n",
    "# \n",
    "# Après avoir établi des benchmarks, nous cherchons à améliorer les performances en analysant et optimisant les modèles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d47c6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.1 Sélection des datasets pour analyse approfondie\n",
    "print(\"\\n--- Sélection des meilleurs datasets pour analyse approfondie ---\")\n",
    "\n",
    "# Identifier les 3 meilleurs datasets d'après les résultats précédents\n",
    "xgb_summary = summary_df[summary_df['model'] == 'xgboost_baseline']\n",
    "top_datasets = xgb_summary.head(3)\n",
    "\n",
    "print(\"Top 3 des meilleures configurations:\")\n",
    "display(top_datasets)\n",
    "\n",
    "# Récupérer les informations des meilleurs datasets\n",
    "best_configs = []\n",
    "for _, row in top_datasets.iterrows():\n",
    "    config = {\n",
    "        \"dataset\": row[\"dataset\"],\n",
    "        \"normalize\": row[\"normalize_by_row\"],\n",
    "        \"description\": row[\"dataset_description\"]\n",
    "    }\n",
    "    best_configs.append(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e11b19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.2 Chargement et préparation des données pour l'analyse des features\n",
    "print(\"\\n--- Préparation des données pour l'analyse des features ---\")\n",
    "\n",
    "# Fonction pour charger un dataset spécifique\n",
    "from utils.data_loading import load_dataset_for_analysis\n",
    "\n",
    "# Utiliser le meilleur dataset pour l'analyse\n",
    "best_dataset = best_configs[0][\"dataset\"]\n",
    "best_normalize = best_configs[0][\"normalize\"]\n",
    "\n",
    "# Charger les données\n",
    "X_train, y_train, X_test, y_test = load_dataset_for_analysis(best_dataset, best_normalize)\n",
    "\n",
    "print(f\"Dataset sélectionné: {best_dataset} (normalize={best_normalize})\")\n",
    "print(f\"Dimensions: {X_train.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba7b6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.3 Analyse en composantes principales (PCA)\n",
    "print(\"\\n--- Analyse en composantes principales (PCA) ---\")\n",
    "\n",
    "# Effectuer l'analyse PCA sur le dataset sélectionné\n",
    "pca_results = perform_pca_analysis(dataset_key=best_dataset, sample_size=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b100b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.4 Analyse des corrélations\n",
    "print(\"\\n--- Analyse des corrélations entre features ---\")\n",
    "\n",
    "# Analyser les corrélations\n",
    "correlation_results = analyze_correlations(dataset_key=best_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9268be75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.5 Ajout des features financières\n",
    "print(\"\\n--- Ajout de features financières avancées ---\")\n",
    "\n",
    "# Appliquer les features financières\n",
    "X_train_with_financial = add_financial_features(X_train)\n",
    "X_test_with_financial = add_financial_features(X_test)\n",
    "\n",
    "# Afficher les nouvelles features\n",
    "new_financial_features = [col for col in X_train_with_financial.columns if col not in X_train.columns]\n",
    "print(f\"Features financières ajoutées: {len(new_financial_features)}\")\n",
    "print(\"Top 10 nouvelles features:\", ', '.join(new_financial_features[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c5fd13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.6 Sélection des features - Approche 1: Garder tous les rendements\n",
    "print(\"\\n--- Sélection des features - Approche 1: Conserver tous les rendements ---\")\n",
    "\n",
    "# Identifier les features de rendement\n",
    "rendement_cols = [col for col in X_train.columns if col.startswith('r') and col[1:].isdigit()]\n",
    "derived_cols = [col for col in X_train_with_financial.columns if col not in rendement_cols]\n",
    "\n",
    "print(f\"Nombre de features de rendement: {len(rendement_cols)}\")\n",
    "print(f\"Nombre de features dérivées (y compris financières): {len(derived_cols)}\")\n",
    "\n",
    "# Utiliser l'information mutuelle pour sélectionner les features dérivées\n",
    "X_derived = X_train_with_financial[derived_cols]\n",
    "mi_results_derived = select_by_mutual_info(X_derived, y_train, top_n=20, plot=False)\n",
    "selected_derived_features = mi_results_derived['selected_features'][:15]  # Top 15\n",
    "\n",
    "# Afficher les features dérivées sélectionnées\n",
    "print(f\"\\nTop 15 features dérivées sélectionnées:\")\n",
    "for i, feature in enumerate(selected_derived_features):\n",
    "    print(f\"{i+1}. {feature}\")\n",
    "\n",
    "# Combiner les rendements avec les features dérivées sélectionnées\n",
    "approach1_features = rendement_cols + selected_derived_features\n",
    "print(f\"\\nApproche 1: Total de {len(approach1_features)} features ({len(rendement_cols)} rendements + {len(selected_derived_features)} dérivées)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d46380",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.7 Sélection des features - Approche 2: Sélectionner parmi toutes les features\n",
    "print(\"\\n--- Sélection des features - Approche 2: Sélectionner parmi toutes les features ---\")\n",
    "\n",
    "# Utiliser l'information mutuelle sur toutes les features\n",
    "mi_results_all = select_by_mutual_info(X_train_with_financial, y_train, top_n=30, plot=True)\n",
    "approach2_features = mi_results_all['selected_features'][:30]  # Top 30\n",
    "\n",
    "print(f\"\\nApproche 2: Total de {len(approach2_features)} features sélectionnées\")\n",
    "print(\"Top 15 features:\")\n",
    "for i, feature in enumerate(approach2_features[:15]):\n",
    "    print(f\"{i+1}. {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d70a719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.8 Détermination du nombre optimal de features\n",
    "print(\"\\n--- Détermination du nombre optimal de features ---\")\n",
    "\n",
    "# Définir une factory function pour XGBoost\n",
    "def xgboost_factory():\n",
    "    \"\"\"Renvoie une nouvelle instance de XGBoost\"\"\"\n",
    "    return XGBClassifier(\n",
    "        objective=\"multi:softmax\",\n",
    "        num_class=3,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "# Optimisation pour l'approche 2 (généralement plus performante)\n",
    "feature_ranking = mi_results_all['selected_features']\n",
    "print(\"\\nOptimisation du nombre de features pour l'approche 2...\")\n",
    "\n",
    "# Pour éviter d'exécuter une optimisation coûteuse, on limite le nombre d'essais\n",
    "optimization_result = optimize_feature_count(\n",
    "    X_train_with_financial, y_train,\n",
    "    model_factory=xgboost_factory,\n",
    "    feature_ranking=feature_ranking,\n",
    "    n_features_range=range(5, min(101, len(feature_ranking)), 5)\n",
    ")\n",
    "\n",
    "# Récupérer le nombre optimal de features et les features correspondantes\n",
    "optimal_n_features = optimization_result['optimal_n_features']\n",
    "optimal_features = optimization_result['optimal_features']\n",
    "\n",
    "print(f\"\\nNombre optimal de features: {optimal_n_features}\")\n",
    "print(f\"Top 10 des features optimales:\")\n",
    "for i, feature in enumerate(optimal_features[:10]):\n",
    "    print(f\"{i+1}. {feature}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ea44f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.9 Optimisation des hyperparamètres de XGBoost\n",
    "print(\"\\n--- Optimisation des hyperparamètres de XGBoost ---\")\n",
    "\n",
    "# Définir la grille de paramètres pour XGBoost\n",
    "xgb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.5, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.5, 0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "# Utiliser les features optimales pour l'optimisation des hyperparamètres\n",
    "X_optimal = X_train_with_financial[optimal_features]\n",
    "X_test_optimal = X_test_with_financial[optimal_features]\n",
    "\n",
    "# Optimiser XGBoost\n",
    "optimization_result = optimize_hyperparameters(\n",
    "    xgboost_factory(),\n",
    "    xgb_param_grid,\n",
    "    X_optimal,\n",
    "    y_train,\n",
    "    n_iter=10,  # Réduit pour des raisons de temps\n",
    "    use_random=True\n",
    ")\n",
    "\n",
    "# Récupérer le meilleur modèle et ses paramètres\n",
    "best_params = optimization_result[\"best_params\"]\n",
    "best_score = optimization_result[\"best_score\"]\n",
    "\n",
    "print(f\"Meilleur score de validation croisée: {best_score:.4f}\")\n",
    "print(\"Meilleurs paramètres:\")\n",
    "for param, value in best_params.items():\n",
    "    print(f\"- {param}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89aebb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.10 Évaluation du modèle XGBoost optimisé\n",
    "print(\"\\n--- Évaluation du modèle XGBoost optimisé ---\")\n",
    "\n",
    "# Créer le modèle XGBoost optimisé\n",
    "optimized_model = XGBClassifier(\n",
    "    objective=\"multi:softmax\",\n",
    "    num_class=3,\n",
    "    random_state=42,\n",
    "    **best_params\n",
    ")\n",
    "\n",
    "# Entraîner le modèle\n",
    "start_train_time = time.time()\n",
    "optimized_model.fit(X_optimal, y_train)\n",
    "train_time = time.time() - start_train_time\n",
    "\n",
    "# Faire des prédictions\n",
    "start_pred_time = time.time()\n",
    "y_pred = optimized_model.predict(X_test_optimal)\n",
    "pred_time = time.time() - start_pred_time\n",
    "\n",
    "# Évaluer les performances\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "report = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "print(f\"Accuracy sur l'ensemble de test: {accuracy:.4f}\")\n",
    "print(f\"F1 score pondéré: {report['weighted avg']['f1-score']:.4f}\")\n",
    "print(f\"Temps d'entraînement: {train_time:.2f}s, Prédiction: {pred_time:.2f}s\")\n",
    "\n",
    "# Ajouter au tracker de résultats\n",
    "result = {\n",
    "    \"dataset\": best_dataset,\n",
    "    \"dataset_description\": f\"{best_configs[0]['description']} avec features optimisées\",\n",
    "    \"model\": \"xgboost_optimized\",\n",
    "    \"model_description\": f\"XGBoost optimisé avec {len(optimal_features)} features\",\n",
    "    \"features_added\": True,\n",
    "    \"feature_sets\": [\"Optimisées\"],\n",
    "    \"normalize_by_row\": best_normalize,\n",
    "    \"accuracy\": accuracy,\n",
    "    \"precision_weighted\": report[\"weighted avg\"][\"precision\"],\n",
    "    \"recall_weighted\": report[\"weighted avg\"][\"recall\"],\n",
    "    \"f1_weighted\": report[\"weighted avg\"][\"f1-score\"],\n",
    "    \"training_time\": train_time,\n",
    "    \"prediction_time\": pred_time,\n",
    "    \"total_time\": train_time + pred_time,\n",
    "    \"notes\": f\"Optimisé avec {optimal_n_features} features et hyperparamètres\"\n",
    "}\n",
    "\n",
    "results_tracker = add_result(results_tracker, result)\n",
    "\n",
    "# Matrice de confusion\n",
    "plt.figure(figsize=(8, 6))\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
    "           xticklabels=[-1, 0, 1], yticklabels=[-1, 0, 1])\n",
    "plt.title('Matrice de Confusion - XGBoost Optimisé')\n",
    "plt.xlabel('Prédiction')\n",
    "plt.ylabel('Valeur Réelle')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4e1671a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.11 Analyse SHAP pour interpréter le modèle\n",
    "print(\"\\n--- Analyse SHAP pour l'interprétation du modèle ---\")\n",
    "\n",
    "try:\n",
    "    # Import shap if available\n",
    "    import shap\n",
    "    \n",
    "    # Réduire l'échantillon pour l'analyse SHAP\n",
    "    sample_size = min(500, len(X_optimal))\n",
    "    X_train_sample = X_optimal.sample(sample_size, random_state=42)\n",
    "    \n",
    "    # Analyser le modèle avec SHAP\n",
    "    shap_values, explainer = analyze_with_shap(optimized_model, X_train_sample)\n",
    "    \n",
    "    if shap_values is not None:\n",
    "        # Visualiser le résumé des valeurs SHAP (Bar Plot)\n",
    "        plot_shap_summary(shap_values, X_train_sample, plot_type=\"bar\")\n",
    "        \n",
    "        # Visualiser l'impact détaillé des features (Dot Plot)\n",
    "        plot_shap_summary(shap_values, X_train_sample, plot_type=\"dot\")\n",
    "        \n",
    "        print(\"Analyse SHAP complétée avec succès\")\n",
    "    else:\n",
    "        print(\"Impossible de calculer les valeurs SHAP\")\n",
    "        \n",
    "except ImportError:\n",
    "    print(\"La bibliothèque SHAP n'est pas installée. Utilisez 'pip install shap' pour l'installer.\")\n",
    "except Exception as e:\n",
    "    print(f\"Erreur lors de l'analyse SHAP: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c69c206",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.12 Comparaison avec le modèle de référence\n",
    "print(\"\\n--- Comparaison avec le modèle de référence ---\")\n",
    "\n",
    "# Récupérer les performances du meilleur modèle de référence\n",
    "benchmark_model = next((r for r in results_tracker.to_dict('records') \n",
    "                        if r['dataset'] == best_dataset and \n",
    "                        r['model'] == 'xgboost_baseline' and \n",
    "                        r['normalize_by_row'] == best_normalize), None)\n",
    "\n",
    "if benchmark_model:\n",
    "    benchmark_accuracy = benchmark_model[\"accuracy\"]\n",
    "    improvement = accuracy - benchmark_accuracy\n",
    "    \n",
    "    print(f\"Modèle de référence (XGBoost baseline): Accuracy = {benchmark_accuracy:.4f}\")\n",
    "    print(f\"Modèle optimisé (XGBoost optimisé): Accuracy = {accuracy:.4f}\")\n",
    "    print(f\"Amélioration: {improvement:.4f} ({improvement*100:.2f}%)\")\n",
    "    \n",
    "    # Visualiser la comparaison\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    comparison_data = pd.DataFrame([\n",
    "        {\"Modèle\": \"XGBoost baseline\", \"Accuracy\": benchmark_accuracy},\n",
    "        {\"Modèle\": \"XGBoost optimisé\", \"Accuracy\": accuracy}\n",
    "    ])\n",
    "    sns.barplot(x=\"Modèle\", y=\"Accuracy\", data=comparison_data)\n",
    "    plt.title('Comparaison des performances XGBoost baseline vs optimisé')\n",
    "    plt.ylim(0.4, 0.5)  # Ajuster selon les valeurs réelles\n",
    "    plt.grid(axis='y')\n",
    "    \n",
    "    # Ajouter les valeurs sur les barres\n",
    "    for i, row in comparison_data.iterrows():\n",
    "        plt.text(i, row[\"Accuracy\"] + 0.005, f\"{row['Accuracy']:.4f}\", \n",
    "                ha='center', va='bottom', fontweight='bold')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Impossible de trouver un modèle de référence comparable pour la comparaison.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e8136f",
   "metadata": {},
   "source": [
    "## 6. Modèles non supervisés\n",
    "# \n",
    "# Explorons maintenant des approches non supervisées pour améliorer la classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e1c5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.1 Préparation des données\n",
    "print(\"\\n--- Préparation des données pour les modèles non supervisés ---\")\n",
    "\n",
    "# Utiliser le meilleur dataset et les features optimales identifiées précédemment\n",
    "print(f\"Utilisation du dataset {best_dataset} avec {optimal_n_features} features optimales\")\n",
    "\n",
    "# Normaliser les données pour les méthodes de clustering\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_optimal)\n",
    "X_test_scaled = scaler.transform(X_test_optimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a1032be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.2 Réduction de dimensionnalité avec PCA\n",
    "print(\"\\n--- Réduction de dimensionnalité avec PCA ---\")\n",
    "\n",
    "# Appliquer PCA\n",
    "n_components = min(15, X_scaled.shape[1])\n",
    "pca = PCA(n_components=n_components)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "X_test_pca = pca.transform(X_test_scaled)\n",
    "\n",
    "# Analyser la variance expliquée\n",
    "explained_variance = pca.explained_variance_ratio_\n",
    "cumulative_variance = np.cumsum(explained_variance)\n",
    "\n",
    "# Visualiser la variance expliquée\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.8)\n",
    "plt.title('Variance expliquée par composante')\n",
    "plt.xlabel('Composante principale')\n",
    "plt.ylabel('Ratio de variance expliquée')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, 'o-', markersize=8)\n",
    "plt.axhline(y=0.9, color='r', linestyle='--', label='90% de variance')\n",
    "plt.title('Variance expliquée cumulée')\n",
    "plt.xlabel('Nombre de composantes')\n",
    "plt.ylabel('Ratio de variance expliquée cumulée')\n",
    "plt.grid(True)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Déterminer le nombre optimal de composantes pour expliquer 90% de la variance\n",
    "n_components_90 = np.argmax(cumulative_variance >= 0.9) + 1\n",
    "print(f\"Nombre de composantes pour expliquer 90% de la variance: {n_components_90}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c87f9f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.3 Modèle non supervisé 1: K-Means\n",
    "print(\"\\n--- Modèle non supervisé 1: K-Means ---\")\n",
    "\n",
    "# Déterminer le nombre optimal de clusters avec la méthode du coude\n",
    "inertia_values = []\n",
    "silhouette_scores = []\n",
    "k_range = range(2, 10)\n",
    "\n",
    "for k in k_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
    "    kmeans.fit(X_pca)\n",
    "    inertia_values.append(kmeans.inertia_)\n",
    "    \n",
    "    # Calculer le score silhouette\n",
    "    from sklearn.metrics import silhouette_score\n",
    "    silhouette_scores.append(silhouette_score(X_pca, kmeans.labels_))\n",
    "    \n",
    "# Visualiser la méthode du coude et les scores silhouette\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(k_range, inertia_values, 'o-', markersize=8)\n",
    "plt.title('Méthode du coude pour K-Means')\n",
    "plt.xlabel('Nombre de clusters (k)')\n",
    "plt.ylabel('Inertie')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(k_range, silhouette_scores, 'o-', markersize=8)\n",
    "plt.title('Score silhouette pour K-Means')\n",
    "plt.xlabel('Nombre de clusters (k)')\n",
    "plt.ylabel('Score silhouette')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Choisir le nombre optimal de clusters\n",
    "optimal_k = k_range[np.argmax(silhouette_scores)]\n",
    "print(f\"Nombre optimal de clusters selon le score silhouette: {optimal_k}\")\n",
    "\n",
    "# Entraîner K-Means avec le nombre optimal de clusters\n",
    "kmeans = KMeans(n_clusters=optimal_k, random_state=42, n_init=10)\n",
    "kmeans.fit(X_pca)\n",
    "cluster_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90266aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.4 Visualisation des clusters et relation avec les classes\n",
    "print(\"\\n--- Visualisation des clusters K-Means ---\")\n",
    "\n",
    "# Visualiser les clusters dans l'espace des 2 premières composantes\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "for cluster in range(optimal_k):\n",
    "    plt.scatter(X_pca[cluster_labels == cluster, 0], X_pca[cluster_labels == cluster, 1], \n",
    "                label=f'Cluster {cluster}', alpha=0.7)\n",
    "plt.title('Clustering K-Means dans l\\'espace PCA')\n",
    "plt.xlabel('Première composante principale')\n",
    "plt.ylabel('Deuxième composante principale')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Visualiser les classes réelles dans l'espace PCA\n",
    "plt.subplot(2, 1, 2)\n",
    "for cls in sorted(np.unique(y_train)):\n",
    "    plt.scatter(X_pca[y_train == cls, 0], X_pca[y_train == cls, 1], \n",
    "                label=f'Classe {cls}', alpha=0.7)\n",
    "plt.title('Classes réelles dans l\\'espace PCA')\n",
    "plt.xlabel('Première composante principale')\n",
    "plt.ylabel('Deuxième composante principale')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Analyser la correspondance entre clusters et classes\n",
    "print(\"\\n--- Correspondance entre clusters et classes ---\")\n",
    "\n",
    "# Créer une table de contingence\n",
    "contingency_table = pd.DataFrame(\n",
    "    confusion_matrix(y_train, cluster_labels),\n",
    "    index=[f'Classe {cls}' for cls in sorted(np.unique(y_train))],\n",
    "    columns=[f'Cluster {i}' for i in range(optimal_k)]\n",
    ")\n",
    "\n",
    "print(\"Table de contingence (lignes: classes réelles, colonnes: clusters):\")\n",
    "display(contingency_table)\n",
    "\n",
    "# Visualiser la table de contingence\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(contingency_table, annot=True, fmt='d', cmap='Blues')\n",
    "plt.title('Correspondance entre clusters et classes')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea12da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.5 Utilisation des clusters comme features pour la classification\n",
    "print(\"\\n--- Utilisation des clusters comme features pour la classification ---\")\n",
    "\n",
    "# Ajouter les clusters comme features aux données d'origine\n",
    "X_with_clusters = np.column_stack((X_optimal, cluster_labels))\n",
    "X_test_clusters = np.column_stack((X_test_optimal, kmeans.predict(X_test_pca)))\n",
    "\n",
    "# Créer des noms pour les nouvelles features\n",
    "all_feature_names = list(X_optimal.columns) + ['cluster_assignment']\n",
    "\n",
    "# Entraîner un modèle XGBoost avec les clusters comme features supplémentaires\n",
    "kmeans_xgb = XGBClassifier(objective=\"multi:softmax\", num_class=3, random_state=42, **best_params)\n",
    "start_time = time.time()\n",
    "kmeans_xgb.fit(X_with_clusters, y_train)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "# Évaluation\n",
    "start_time = time.time()\n",
    "y_pred_kmeans = kmeans_xgb.predict(X_test_clusters)\n",
    "pred_time = time.time() - start_time\n",
    "\n",
    "accuracy_kmeans = accuracy_score(y_test, y_pred_kmeans)\n",
    "report_kmeans = classification_report(y_test, y_pred_kmeans, output_dict=True)\n",
    "\n",
    "print(f\"Accuracy avec clusters comme features: {accuracy_kmeans:.4f}\")\n",
    "print(f\"F1 score pondéré: {report_kmeans['weighted avg']['f1-score']:.4f}\")\n",
    "\n",
    "# Ajouter au tracker de résultats\n",
    "result_kmeans = {\n",
    "    \"dataset\": best_dataset,\n",
    "    \"dataset_description\": f\"{best_configs[0]['description']} avec features optimisées + K-Means\",\n",
    "    \"model\": \"xgboost_kmeans\",\n",
    "    \"model_description\": \"XGBoost avec clusters K-Means comme features\",\n",
    "    \"features_added\": True,\n",
    "    \"feature_sets\": [\"Optimisées + K-Means\"],\n",
    "    \"normalize_by_row\": best_normalize,\n",
    "    \"accuracy\": accuracy_kmeans,\n",
    "    \"precision_weighted\": report_kmeans[\"weighted avg\"][\"precision\"],\n",
    "    \"recall_weighted\": report_kmeans[\"weighted avg\"][\"recall\"],\n",
    "    \"f1_weighted\": report_kmeans[\"weighted avg\"][\"f1-score\"],\n",
    "    \"training_time\": train_time,\n",
    "    \"prediction_time\": pred_time,\n",
    "    \"total_time\": train_time + pred_time,\n",
    "    \"notes\": f\"K-Means avec {optimal_k} clusters sur {n_components_90} composantes PCA\"\n",
    "}\n",
    "\n",
    "results_tracker = add_result(results_tracker, result_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe1663",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.6 Modèle non supervisé 2: DBSCAN\n",
    "print(\"\\n--- Modèle non supervisé 2: DBSCAN ---\")\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "# Déterminer le eps optimal avec la méthode du coude pour les k plus proches voisins\n",
    "k = min(15, len(X_pca) - 1)\n",
    "neigh = NearestNeighbors(n_neighbors=k)\n",
    "neigh.fit(X_pca)\n",
    "distances, indices = neigh.kneighbors(X_pca)\n",
    "\n",
    "# Trier les distances au kème voisin\n",
    "sorted_distances = np.sort(distances[:, k-1])\n",
    "\n",
    "# Visualiser la courbe pour déterminer eps\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(len(sorted_distances)), sorted_distances, 'o-', markersize=3)\n",
    "plt.title('Méthode du coude pour déterminer eps dans DBSCAN')\n",
    "plt.xlabel('Points triés par distance')\n",
    "plt.ylabel(f'Distance au {k}ème voisin')\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Choisir eps et min_samples\n",
    "eps = np.percentile(sorted_distances, 90)  # Valeur où il y a un \"coude\"\n",
    "min_samples = 5  # Valeur typique\n",
    "\n",
    "print(f\"Paramètres DBSCAN choisis: eps={eps:.4f}, min_samples={min_samples}\")\n",
    "\n",
    "# Appliquer DBSCAN\n",
    "dbscan = DBSCAN(eps=eps, min_samples=min_samples)\n",
    "dbscan_labels = dbscan.fit_predict(X_pca)\n",
    "\n",
    "# Nombre de clusters trouvés (excluant le bruit)\n",
    "n_clusters_dbscan = len(set(dbscan_labels)) - (1 if -1 in dbscan_labels else 0)\n",
    "n_noise = list(dbscan_labels).count(-1)\n",
    "\n",
    "print(f\"Nombre de clusters trouvés: {n_clusters_dbscan}\")\n",
    "print(f\"Nombre de points de bruit: {n_noise} ({n_noise/len(dbscan_labels)*100:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "563fdf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.7 Visualisation des clusters DBSCAN\n",
    "print(\"\\n--- Visualisation des clusters DBSCAN ---\")\n",
    "\n",
    "# Visualiser les clusters dans l'espace des 2 premières composantes\n",
    "plt.figure(figsize=(10, 8))\n",
    "colors = plt.cm.rainbow(np.linspace(0, 1, n_clusters_dbscan + 1))\n",
    "\n",
    "# Points de bruit en noir\n",
    "plt.scatter(X_pca[dbscan_labels == -1, 0], X_pca[dbscan_labels == -1, 1], \n",
    "            c='black', marker='x', label='Bruit', alpha=0.7)\n",
    "\n",
    "# Clusters\n",
    "for i, color in zip(range(n_clusters_dbscan), colors):\n",
    "    plt.scatter(X_pca[dbscan_labels == i, 0], X_pca[dbscan_labels == i, 1], \n",
    "                c=color.reshape(1, -1), label=f'Cluster {i}', alpha=0.7)\n",
    "\n",
    "plt.title('Clustering DBSCAN dans l\\'espace PCA')\n",
    "plt.xlabel('Première composante principale')\n",
    "plt.ylabel('Deuxième composante principale')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "622bad81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.8 DBSCAN comme feature pour la classification\n",
    "print(\"\\n--- Utilisation de DBSCAN comme feature pour la classification ---\")\n",
    "\n",
    "# Ajouter DBSCAN comme feature\n",
    "X_with_dbscan = np.column_stack((X_optimal, dbscan_labels))\n",
    "\n",
    "# Prédire les clusters pour les données de test\n",
    "# Note: DBSCAN n'a pas de méthode predict()\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "# Entraîner un KNN sur les labels DBSCAN pour \"simuler\" une prédiction\n",
    "knn_for_dbscan = KNeighborsClassifier(n_neighbors=5)\n",
    "# Exclure les points de bruit pour l'entraînement\n",
    "non_noise_idx = (dbscan_labels != -1)\n",
    "if sum(non_noise_idx) > 0:  # S'il y a des points non-bruit\n",
    "    knn_for_dbscan.fit(X_pca[non_noise_idx], dbscan_labels[non_noise_idx])\n",
    "    dbscan_pred = knn_for_dbscan.predict(X_test_pca)\n",
    "else:\n",
    "    # Si tous les points sont considérés comme du bruit, considérer que tout est du bruit\n",
    "    dbscan_pred = np.full(X_test_pca.shape[0], -1)\n",
    "\n",
    "X_test_dbscan = np.column_stack((X_test_optimal, dbscan_pred))\n",
    "\n",
    "# Entraîner un modèle XGBoost avec DBSCAN comme feature\n",
    "dbscan_xgb = XGBClassifier(objective=\"multi:softmax\", num_class=3, random_state=42, **best_params)\n",
    "start_time = time.time()\n",
    "dbscan_xgb.fit(X_with_dbscan, y_train)\n",
    "train_time = time.time() - start_time\n",
    "\n",
    "# Évaluation\n",
    "start_time = time.time()\n",
    "y_pred_dbscan = dbscan_xgb.predict(X_test_dbscan)\n",
    "pred_time = time.time() - start_time\n",
    "\n",
    "accuracy_dbscan = accuracy_score(y_test, y_pred_dbscan)\n",
    "report_dbscan = classification_report(y_test, y_pred_dbscan, output_dict=True)\n",
    "\n",
    "print(f\"Accuracy avec DBSCAN comme feature: {accuracy_dbscan:.4f}\")\n",
    "print(f\"F1 score pondéré: {report_dbscan['weighted avg']['f1-score']:.4f}\")\n",
    "\n",
    "# Ajouter au tracker de résultats\n",
    "result_dbscan = {\n",
    "    \"dataset\": best_dataset,\n",
    "    \"dataset_description\": f\"{best_configs[0]['description']} avec features optimisées + DBSCAN\",\n",
    "    \"model\": \"xgboost_dbscan\",\n",
    "    \"model_description\": \"XGBoost avec clusters DBSCAN comme features\",\n",
    "    \"features_added\": True,\n",
    "    \"feature_sets\": [\"Optimisées + DBSCAN\"],\n",
    "    \"normalize_by_row\": best_normalize,\n",
    "    \"accuracy\": accuracy_dbscan,\n",
    "    \"precision_weighted\": report_dbscan[\"weighted avg\"][\"precision\"],\n",
    "    \"recall_weighted\": report_dbscan[\"weighted avg\"][\"recall\"],\n",
    "    \"f1_weighted\": report_dbscan[\"weighted avg\"][\"f1-score\"],\n",
    "    \"training_time\": train_time,\n",
    "    \"prediction_time\": pred_time,\n",
    "    \"total_time\": train_time + pred_time,\n",
    "    \"notes\": f\"DBSCAN avec eps={eps:.4f}, min_samples={min_samples}, {n_clusters_dbscan} clusters\"\n",
    "}\n",
    "\n",
    "results_tracker = add_result(results_tracker, result_dbscan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cf013bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6.9 Comparaison des modèles non supervisés\n",
    "print(\"\\n--- Comparaison des modèles non supervisés ---\")\n",
    "\n",
    "# Créer un DataFrame pour la comparaison\n",
    "comparison_df = pd.DataFrame([\n",
    "    {\"Modèle\": \"XGBoost optimisé\", \"Accuracy\": accuracy, \"F1 score\": report['weighted avg']['f1-score']},\n",
    "    {\"Modèle\": \"XGBoost + K-Means\", \"Accuracy\": accuracy_kmeans, \"F1 score\": report_kmeans['weighted avg']['f1-score']},\n",
    "    {\"Modèle\": \"XGBoost + DBSCAN\", \"Accuracy\": accuracy_dbscan, \"F1 score\": report_dbscan['weighted avg']['f1-score']}\n",
    "])\n",
    "\n",
    "# Afficher le tableau de comparaison\n",
    "print(\"Comparaison des performances:\")\n",
    "display(comparison_df)\n",
    "\n",
    "# Visualiser la comparaison\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.barplot(x=\"Modèle\", y=\"Accuracy\", data=comparison_df)\n",
    "plt.title('Comparaison des Accuracy')\n",
    "plt.ylim(0.4, 0.5)  # Ajuster selon les valeurs réelles\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.barplot(x=\"Modèle\", y=\"F1 score\", data=comparison_df)\n",
    "plt.title('Comparaison des F1 scores')\n",
    "plt.ylim(0.4, 0.5)  # Ajuster selon les valeurs réelles\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "669bd9be",
   "metadata": {},
   "source": [
    "## 7. Modèles supervisés avancés\n",
    "# \n",
    "# Explorons maintenant des modèles supervisés plus avancés pour améliorer la classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0afdeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.1 Modèle supervisé 1: Random Forest\n",
    "print(\"\\n--- Modèle supervisé 1: Random Forest ---\")\n",
    "\n",
    "# Définir la grille de paramètres pour Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [None, 10, 20, 30],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "# Optimiser les hyperparamètres de Random Forest\n",
    "print(\"\\nOptimisation des hyperparamètres pour Random Forest...\")\n",
    "rf_opt_result = optimize_hyperparameters(\n",
    "    RandomForestClassifier(random_state=42),\n",
    "    rf_param_grid,\n",
    "    X_optimal,\n",
    "    y_train,\n",
    "    n_iter=10,  # Réduit pour des raisons de temps\n",
    "    use_random=True\n",
    ")\n",
    "\n",
    "# Extraire le meilleur modèle et ses paramètres\n",
    "rf_best_params = rf_opt_result[\"best_params\"]\n",
    "rf_best_score = rf_opt_result[\"best_score\"]\n",
    "\n",
    "print(f\"Meilleur score de validation croisée: {rf_best_score:.4f}\")\n",
    "print(\"Meilleurs paramètres pour Random Forest:\")\n",
    "for param, value in rf_best_params.items():\n",
    "    print(f\"- {param}: {value}\")\n",
    "\n",
    "# Créer le modèle optimisé\n",
    "rf_model = RandomForestClassifier(random_state=42, **rf_best_params)\n",
    "\n",
    "# Entraîner le modèle\n",
    "start_time = time.time()\n",
    "rf_model.fit(X_optimal, y_train)\n",
    "rf_train_time = time.time() - start_time\n",
    "\n",
    "# Faire des prédictions\n",
    "start_time = time.time()\n",
    "rf_pred = rf_model.predict(X_test_optimal)\n",
    "rf_pred_time = time.time() - start_time\n",
    "\n",
    "# Évaluer les performances\n",
    "rf_accuracy = accuracy_score(y_test, rf_pred)\n",
    "rf_report = classification_report(y_test, rf_pred, output_dict=True)\n",
    "\n",
    "print(f\"\\nPerformances du modèle Random Forest:\")\n",
    "print(f\"Accuracy: {rf_accuracy:.4f}\")\n",
    "print(f\"F1 score pondéré: {rf_report['weighted avg']['f1-score']:.4f}\")\n",
    "print(f\"Temps d'entraînement: {rf_train_time:.2f}s, Prédiction: {rf_pred_time:.2f}s\")\n",
    "\n",
    "# Ajouter au tracker de résultats\n",
    "result_rf = {\n",
    "    \"dataset\": best_dataset,\n",
    "    \"dataset_description\": f\"{best_configs[0]['description']} avec features optimisées\",\n",
    "    \"model\": \"random_forest_optimized\",\n",
    "    \"model_description\": \"Random Forest optimisé\",\n",
    "    \"features_added\": True,\n",
    "    \"feature_sets\": [\"Optimisées\"],\n",
    "    \"normalize_by_row\": best_normalize,\n",
    "    \"accuracy\": rf_accuracy,\n",
    "    \"precision_weighted\": rf_report[\"weighted avg\"][\"precision\"],\n",
    "    \"recall_weighted\": rf_report[\"weighted avg\"][\"recall\"],\n",
    "    \"f1_weighted\": rf_report[\"weighted avg\"][\"f1-score\"],\n",
    "    \"training_time\": rf_train_time,\n",
    "    \"prediction_time\": rf_pred_time,\n",
    "    \"total_time\": rf_train_time + rf_pred_time,\n",
    "    \"notes\": f\"Random Forest optimisé avec {optimal_n_features} features\"\n",
    "}\n",
    "\n",
    "results_tracker = add_result(results_tracker, result_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b42b297",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.2 Modèle supervisé 2: Gradient Boosting\n",
    "print(\"\\n--- Modèle supervisé 2: Gradient Boosting ---\")\n",
    "\n",
    "# Définir la grille de paramètres pour Gradient Boosting\n",
    "gb_param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'subsample': [0.8, 0.9, 1.0]\n",
    "}\n",
    "\n",
    "# Optimiser les hyperparamètres de Gradient Boosting\n",
    "print(\"\\nOptimisation des hyperparamètres pour Gradient Boosting...\")\n",
    "gb_opt_result = optimize_hyperparameters(\n",
    "    GradientBoostingClassifier(random_state=42),\n",
    "    gb_param_grid,\n",
    "    X_optimal,\n",
    "    y_train,\n",
    "    n_iter=10,  # Réduit pour des raisons de temps\n",
    "    use_random=True\n",
    ")\n",
    "\n",
    "# Extraire le meilleur modèle et ses paramètres\n",
    "gb_best_params = gb_opt_result[\"best_params\"]\n",
    "gb_best_score = gb_opt_result[\"best_score\"]\n",
    "\n",
    "print(f\"Meilleur score de validation croisée: {gb_best_score:.4f}\")\n",
    "print(\"Meilleurs paramètres pour Gradient Boosting:\")\n",
    "for param, value in gb_best_params.items():\n",
    "    print(f\"- {param}: {value}\")\n",
    "\n",
    "# Créer le modèle optimisé\n",
    "gb_model = GradientBoostingClassifier(random_state=42, **gb_best_params)\n",
    "\n",
    "# Entraîner le modèle\n",
    "start_time = time.time()\n",
    "gb_model.fit(X_optimal, y_train)\n",
    "gb_train_time = time.time() - start_time\n",
    "\n",
    "# Faire des prédictions\n",
    "start_time = time.time()\n",
    "gb_pred = gb_model.predict(X_test_optimal)\n",
    "gb_pred_time = time.time() - start_time\n",
    "\n",
    "# Évaluer les performances\n",
    "gb_accuracy = accuracy_score(y_test, gb_pred)\n",
    "gb_report = classification_report(y_test, gb_pred, output_dict=True)\n",
    "\n",
    "print(f\"\\nPerformances du modèle Gradient Boosting:\")\n",
    "print(f\"Accuracy: {gb_accuracy:.4f}\")\n",
    "print(f\"F1 score pondéré: {gb_report['weighted avg']['f1-score']:.4f}\")\n",
    "print(f\"Temps d'entraînement: {gb_train_time:.2f}s, Prédiction: {gb_pred_time:.2f}s\")\n",
    "\n",
    "# Ajouter au tracker de résultats\n",
    "result_gb = {\n",
    "    \"dataset\": best_dataset,\n",
    "    \"dataset_description\": f\"{best_configs[0]['description']} avec features optimisées\",\n",
    "    \"model\": \"gradient_boosting_optimized\",\n",
    "    \"model_description\": \"Gradient Boosting optimisé\",\n",
    "    \"features_added\": True,\n",
    "    \"feature_sets\": [\"Optimisées\"],\n",
    "    \"normalize_by_row\": best_normalize,\n",
    "    \"accuracy\": gb_accuracy,\n",
    "    \"precision_weighted\": gb_report[\"weighted avg\"][\"precision\"],\n",
    "    \"recall_weighted\": gb_report[\"weighted avg\"][\"recall\"],\n",
    "    \"f1_weighted\": gb_report[\"weighted avg\"][\"f1-score\"],\n",
    "    \"training_time\": gb_train_time,\n",
    "    \"prediction_time\": gb_pred_time,\n",
    "    \"total_time\": gb_train_time + gb_pred_time,\n",
    "    \"notes\": f\"Gradient Boosting optimisé avec {optimal_n_features} features\"\n",
    "}\n",
    "\n",
    "results_tracker = add_result(results_tracker, result_gb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e71eb31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.3 Modèle supervisé 3: SVM\n",
    "print(\"\\n--- Modèle supervisé 3: SVM ---\")\n",
    "\n",
    "# Définir la grille de paramètres pour SVM\n",
    "svm_param_grid = {\n",
    "    'C': [0.1, 1, 10, 100],\n",
    "    'gamma': ['scale', 'auto', 0.1, 0.01],\n",
    "    'kernel': ['rbf', 'poly', 'sigmoid'],\n",
    "    'class_weight': ['balanced', None]\n",
    "}\n",
    "\n",
    "# Optimiser les hyperparamètres de SVM sur un échantillon réduit\n",
    "sample_size = min(5000, len(X_optimal))\n",
    "X_sample = X_optimal.iloc[:sample_size]\n",
    "y_sample = y_train.iloc[:sample_size]\n",
    "\n",
    "print(\"\\nOptimisation des hyperparamètres pour SVM (sur échantillon réduit)...\")\n",
    "svm_opt_result = optimize_hyperparameters(\n",
    "    SVC(random_state=42, probability=True),\n",
    "    svm_param_grid,\n",
    "    X_sample,\n",
    "    y_sample,\n",
    "    n_iter=10,  # Réduit pour des raisons de temps\n",
    "    use_random=True\n",
    ")\n",
    "\n",
    "# Extraire le meilleur modèle et ses paramètres\n",
    "svm_best_params = svm_opt_result[\"best_params\"]\n",
    "svm_best_score = svm_opt_result[\"best_score\"]\n",
    "\n",
    "print(f\"Meilleur score de validation croisée: {svm_best_score:.4f}\")\n",
    "print(\"Meilleurs paramètres pour SVM:\")\n",
    "for param, value in svm_best_params.items():\n",
    "    print(f\"- {param}: {value}\")\n",
    "\n",
    "# Créer le modèle optimisé\n",
    "svm_model = SVC(random_state=42, probability=True, **svm_best_params)\n",
    "\n",
    "# Entraîner le modèle\n",
    "start_time = time.time()\n",
    "svm_model.fit(X_optimal, y_train)\n",
    "svm_train_time = time.time() - start_time\n",
    "\n",
    "# Faire des prédictions\n",
    "start_time = time.time()\n",
    "svm_pred = svm_model.predict(X_test_optimal)\n",
    "svm_pred_time = time.time() - start_time\n",
    "\n",
    "# Évaluer les performances\n",
    "svm_accuracy = accuracy_score(y_test, svm_pred)\n",
    "svm_report = classification_report(y_test, svm_pred, output_dict=True)\n",
    "\n",
    "print(f\"\\nPerformances du modèle SVM:\")\n",
    "print(f\"Accuracy: {svm_accuracy:.4f}\")\n",
    "print(f\"F1 score pondéré: {svm_report['weighted avg']['f1-score']:.4f}\")\n",
    "print(f\"Temps d'entraînement: {svm_train_time:.2f}s, Prédiction: {svm_pred_time:.2f}s\")\n",
    "\n",
    "# Ajouter au tracker de résultats\n",
    "result_svm = {\n",
    "    \"dataset\": best_dataset,\n",
    "    \"dataset_description\": f\"{best_configs[0]['description']} avec features optimisées\",\n",
    "    \"model\": \"svm_optimized\",\n",
    "    \"model_description\": \"SVM optimisé\",\n",
    "    \"features_added\": True,\n",
    "    \"feature_sets\": [\"Optimisées\"],\n",
    "    \"normalize_by_row\": best_normalize,\n",
    "    \"accuracy\": svm_accuracy,\n",
    "    \"precision_weighted\": svm_report[\"weighted avg\"][\"precision\"],\n",
    "    \"recall_weighted\": svm_report[\"weighted avg\"][\"recall\"],\n",
    "    \"f1_weighted\": svm_report[\"weighted avg\"][\"f1-score\"],\n",
    "    \"training_time\": svm_train_time,\n",
    "    \"prediction_time\": svm_pred_time,\n",
    "    \"total_time\": svm_train_time + svm_pred_time,\n",
    "    \"notes\": f\"SVM optimisé avec {optimal_n_features} features\"\n",
    "}\n",
    "\n",
    "results_tracker = add_result(results_tracker, result_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce70e7d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.4 Modèle ensembliste: Stacking\n",
    "print(\"\\n--- Modèle ensembliste: Stacking ---\")\n",
    "\n",
    "# Utiliser LogisticRegression comme meta-classifier\n",
    "meta_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
    "\n",
    "# Créer les estimateurs de base\n",
    "base_estimators = [\n",
    "    ('xgb', XGBClassifier(objective=\"multi:softmax\", num_class=3, random_state=42, **best_params)),\n",
    "    ('rf', RandomForestClassifier(random_state=42, **rf_best_params)),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42, **gb_best_params))\n",
    "]\n",
    "\n",
    "# Créer le modèle de stacking\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=base_estimators,\n",
    "    final_estimator=meta_classifier,\n",
    "    cv=5,\n",
    "    stack_method='predict_proba',\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entraîner le modèle\n",
    "start_time = time.time()\n",
    "stacking_model.fit(X_optimal, y_train)\n",
    "stacking_train_time = time.time() - start_time\n",
    "\n",
    "# Faire des prédictions\n",
    "start_time = time.time()\n",
    "stacking_pred = stacking_model.predict(X_test_optimal)\n",
    "stacking_pred_time = time.time() - start_time\n",
    "\n",
    "# Évaluer les performances\n",
    "stacking_accuracy = accuracy_score(y_test, stacking_pred)\n",
    "stacking_report = classification_report(y_test, stacking_pred, output_dict=True)\n",
    "\n",
    "print(f\"\\nPerformances du modèle Stacking:\")\n",
    "print(f\"Accuracy: {stacking_accuracy:.4f}\")\n",
    "print(f\"F1 score pondéré: {stacking_report['weighted avg']['f1-score']:.4f}\")\n",
    "print(f\"Temps d'entraînement: {stacking_train_time:.2f}s, Prédiction: {stacking_pred_time:.2f}s\")\n",
    "\n",
    "# Ajouter au tracker de résultats\n",
    "result_stacking = {\n",
    "    \"dataset\": best_dataset,\n",
    "    \"dataset_description\": f\"{best_configs[0]['description']} avec features optimisées\",\n",
    "    \"model\": \"stacking_ensemble\",\n",
    "    \"model_description\": \"Stacking (XGBoost, RF, GB)\",\n",
    "    \"features_added\": True,\n",
    "    \"feature_sets\": [\"Optimisées\"],\n",
    "    \"normalize_by_row\": best_normalize,\n",
    "    \"accuracy\": stacking_accuracy,\n",
    "    \"precision_weighted\": stacking_report[\"weighted avg\"][\"precision\"],\n",
    "    \"recall_weighted\": stacking_report[\"weighted avg\"][\"recall\"],\n",
    "    \"f1_weighted\": stacking_report[\"weighted avg\"][\"f1-score\"],\n",
    "    \"training_time\": stacking_train_time,\n",
    "    \"prediction_time\": stacking_pred_time,\n",
    "    \"total_time\": stacking_train_time + stacking_pred_time,\n",
    "    \"notes\": f\"Stacking de XGBoost, Random Forest et Gradient Boosting\"\n",
    "}\n",
    "\n",
    "results_tracker = add_result(results_tracker, result_stacking)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6456f50c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.5 Modèle ensembliste: Voting\n",
    "print(\"\\n--- Modèle ensembliste: Voting ---\")\n",
    "\n",
    "# Créer les estimateurs de base\n",
    "estimators = [\n",
    "    ('xgb', XGBClassifier(objective=\"multi:softmax\", num_class=3, random_state=42, **best_params)),\n",
    "    ('rf', RandomForestClassifier(random_state=42, **rf_best_params)),\n",
    "    ('gb', GradientBoostingClassifier(random_state=42, **gb_best_params))\n",
    "]\n",
    "\n",
    "# Créer le modèle de vote\n",
    "voting_model = VotingClassifier(\n",
    "    estimators=estimators,\n",
    "    voting='soft',  # Utiliser les probabilités pour le vote\n",
    "    n_jobs=-1\n",
    ")\n",
    "\n",
    "# Entraîner le modèle\n",
    "start_time = time.time()\n",
    "voting_model.fit(X_optimal, y_train)\n",
    "voting_train_time = time.time() - start_time\n",
    "\n",
    "# Faire des prédictions\n",
    "start_time = time.time()\n",
    "voting_pred = voting_model.predict(X_test_optimal)\n",
    "voting_pred_time = time.time() - start_time\n",
    "\n",
    "# Évaluer les performances\n",
    "voting_accuracy = accuracy_score(y_test, voting_pred)\n",
    "voting_report = classification_report(y_test, voting_pred, output_dict=True)\n",
    "\n",
    "print(f\"\\nPerformances du modèle Voting:\")\n",
    "print(f\"Accuracy: {voting_accuracy:.4f}\")\n",
    "print(f\"F1 score pondéré: {voting_report['weighted avg']['f1-score']:.4f}\")\n",
    "print(f\"Temps d'entraînement: {voting_train_time:.2f}s, Prédiction: {voting_pred_time:.2f}s\")\n",
    "\n",
    "# Ajouter au tracker de résultats\n",
    "result_voting = {\n",
    "    \"dataset\": best_dataset,\n",
    "    \"dataset_description\": f\"{best_configs[0]['description']} avec features optimisées\",\n",
    "    \"model\": \"voting_ensemble\",\n",
    "    \"model_description\": \"Voting (XGBoost, RF, GB)\",\n",
    "    \"features_added\": True,\n",
    "    \"feature_sets\": [\"Optimisées\"],\n",
    "    \"normalize_by_row\": best_normalize,\n",
    "    \"accuracy\": voting_accuracy,\n",
    "    \"precision_weighted\": voting_report[\"weighted avg\"][\"precision\"],\n",
    "    \"recall_weighted\": voting_report[\"weighted avg\"][\"recall\"],\n",
    "    \"f1_weighted\": voting_report[\"weighted avg\"][\"f1-score\"],\n",
    "    \"training_time\": voting_train_time,\n",
    "    \"prediction_time\": voting_pred_time,\n",
    "    \"total_time\": voting_train_time + voting_pred_time,\n",
    "    \"notes\": f\"Voting de XGBoost, Random Forest et Gradient Boosting\"\n",
    "}\n",
    "\n",
    "results_tracker = add_result(results_tracker, result_voting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78d82c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7.6 Comparaison des modèles supervisés\n",
    "print(\"\\n--- Comparaison des modèles supervisés ---\")\n",
    "\n",
    "# Créer un DataFrame pour la comparaison\n",
    "comparison_sup_df = pd.DataFrame([\n",
    "    {\"Modèle\": \"XGBoost optimisé\", \"Accuracy\": accuracy, \"F1 score\": report['weighted avg']['f1-score'], \n",
    "     \"Temps d'entraînement\": train_time, \"Temps total\": train_time + pred_time},\n",
    "    {\"Modèle\": \"Random Forest\", \"Accuracy\": rf_accuracy, \"F1 score\": rf_report['weighted avg']['f1-score'], \n",
    "     \"Temps d'entraînement\": rf_train_time, \"Temps total\": rf_train_time + rf_pred_time},\n",
    "    {\"Modèle\": \"Gradient Boosting\", \"Accuracy\": gb_accuracy, \"F1 score\": gb_report['weighted avg']['f1-score'], \n",
    "     \"Temps d'entraînement\": gb_train_time, \"Temps total\": gb_train_time + gb_pred_time},\n",
    "    {\"Modèle\": \"SVM\", \"Accuracy\": svm_accuracy, \"F1 score\": svm_report['weighted avg']['f1-score'], \n",
    "     \"Temps d'entraînement\": svm_train_time, \"Temps total\": svm_train_time + svm_pred_time},\n",
    "    {\"Modèle\": \"Stacking\", \"Accuracy\": stacking_accuracy, \"F1 score\": stacking_report['weighted avg']['f1-score'], \n",
    "     \"Temps d'entraînement\": stacking_train_time, \"Temps total\": stacking_train_time + stacking_pred_time},\n",
    "    {\"Modèle\": \"Voting\", \"Accuracy\": voting_accuracy, \"F1 score\": voting_report['weighted avg']['f1-score'], \n",
    "     \"Temps d'entraînement\": voting_train_time, \"Temps total\": voting_train_time + voting_pred_time}\n",
    "])\n",
    "\n",
    "# Trier par accuracy décroissante\n",
    "comparison_sup_df = comparison_sup_df.sort_values(\"Accuracy\", ascending=False)\n",
    "\n",
    "# Afficher le tableau de comparaison\n",
    "print(\"Comparaison des performances:\")\n",
    "display(comparison_sup_df)\n",
    "\n",
    "# Visualiser la comparaison\n",
    "plt.figure(figsize=(14, 10))\n",
    "\n",
    "plt.subplot(2, 1, 1)\n",
    "sns.barplot(x=\"Modèle\", y=\"Accuracy\", data=comparison_sup_df)\n",
    "plt.title('Comparaison des Accuracy')\n",
    "plt.ylim(0.4, 0.5)  # Ajuster selon les valeurs réelles\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.subplot(2, 1, 2)\n",
    "sns.barplot(x=\"Modèle\", y=\"Temps total\", data=comparison_sup_df)\n",
    "plt.title('Comparaison des temps d\\'exécution (secondes)')\n",
    "plt.xticks(rotation=45, ha=\"right\")\n",
    "plt.yscale('log')  # Échelle logarithmique pour mieux visualiser les différences\n",
    "plt.grid(axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3f9a2aa",
   "metadata": {},
   "source": [
    "## 8. Deep Learning\n",
    "# \n",
    "# Explorons maintenant des approches de Deep Learning pour la classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67bb71bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importation des librairies nécessaires pour le Deep Learning\n",
    "try:\n",
    "    import tensorflow as tf\n",
    "    from tensorflow.keras.models import Sequential, Model\n",
    "    from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
    "    from tensorflow.keras.optimizers import Adam\n",
    "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "    from tensorflow.keras.utils import to_categorical\n",
    "    \n",
    "    tf_available = True\n",
    "    print(\"TensorFlow est disponible, version:\", tf.__version__)\n",
    "except ImportError:\n",
    "    tf_available = False\n",
    "    print(\"TensorFlow n'est pas installé. Utilisez 'pip install tensorflow' pour l'installer.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ddaa8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "if tf_available:\n",
    "    # 8.1 Préparation des données pour le Deep Learning\n",
    "    print(\"\\n--- Préparation des données pour le Deep Learning ---\")\n",
    "    \n",
    "    # Normaliser les données\n",
    "    scaler = StandardScaler()\n",
    "    X_train_dl = scaler.fit_transform(X_optimal)\n",
    "    X_test_dl = scaler.transform(X_test_optimal)\n",
    "    \n",
    "    # Conversion des labels pour le format one-hot encoding\n",
    "    # Mapping des classes pour tensorflow\n",
    "    mapping_dl = {-1: 0, 0: 1, 1: 2}\n",
    "    y_train_mapped = np.array([mapping_dl.get(label, label) for label in y_train])\n",
    "    y_test_mapped = np.array([mapping_dl.get(label, label) for label in y_test])\n",
    "    \n",
    "    # Convertir en one-hot encoding\n",
    "    y_train_cat = to_categorical(y_train_mapped)\n",
    "    y_test_cat = to_categorical(y_test_mapped)\n",
    "    \n",
    "    print(f\"Dimensions des données d'entraînement: {X_train_dl.shape}\")\n",
    "    print(f\"Dimensions des labels d'entraînement (one-hot): {y_train_cat.shape}\")\n",
    "    \n",
    "    # 8.2 Définition du modèle MLP\n",
    "    print(\"\\n--- Définition du modèle de réseau de neurones MLP ---\")\n",
    "    \n",
    "    # Pour reproductibilité\n",
    "    tf.random.set_seed(42)\n",
    "    \n",
    "    # Définir le modèle MLP\n",
    "    def create_mlp_model(input_dim, dropout_rate=0.3):\n",
    "        model = Sequential([\n",
    "            # Première couche cachée\n",
    "            Dense(128, input_dim=input_dim, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(dropout_rate),\n",
    "            \n",
    "            # Deuxième couche cachée\n",
    "            Dense(64, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(dropout_rate),\n",
    "            \n",
    "            # Troisième couche cachée\n",
    "            Dense(32, activation='relu'),\n",
    "            BatchNormalization(),\n",
    "            Dropout(dropout_rate),\n",
    "            \n",
    "            # Couche de sortie (3 classes)\n",
    "            Dense(3, activation='softmax')\n",
    "        ])\n",
    "        \n",
    "        # Compiler le modèle\n",
    "        model.compile(\n",
    "            optimizer=Adam(learning_rate=0.001),\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['accuracy']\n",
    "        )\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    # Créer le modèle\n",
    "    mlp_model = create_mlp_model(input_dim=X_train_dl.shape[1])\n",
    "    \n",
    "    # Résumé du modèle\n",
    "    mlp_model.summary()\n",
    "    \n",
    "    # 8.3 Entraînement du modèle\n",
    "    print(\"\\n--- Entraînement du modèle MLP ---\")\n",
    "    \n",
    "    # Définir les callbacks\n",
    "    early_stopping = EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=10,\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=5,\n",
    "        min_lr=0.0001,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Entraîner le modèle\n",
    "    start_time = time.time()\n",
    "    history = mlp_model.fit(\n",
    "        X_train_dl,\n",
    "        y_train_cat,\n",
    "        validation_split=0.2,\n",
    "        epochs=50,\n",
    "        batch_size=64,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    mlp_train_time = time.time() - start_time\n",
    "    \n",
    "    # 8.4 Évaluation du modèle\n",
    "    print(\"\\n--- Évaluation du modèle MLP ---\")\n",
    "    \n",
    "    # Évaluer le modèle sur les données de test\n",
    "    start_time = time.time()\n",
    "    mlp_loss, mlp_accuracy = mlp_model.evaluate(X_test_dl, y_test_cat, verbose=0)\n",
    "    mlp_pred_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Accuracy du modèle MLP: {mlp_accuracy:.4f}\")\n",
    "    print(f\"Temps d'entraînement: {mlp_train_time:.2f} secondes\")\n",
    "    print(f\"Temps de prédiction: {mlp_pred_time:.2f} secondes\")\n",
    "    \n",
    "    # Obtenir les prédictions\n",
    "    mlp_pred_proba = mlp_model.predict(X_test_dl)\n",
    "    mlp_pred_classes = np.argmax(mlp_pred_proba, axis=1)\n",
    "    \n",
    "    # Reconvertir les classes prédites au format original (-1, 0, 1)\n",
    "    inverse_mapping = {0: -1, 1: 0, 2: 1}\n",
    "    mlp_predictions = np.array([inverse_mapping.get(label, label) for label in mlp_pred_classes])\n",
    "# Calculer les métriques\n",
    "    mlp_eval_accuracy = accuracy_score(y_test, mlp_predictions)\n",
    "    mlp_report = classification_report(y_test, mlp_predictions, output_dict=True)\n",
    "    \n",
    "    print(f\"\\nPerformances détaillées:\")\n",
    "    print(f\"Accuracy: {mlp_eval_accuracy:.4f}\")\n",
    "    print(f\"F1 score pondéré: {mlp_report['weighted avg']['f1-score']:.4f}\")\n",
    "    \n",
    "    # Afficher la matrice de confusion\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    mlp_conf_matrix = confusion_matrix(y_test, mlp_predictions)\n",
    "    sns.heatmap(mlp_conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
    "               xticklabels=[-1, 0, 1], yticklabels=[-1, 0, 1])\n",
    "    plt.title('Matrice de Confusion - MLP')\n",
    "    plt.xlabel('Prédiction')\n",
    "    plt.ylabel('Valeur Réelle')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Ajouter au tracker de résultats\n",
    "    result_mlp = {\n",
    "        \"dataset\": best_dataset,\n",
    "        \"dataset_description\": f\"{best_configs[0]['description']} avec features optimisées\",\n",
    "        \"model\": \"mlp_deep_learning\",\n",
    "        \"model_description\": \"Réseau de neurones MLP\",\n",
    "        \"features_added\": True,\n",
    "        \"feature_sets\": [\"Optimisées\"],\n",
    "        \"normalize_by_row\": best_normalize,\n",
    "        \"accuracy\": mlp_eval_accuracy,\n",
    "        \"precision_weighted\": mlp_report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall_weighted\": mlp_report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1_weighted\": mlp_report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"training_time\": mlp_train_time,\n",
    "        \"prediction_time\": mlp_pred_time,\n",
    "        \"total_time\": mlp_train_time + mlp_pred_time,\n",
    "        \"notes\": f\"MLP avec 3 couches cachées (128, 64, 32)\"\n",
    "    }\n",
    "    \n",
    "    results_tracker = add_result(results_tracker, result_mlp)\n",
    "    \n",
    "    # 8.5 Visualisation des courbes d'apprentissage\n",
    "    print(\"\\n--- Visualisation des courbes d'apprentissage ---\")\n",
    "    \n",
    "    # Visualiser l'évolution de l'accuracy et de la loss\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history.history['accuracy'], label='Train')\n",
    "    plt.plot(history.history['val_accuracy'], label='Validation')\n",
    "    plt.title('Évolution de l\\'accuracy')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history.history['loss'], label='Train')\n",
    "    plt.plot(history.history['val_loss'], label='Validation')\n",
    "    plt.title('Évolution de la loss')\n",
    "    plt.xlabel('Époque')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 8.6 Modèle Deep Learning avec autoencoder\n",
    "    print(\"\\n--- Modèle Deep Learning avec autoencoder ---\")\n",
    "    \n",
    "    # Définir le modèle autoencoder\n",
    "    def create_autoencoder(input_dim, encoding_dim=15):\n",
    "        # Encoder\n",
    "        input_layer = Input(shape=(input_dim,))\n",
    "        encoded = Dense(64, activation='relu')(input_layer)\n",
    "        encoded = Dense(32, activation='relu')(encoded)\n",
    "        encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
    "        \n",
    "        # Decoder\n",
    "        decoded = Dense(32, activation='relu')(encoded)\n",
    "        decoded = Dense(64, activation='relu')(decoded)\n",
    "        decoded = Dense(input_dim, activation='linear')(decoded)\n",
    "        \n",
    "        # Autoencoder complet\n",
    "        autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
    "        autoencoder.compile(optimizer='adam', loss='mse')\n",
    "        \n",
    "        # Encoder seul (pour extraire les features)\n",
    "        encoder = Model(inputs=input_layer, outputs=encoded)\n",
    "        \n",
    "        return autoencoder, encoder\n",
    "    \n",
    "    # Créer l'autoencoder\n",
    "    autoencoder, encoder = create_autoencoder(input_dim=X_train_dl.shape[1])\n",
    "    \n",
    "    # Entraîner l'autoencoder\n",
    "    start_time = time.time()\n",
    "    autoencoder.fit(\n",
    "        X_train_dl, \n",
    "        X_train_dl,\n",
    "        epochs=30,\n",
    "        batch_size=64,\n",
    "        validation_split=0.2,\n",
    "        callbacks=[early_stopping],\n",
    "        verbose=1\n",
    "    )\n",
    "    autoencoder_train_time = time.time() - start_time\n",
    "    \n",
    "    # Extraire les features encodées\n",
    "    X_train_encoded = encoder.predict(X_train_dl)\n",
    "    X_test_encoded = encoder.predict(X_test_dl)\n",
    "    \n",
    "    print(f\"Dimensions des features encodées: {X_train_encoded.shape}\")\n",
    "    \n",
    "    # 8.7 Classification avec les features encodées\n",
    "    print(\"\\n--- Classification avec les features encodées de l'autoencoder ---\")\n",
    "    \n",
    "    # Créer un modèle de classification\n",
    "    ae_classifier = Sequential([\n",
    "        Dense(32, input_dim=X_train_encoded.shape[1], activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(16, activation='relu'),\n",
    "        BatchNormalization(),\n",
    "        Dropout(0.3),\n",
    "        Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    # Compiler le modèle\n",
    "    ae_classifier.compile(\n",
    "        optimizer=Adam(learning_rate=0.001),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "    \n",
    "    # Entraîner le modèle\n",
    "    start_time = time.time()\n",
    "    ae_history = ae_classifier.fit(\n",
    "        X_train_encoded,\n",
    "        y_train_cat,\n",
    "        validation_split=0.2,\n",
    "        epochs=50,\n",
    "        batch_size=64,\n",
    "        callbacks=[early_stopping, reduce_lr],\n",
    "        verbose=1\n",
    "    )\n",
    "    ae_train_time = time.time() - start_time + autoencoder_train_time  # Inclure le temps d'entraînement de l'autoencoder\n",
    "    \n",
    "    # Évaluer le modèle\n",
    "    start_time = time.time()\n",
    "    ae_loss, ae_accuracy = ae_classifier.evaluate(X_test_encoded, y_test_cat, verbose=0)\n",
    "    ae_pred_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"Accuracy du modèle avec autoencoder: {ae_accuracy:.4f}\")\n",
    "    print(f\"Temps d'entraînement total (autoencoder + classifier): {ae_train_time:.2f} secondes\")\n",
    "    print(f\"Temps de prédiction: {ae_pred_time:.2f} secondes\")\n",
    "    \n",
    "    # Obtenir les prédictions\n",
    "    ae_pred_proba = ae_classifier.predict(X_test_encoded)\n",
    "    ae_pred_classes = np.argmax(ae_pred_proba, axis=1)\n",
    "    \n",
    "    # Reconvertir les classes prédites au format original (-1, 0, 1)\n",
    "    ae_predictions = np.array([inverse_mapping.get(label, label) for label in ae_pred_classes])\n",
    "    \n",
    "    # Calculer les métriques\n",
    "    ae_eval_accuracy = accuracy_score(y_test, ae_predictions)\n",
    "    ae_report = classification_report(y_test, ae_predictions, output_dict=True)\n",
    "    \n",
    "    print(f\"\\nPerformances détaillées:\")\n",
    "    print(f\"Accuracy: {ae_eval_accuracy:.4f}\")\n",
    "    print(f\"F1 score pondéré: {ae_report['weighted avg']['f1-score']:.4f}\")\n",
    "    \n",
    "    # Ajouter au tracker de résultats\n",
    "    result_ae = {\n",
    "        \"dataset\": best_dataset,\n",
    "        \"dataset_description\": f\"{best_configs[0]['description']} avec features optimisées\",\n",
    "        \"model\": \"autoencoder_deep_learning\",\n",
    "        \"model_description\": \"Autoencoder + MLP\",\n",
    "        \"features_added\": True,\n",
    "        \"feature_sets\": [\"Optimisées + Autoencoder\"],\n",
    "        \"normalize_by_row\": best_normalize,\n",
    "        \"accuracy\": ae_eval_accuracy,\n",
    "        \"precision_weighted\": ae_report[\"weighted avg\"][\"precision\"],\n",
    "        \"recall_weighted\": ae_report[\"weighted avg\"][\"recall\"],\n",
    "        \"f1_weighted\": ae_report[\"weighted avg\"][\"f1-score\"],\n",
    "        \"training_time\": ae_train_time,\n",
    "        \"prediction_time\": ae_pred_time,\n",
    "        \"total_time\": ae_train_time + ae_pred_time,\n",
    "        \"notes\": f\"Autoencoder (encoding_dim={X_train_encoded.shape[1]}) + classifier\"\n",
    "    }\n",
    "    \n",
    "    results_tracker = add_result(results_tracker, result_ae)\n",
    "    \n",
    "    # 8.8 Comparaison des modèles Deep Learning avec les autres modèles\n",
    "    print(\"\\n--- Comparaison des modèles Deep Learning avec les autres approches ---\")\n",
    "    \n",
    "    # Créer un DataFrame pour la comparaison\n",
    "    dl_comparison_df = pd.DataFrame([\n",
    "        {\"Modèle\": \"XGBoost optimisé\", \"Accuracy\": accuracy, \"F1 score\": report['weighted avg']['f1-score'],\n",
    "         \"Catégorie\": \"Supervisé\"},\n",
    "        {\"Modèle\": \"Random Forest\", \"Accuracy\": rf_accuracy, \"F1 score\": rf_report['weighted avg']['f1-score'],\n",
    "         \"Catégorie\": \"Supervisé\"},\n",
    "        {\"Modèle\": \"Stacking Ensemble\", \"Accuracy\": stacking_accuracy, \"F1 score\": stacking_report['weighted avg']['f1-score'],\n",
    "         \"Catégorie\": \"Supervisé\"},\n",
    "        {\"Modèle\": \"K-Means + XGBoost\", \"Accuracy\": accuracy_kmeans, \"F1 score\": report_kmeans['weighted avg']['f1-score'],\n",
    "         \"Catégorie\": \"Non supervisé\"},\n",
    "        {\"Modèle\": \"MLP\", \"Accuracy\": mlp_eval_accuracy, \"F1 score\": mlp_report['weighted avg']['f1-score'],\n",
    "         \"Catégorie\": \"Deep Learning\"},\n",
    "        {\"Modèle\": \"Autoencoder + MLP\", \"Accuracy\": ae_eval_accuracy, \"F1 score\": ae_report['weighted avg']['f1-score'],\n",
    "         \"Catégorie\": \"Deep Learning\"}\n",
    "    ])\n",
    "    \n",
    "    # Trier par accuracy décroissante\n",
    "    dl_comparison_df = dl_comparison_df.sort_values(\"Accuracy\", ascending=False)\n",
    "    \n",
    "    # Afficher le tableau de comparaison\n",
    "    print(\"Comparaison des performances:\")\n",
    "    display(dl_comparison_df)\n",
    "    \n",
    "    # Visualiser la comparaison\n",
    "    plt.figure(figsize=(14, 8))\n",
    "    sns.barplot(x=\"Modèle\", y=\"Accuracy\", hue=\"Catégorie\", data=dl_comparison_df)\n",
    "    plt.title('Comparaison des performances des différentes approches')\n",
    "    plt.xticks(rotation=45, ha=\"right\")\n",
    "    plt.ylim(0.4, 0.5)  # Ajuster selon les valeurs réelles\n",
    "    plt.grid(axis='y')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # 8.9 Bilan des modèles Deep Learning\n",
    "    print(\"\\n--- Bilan des modèles Deep Learning ---\")\n",
    "    \n",
    "    # Comparer spécifiquement les deux approches Deep Learning\n",
    "    dl_specific_comparison = dl_comparison_df[dl_comparison_df[\"Catégorie\"] == \"Deep Learning\"]\n",
    "    display(dl_specific_comparison)\n",
    "    \n",
    "    print(\"\\nAvantages et inconvénients des modèles Deep Learning:\")\n",
    "    print(\"Avantages:\")\n",
    "    print(\"- Capacité à capturer des relations complexes et non linéaires\")\n",
    "    print(\"- Performances compétitives avec les autres approches\")\n",
    "    print(\"- Flexibilité dans l'architecture et la représentation des données\")\n",
    "    \n",
    "    print(\"\\nInconvénients:\")\n",
    "    print(\"- Temps d'entraînement plus long\")\n",
    "    print(\"- Nécessite plus de paramétrage et d'optimisation\")\n",
    "    print(\"- Risque de surapprentissage plus élevé\")\n",
    "    \n",
    "    # Meilleur modèle global\n",
    "    best_model_overall = dl_comparison_df.iloc[0]\n",
    "    print(f\"\\nMeilleur modèle global: {best_model_overall['Modèle']}\")\n",
    "    print(f\"Accuracy: {best_model_overall['Accuracy']:.4f}\")\n",
    "    print(f\"F1 score: {best_model_overall['F1 score']:.4f}\")\n",
    "    print(f\"Catégorie: {best_model_overall['Catégorie']}\")\n",
    "else:\n",
    "    print(\"\\nLa partie Deep Learning n'a pas été exécutée car TensorFlow n'est pas installé.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30b1f9a",
   "metadata": {},
   "source": [
    "## 9. Résumé et conclusion\n",
    "# \n",
    "# Dans cette étude, nous avons exploré différentes approches pour prédire la direction des prix des actions sur le marché américain pendant les deux dernières heures de trading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4b46fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9.1 Compilation des résultats finaux"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
