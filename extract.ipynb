{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1fdd4658",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# --- Code Cell ---\n",
      "# --- Importation des librairies (section ajoutée pour regrouper tous les imports) ---\n",
      "import pandas as pd\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "import time\n",
      "from datetime import datetime\n",
      "import warnings\n",
      "warnings.filterwarnings('ignore')\n",
      "\n",
      "# Configuration de l'affichage\n",
      "plt.style.use('seaborn-v0_8-whitegrid')\n",
      "sns.set_context(\"notebook\", font_scale=1.2)\n",
      "plt.rcParams['figure.figsize'] = (12, 8)\n",
      "\n",
      "# Importation des modules utilitaires\n",
      "from utils.data_registry import DATASETS\n",
      "from utils.benchmarks import get_models, get_unsupervised_models, get_supervised_advanced_models\n",
      "from utils.data_loading import load_datasets\n",
      "from utils.data_preprocessing import normalize_rendements_by_row, create_low_nan_dataset\n",
      "from utils.feature_engineering import add_features, add_financial_features\n",
      "from utils.experiment_runner import run_experiment, display_experiment_result, add_result\n",
      "from utils.data_analysis import (\n",
      "    analyze_distributions,\n",
      "    compare_column_stats,\n",
      "    analyze_normalization,\n",
      "    compare_normalization_impact,\n",
      "    perform_pca_analysis,\n",
      "    analyze_correlations\n",
      ")\n",
      "from utils.feature_selection import (\n",
      "    select_by_correlation,\n",
      "    select_by_f_value,\n",
      "    select_by_mutual_info,\n",
      "    optimize_feature_count,\n",
      "    find_important_features\n",
      ")\n",
      "from utils.model_interpretation import analyze_feature_importance, analyze_with_shap, plot_shap_summary\n",
      "from utils.model_evaluation import optimize_hyperparameters, evaluate_model_performance, plot_confusion_matrix, create_results_summary\n",
      "\n",
      "from sklearn.impute import SimpleImputer\n",
      "from sklearn.pipeline import Pipeline\n",
      "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, StackingClassifier, VotingClassifier\n",
      "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
      "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, QuantileTransformer\n",
      "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
      "from sklearn.svm import SVC\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.cluster import KMeans, DBSCAN\n",
      "from sklearn.decomposition import PCA\n",
      "from xgboost import XGBClassifier\n",
      "from IPython.display import display\n",
      "from tqdm import tqdm\n",
      "\n",
      "# Create empty results tracker avec les colonnes améliorées\n",
      "results_tracker = pd.DataFrame(columns=[\n",
      "    \"dataset\", \"dataset_description\", \"model\", \"model_description\",\n",
      "    \"features_added\", \"feature_sets\", \"normalize_by_row\", \"accuracy\", \n",
      "    \"precision_weighted\", \"recall_weighted\", \"f1_weighted\",\n",
      "    \"training_time\", \"prediction_time\", \"total_time\", \"notes\"\n",
      "])\n",
      "# --- Markdown Cell ---\n",
      "# Prédiction de la direction des prix sur les marchés financiers\n",
      "# --- Markdown Cell ---\n",
      "## 1. Introduction et présentation du problème\n",
      "# --- Markdown Cell ---\n",
      "# \n",
      "### 1.1 Contexte et enjeux\n",
      "# \n",
      "# Dans le cadre de ce challenge (issu du Collège de France ou du Lab Banque de France), nous disposons de données de marché avec pour objectif de prédire la direction du prix (baisse, stable, hausse) en fin de journée, à partir des rendements du matin.\n",
      "#  \n",
      "# Ce marché américain étant particulièrement liquide, l'enjeu est de pouvoir estimer la tendance entre 14h et 16h pour prendre des décisions d'investissement ou d'arbitrage.\n",
      "# --- Markdown Cell ---\n",
      "# \n",
      "### 1.2 Description des données\n",
      "# \n",
      "# - **Index des données**\n",
      "#   - Chaque ligne représente un jour donné et une action donnée (identifiants : `day` et `equity`).\n",
      "#   - Les colonnes `r0` à `r52` correspondent aux rendements (en points de base) toutes les 5 minutes entre 9h30 et 14h.\n",
      "# \n",
      "# - **Variables explicatives**\n",
      "#   - Les 53 rendements (`r0, r1, …, r52`), éventuellement d'autres features dérivées.\n",
      "# \n",
      "# - **Variable cible**\n",
      "#   - `reod` {-1, 0, 1} indiquant la tendance de l'actif entre 14h et 16h (baisse, stable ou hausse).\n",
      "\n",
      "# --- Markdown Cell ---\n",
      "# \n",
      "### 1.3 Problématique et défis\n",
      "# \n",
      "# Notre mission est de prédire la classe de rendement (`reod`) en fin de journée, à partir des données matinales. Les défis principaux sont :\n",
      "# \n",
      "# - La **taille importante** du dataset (plusieurs centaines de milliers de lignes).\n",
      "# - La **présence de valeurs manquantes** (`NaN`).\n",
      "# - L'**absence de jours/actions communs** entre le jeu d'entraînement et le jeu de test, ce qui complique l'utilisation directe de `equity` ou `day` en tant que features.\n",
      "# - Le **risque de surcoût mémoire** et de temps de calcul avec certains modèles comme les Random Forest.\n",
      "\n",
      "# --- Markdown Cell ---\n",
      "# \n",
      "## 2. Exploration des données (EDA)\n",
      "# --- Markdown Cell ---\n",
      "### 2.1 Aperçu des données et analyse des valeurs manquantes\n",
      "# \n",
      "# Nous commençons par explorer les données d'entraînement pour comprendre leur structure et la distribution des valeurs manquantes.\n",
      "\n",
      "# --- Code Cell ---\n",
      "# Importation des données d'entraînement\n",
      "X = pd.read_csv('input_training.csv')\n",
      "X.sort_values(by=\"ID\", inplace=True)\n",
      "y = pd.read_csv('output/output_training_gmEd6Zt.csv')\n",
      "\n",
      "# Importation des données de test\n",
      "data_test = pd.read_csv('input_test.csv')\n",
      "data_test.sort_values(by=\"ID\", inplace=True)\n",
      "y_test = pd.read_csv(\"output/output_test_random.csv\")\n",
      "\n",
      "# Fusion des données et labels\n",
      "X_train = pd.merge(X, y, on=\"ID\").copy()\n",
      "data_test.sort_values(by=\"ID\", inplace=True)\n",
      "X_test = pd.merge(data_test, y_test, on=\"ID\").copy()\n",
      "\n",
      "# Aperçu des données\n",
      "print(\"\\n--- Aperçu des données d'entraînement ---\")\n",
      "print(f\"Nombre de lignes train: {X_train.shape[0]}, Nombre de colonnes: {X_train.shape[1]}\")\n",
      "print(f\"Nombre de lignes test: {X_test.shape[0]}, Nombre de colonnes: {X_test.shape[1]}\")\n",
      "print(\"\\nPremières lignes:\")\n",
      "X_train.head()\n",
      "# --- Markdown Cell ---\n",
      "#### Analyse des valeurs manquantes \n",
      "# --- Code Cell ---\n",
      "col_rendements = [col for col in X_train.columns if col.startswith(\"r\")]\n",
      "# Analyse du nombre de valeurs manquantes par colonne\n",
      "plt.figure(figsize=(16, 4))\n",
      "\n",
      "missing_values_count = X_train[col_rendements].isna().sum()\n",
      "missing_values_percent = (missing_values_count / len(X_train)) * 100\n",
      "missing_df = pd.DataFrame({\n",
      "    'Nombre de NaN': missing_values_count,\n",
      "    'Pourcentage (%)': missing_values_percent\n",
      "}).sort_values('Nombre de NaN', ascending=False)\n",
      "\n",
      "ax = missing_df['Pourcentage (%)'].plot.bar()\n",
      "plt.title('Pourcentage de valeurs manquantes par colonne de rendement')\n",
      "plt.ylabel('Pourcentage de valeurs manquantes (%)')\n",
      "plt.xlabel('Colonne')\n",
      "plt.xticks(rotation=90)\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "# --- Markdown Cell ---\n",
      "# On observe que la majorité des colonnes contiennent en moyenne 10% de NaN. Le plus probable est que ce soit lié à des lignes majoritairement composées de NaN, probablement lié à une erreur lors de l'extraction des données. \n",
      "# --- Code Cell ---\n",
      "# Analyse du nombre de valeurs manquantes par ligne\n",
      "NaN_analysis = pd.DataFrame(index=X_train.index, columns=[\"NaN_count\", \"NaN_percent\"])\n",
      "NaN_analysis[\"NaN_count\"] = X_train[col_rendements].isna().sum(axis=1)\n",
      "nombre_colonnes_rend = len(col_rendements)\n",
      "NaN_analysis[\"NaN_percent\"] = (NaN_analysis[\"NaN_count\"] / nombre_colonnes_rend) * 100\n",
      "\n",
      "# Compter le nombre de lignes avec des NaN\n",
      "nbr_row_na = X_train.isna().any(axis=1).sum()\n",
      "\n",
      "print(f\"Nombre de lignes totales du dataset: {len(X_train)}\")\n",
      "print(f\"Nombre de lignes contenant au moins un NaN: {nbr_row_na}, soit {(nbr_row_na/len(X_train)*100):.2f}%\")\n",
      "print(f\"Nombre de lignes avec plus de 30% de NaN: {len(NaN_analysis[NaN_analysis['NaN_percent']>30])}, soit {len(NaN_analysis[NaN_analysis['NaN_percent']>30])/len(X_train)*100:.2f}%\")\n",
      "print(f\"Nombre de lignes avec plus de 50% de NaN: {len(NaN_analysis[NaN_analysis['NaN_percent']>50])}, soit {len(NaN_analysis[NaN_analysis['NaN_percent']>50])/len(X_train)*100:.2f}%\")\n",
      "\n",
      "plt.figure(figsize=(12, 6))\n",
      "sns.histplot(NaN_analysis[\"NaN_percent\"], bins=50, kde=True)\n",
      "plt.title('Distribution du pourcentage de valeurs manquantes par ligne')\n",
      "plt.xlabel('Pourcentage de valeurs manquantes (%)')\n",
      "plt.ylabel('Nombre de lignes')\n",
      "plt.axvline(x=30, color='r', linestyle='--', label='Seuil de 30%')\n",
      "plt.axvline(x=50, color='g', linestyle='--', label='Seuil de 50%')\n",
      "plt.legend()\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "# --- Markdown Cell ---\n",
      "# On décide arbitrairement de retirer l'ensemble des lignes qui contiennent 30% de NaN (dans les colonnes rendements, donc day, equity, ID sont exclus) afin d'avoir un dataset potentiellement plus propre.\n",
      "# \n",
      "# Fast Forward : Cette décision est également motivée par la répartition des classes \"reod\", composée majoritairement de 0 (environ 41%). On peut intellectualiser cela par le fait que les problèmes de données viennent des exchanges ou du marché résultant dans un marché peu mouvementé. On aurait donc un lien entre l'absence de mouvement dans les marchés et le problème de récupération des données. Potentiellement une fermeture de marché\n",
      "# --- Code Cell ---\n",
      "# Distribution spatiale des NaN (heatmap)\n",
      "plt.figure(figsize=(20, 10))\n",
      "sample_size = min(1000, len(X_train))  # Limiter à 1000 lignes pour la lisibilité\n",
      "sample_indices = np.random.choice(range(len(X_train)), sample_size, replace=False)\n",
      "sample_data = X_train.iloc[sample_indices][col_rendements].isna()\n",
      "sns.heatmap(sample_data, cbar=False, cmap='viridis')\n",
      "plt.title('Distribution spatiale des valeurs manquantes (échantillon aléatoire)')\n",
      "plt.xlabel('Colonne de rendement')\n",
      "plt.ylabel('Ligne (échantillon)')\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "# --- Markdown Cell ---\n",
      "### 2.2 Distribution des rendements\n",
      "# \n",
      "# Analysons la distribution des rendements pour identifier d'éventuelles caractéristiques ou anomalies.\n",
      "# --- Code Cell ---\n",
      "col_rendements.remove(\"reod\")\n",
      "# --- Code Cell ---\n",
      "# Affichage de la distribution pour quelques rendements représentatifs\n",
      "sample_cols = ['r0', 'r1', 'r2', 'r3','r4', 'r5','r6', 'r10', 'r25', 'r40','r50','r51', 'r52']\n",
      "plt.figure(figsize=(15, 15))\n",
      "\n",
      "for i, col in enumerate(sample_cols):\n",
      "    plt.subplot(len(sample_cols), 1, i+1)\n",
      "    sns.histplot(X_train[col].dropna(), kde=True, bins=50)\n",
      "    plt.title(f'Distribution de {col}')\n",
      "    plt.xlabel('Rendement (points de base)')\n",
      "    plt.ylabel('Fréquence')\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "# --- Markdown Cell ---\n",
      "# L'analyse de la distribution des rendements n'est venue qu'assez tard dans notre analyse des données. En effet, avant de se plonger dans la construction des modèles, nous avions un benchmark, le XGBoost. L'objectif était de retrouver dans un premier temps les résultats du benchmark du challenge. Ces tentatives d'amélioration sont passées par de nombreuses de transformations de données, dont certaines imputations que l'on retrouvera plus tard (forward fill, backward fill...) puis l'analyse de la normalité des données. Le StandardScaler() de scikit learn s'effectuant sur les colonnes, il fallait d'abord regarder comment se comportaient certaines colonnes. Nous nous pencherons sur cette analyse dans le focus sur le XGBoost (Partie 5).\n",
      "# \n",
      "# Bien que les rendements ne suivent pas une loi normale, de toute évidence, il est important de noter que certains présentent de nombreuses valeurs extrêmes, notamment les rendements en début de journée (de r0 à r3) donc les 20 premières minutes qui présentent une moyenne très élevée et surtout de nombreuses valeurs extrêmes. \n",
      "# --- Code Cell ---\n",
      "rendements_stats = X_train[col_rendements].describe().T\n",
      "rendements_stats['missing_percent'] = X_train[col_rendements].isna().mean() * 100\n",
      "rendements_stats = rendements_stats.sort_values('max', ascending=False)\n",
      "rendements_stats.head(10)\n",
      "# --- Code Cell ---\n",
      "plt.figure(figsize=(15, 6))\n",
      "plt.subplot(1, 2, 1)\n",
      "plt.scatter(rendements_stats.index, rendements_stats['mean'], alpha=0.6)\n",
      "plt.title('Moyenne des rendements par colonne')\n",
      "plt.xticks(rotation=90)\n",
      "plt.ylabel('Moyenne')\n",
      "\n",
      "plt.subplot(1, 2, 2)\n",
      "plt.scatter(rendements_stats.index, rendements_stats['std'], alpha=0.6, color='orange')\n",
      "plt.title('Écart-type des rendements par colonne')\n",
      "plt.xticks(rotation=90)\n",
      "plt.ylabel('Écart-type')\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "# --- Markdown Cell ---\n",
      "### 2.3 Analyse de la variable cible\n",
      "# \n",
      "# Examinons la distribution de notre variable cible `reod` pour vérifier l'équilibre entre les classes.\n",
      "# --- Code Cell ---\n",
      "# Distribution des classes\n",
      "plt.figure(figsize=(10, 6))\n",
      "\n",
      "class_counts = X_train['reod'].value_counts().sort_index()\n",
      "ax = sns.barplot(x=class_counts.index, y=class_counts.values)\n",
      "\n",
      "plt.title('Distribution des classes (reod)')\n",
      "plt.xlabel('Classe (-1: Baisse, 0: Stable, 1: Hausse)')\n",
      "plt.ylabel('Nombre d\\'observations')\n",
      "\n",
      "total = len(X_train)\n",
      "for i, v in enumerate(class_counts):\n",
      "    ax.text(i, v + 5000, f'{v} ({v/total*100:.1f}%)', ha='center')\n",
      "    \n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "# --- Code Cell ---\n",
      "# Analyse des rendements par classe pour quelques variables représentatives\n",
      "plt.figure(figsize=(15, 15))\n",
      "\n",
      "for i, col in enumerate(sample_cols):\n",
      "    plt.subplot(len(sample_cols), 1, i+1)\n",
      "    for cls in sorted(X_train['reod'].unique()):\n",
      "        subset = X_train[X_train['reod'] == cls][col].dropna()\n",
      "        sns.kdeplot(subset, label=f'Classe {cls}')\n",
      "    plt.title(f'Distribution de {col} par classe')\n",
      "    plt.xlabel('Rendement (points de base)')\n",
      "    plt.ylabel('Densité')\n",
      "    plt.legend()\n",
      "    \n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "# --- Code Cell ---\n",
      "# Corrélation entre les rendements et la variable cible\n",
      "correlations = X_train[col_rendements + ['reod']].corr()['reod'].drop('reod').sort_values(ascending=False)\n",
      "\n",
      "plt.figure(figsize=(12, 6))\n",
      "sns.barplot(x=correlations.index, y=correlations.values)\n",
      "plt.title('Corrélation entre les rendements et la variable cible (reod)')\n",
      "plt.xticks(rotation=90)\n",
      "plt.xlabel('Colonne de rendement')\n",
      "plt.ylabel('Coefficient de corrélation')\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "print(\"Top 5 des rendements positivement corrélés avec reod:\")\n",
      "display(correlations.head())\n",
      "\n",
      "print(\"\\nTop 5 des rendements négativement corrélés avec reod:\")\n",
      "display(correlations.tail())\n",
      "# --- Markdown Cell ---\n",
      "# 3. Stratégies d'imputation\n",
      "# \n",
      "# Face au défi des valeurs manquantes, nous testons plusieurs stratégies d'imputation pour compléter les données. Ces données ont été générée en amont dans le fichier : KNN_data.ipynb pour des raisons pratiques et de présentation.\n",
      "# \n",
      "# - 1 :  Forward-fill puis backward-fill (FFBF)\n",
      "# \n",
      "# Cette stratégie propage d'abord les dernières valeurs connues vers l'avant, puis remplit les valeurs restantes en propageant depuis la fin. C'est supposément la méthode d'imputation classique pour ce genre de cas avec l'interpolation linéaire.\n",
      "# \n",
      "# - 2 : Backward-fill puis forward-fill (BFFF)\n",
      "# \n",
      "# Cette stratégie inverse commence par propager depuis la fin, puis remplit les valeurs restantes en propageant depuis le début. Cette méthode peut introduire un biais de looking forward mais dans les faits, on remarquera que la différence est très faible avec le FFBF.\n",
      "# \n",
      "# - 3 : Interpolation linéaire\n",
      "# \n",
      "# Cette méthode crée une ligne droite entre les valeurs connues pour estimer les valeurs manquantes.\n",
      "# \n",
      "# - 4 : Imputation par K plus proches voisins (KNN)\n",
      "# \n",
      "# Cette méthode utilise les K observations les plus similaires pour estimer les valeurs manquantes.\n",
      "# \n",
      "# - 5 : MICE (Multiple Imputation by Chained Equations) est une méthode itérative qui modélise chaque variable contenant des valeurs manquantes en fonction des autres variables du jeu de données, en répétant ce processus plusieurs fois pour affiner les imputations et générer des estimations cohérentes et réalistes.\n",
      "# \n",
      "# Chacune de ces méthodes est appliquée en première. Ensuite, pour chacune, nous appliquons un forward puis un backward fill s'il reste des NaN. L'ensemble de ces fonctions peuvent être trouvées dans data_preprocessing.py. \n",
      "# \n",
      "# \n",
      "# Egalement, l'ensemble des données, chemin d'accès à ces données sont dans une variable globale DATASETS dans data_registry \n",
      "# --- Markdown Cell ---\n",
      "### 3.1 Chargement des datasets avec les différentes stratégies d'imputation. \n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Chargement des datasets avec différentes stratégies d'imputation ---\")\n",
      "imputed_datasets = load_datasets()\n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Création d'un dataset avec moins de 30% de valeurs manquantes ---\")\n",
      "\n",
      "# Charger les données brutes pour appliquer le filtrage\n",
      "X_train_70 = pd.read_csv(r\"processed_data\\X_train_70.csv\")\n",
      "X_test_70 = pd.read_csv(r\"processed_data\\X_test_70.csv\")\n",
      "\n",
      "# Créer un dataset filtré (<30% NaN) avec imputation à zéro\n",
      "X_train_low_nan, X_test_low_nan = create_low_nan_dataset(X_train_70, X_test_70, threshold=0.3)\n",
      "\n",
      "# Enregistrer les datasets pour pouvoir les utiliser avec run_experiment\n",
      "X_train_low_nan.to_csv(\"processed_data/X_train_low_nan.csv\", index=False)\n",
      "X_test_low_nan.to_csv(\"processed_data/X_test_low_nan.csv\", index=False)\n",
      "\n",
      "# Ajouter au registre des datasets\n",
      "from utils.data_registry import add_dataset_with_features\n",
      "add_dataset_with_features(\"low_nan\", \n",
      "                        \"processed_data/X_train_low_nan.csv\", \n",
      "                        \"processed_data/X_test_low_nan.csv\", \n",
      "                        \"Colonnes avec <30% de NaN, imputation à 0\")\n",
      "# --- Markdown Cell ---\n",
      "### 3.2  Analyse des distribution en fonction des imputations\n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Analyse des distributions après imputation ---\")\n",
      "analyze_distributions(imputed_datasets)\n",
      "# --- Markdown Cell ---\n",
      "# Les rendements suivent environ la même distribution, même les premiers rendements, cependant, on observe largement des queues de distributions plus longues impliquant des valeurs extrêmes. On essaiera de rectifier cela en essaynt plusieurs scaler par colonnes et en faisant également une normalisation par ligne. Cela permettra d'une certaine manière de modifier la distribution. Ne connaissant pas l'impact que cela puisse avoir, nous avons testés chaque cas. Les résultats étaient soient négligeables en fonction de scaler (Standard, MinMax, Quantile...) soit positifs pour la normalisation par ligne (légère amélioration pour les XGBoost) mais négligeable.\n",
      "# --- Markdown Cell ---\n",
      "### 3.3 Comparaison des statistiques (moyenne / écart-type) par colonne et stratégie\n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Comparaison des statistiques entre les stratégies d'imputation ---\")\n",
      "stats_results = compare_column_stats(imputed_datasets)\n",
      "# --- Markdown Cell ---\n",
      "# Encore une fois, on observe que les statistiques principales pour les premiers rendements sont démesurement plus grands par rapport au reste. \n",
      "# --- Markdown Cell ---\n",
      "### 3.4 Impact des méthodes de normalisation\n",
      "# --- Code Cell ---\n",
      "normalization_results = analyze_normalization(imputed_datasets)\n",
      "# --- Markdown Cell ---\n",
      "# La normalisation par ligne et par le Quantile sont deux méthodes qui permettent de résorber le problème des longues queues de distribution qui pourraient fausser les calculs. Bien que les rendements ne suivent pas une loi normale, la distribution est légèrement meilleure et règle le soucis des extrêmes.\n",
      "# --- Markdown Cell ---\n",
      "## 4. Modèles de référence (benchmarks)\n",
      "#  \n",
      "# Nous établissons des modèles de base pour servir de références aux futures améliorations. Et effectuons une comparaison de base qui nous servira de sélection pour le choix des jeux de données. \n",
      "# --- Markdown Cell ---\n",
      "#### Features d'Ingénierie pour la Prédiction des Prix d'Actions\n",
      "# \n",
      "# Notre modèle utilise deux catégories principales de features dérivées des rendements bruts (r0 à r52):\n",
      "# \n",
      "##### 1. Features Statistiques de Base (`basic_stats`)\n",
      "# \n",
      "# Ces features capturent les distributions et tendances générales des rendements:\n",
      "# \n",
      "# | Feature | Description | Formule |\n",
      "# |---------|-------------|---------|\n",
      "# | `r_mean` | Moyenne des rendements | $\\frac{1}{n}\\sum_{i=0}^{n} r_i$ |\n",
      "# | `r_std` | Écart-type des rendements | $\\sqrt{\\frac{1}{n}\\sum_{i=0}^{n}(r_i - \\bar{r})^2}$ |\n",
      "# | `r_min` | Rendement minimum | $\\min(r_0, r_1, ..., r_{52})$ |\n",
      "# | `r_max` | Rendement maximum | $\\max(r_0, r_1, ..., r_{52})$ |\n",
      "# | `r_sum` | Somme totale des rendements | $\\sum_{i=0}^{n} r_i$ |\n",
      "# | `r_pos_count` | Nombre de rendements positifs | $\\sum_{i=0}^{n} \\mathbb{1}_{r_i > 0}$ |\n",
      "# | `r_neg_count` | Nombre de rendements négatifs | $\\sum_{i=0}^{n} \\mathbb{1}_{r_i < 0}$ |\n",
      "# | `r_zero_count` | Nombre de rendements nuls | $\\sum_{i=0}^{n} \\mathbb{1}_{r_i = 0}$ |\n",
      "# | `r_pos_sum` | Somme des rendements positifs | $\\sum_{i=0}^{n} r_i \\cdot \\mathbb{1}_{r_i > 0}$ |\n",
      "# | `r_neg_sum` | Somme des rendements négatifs | $\\sum_{i=0}^{n} r_i \\cdot \\mathbb{1}_{r_i < 0}$ |\n",
      "# \n",
      "##### 2. Indicateurs Techniques (`technical`)\n",
      "# \n",
      "# Ces features s'inspirent d'indicateurs techniques utilisés en analyse financière:\n",
      "# \n",
      "# | Feature | Description | Formule |\n",
      "# |---------|-------------|---------|\n",
      "# | `r_roll_mean_X` | Moyenne mobile sur X périodes | $\\frac{1}{X}\\sum_{i=n-X+1}^{n} r_i$ |\n",
      "# | `r_roll_std_X` | Écart-type mobile sur X périodes | $\\sqrt{\\frac{1}{X}\\sum_{i=n-X+1}^{n}(r_i - \\bar{r}_X)^2}$ |\n",
      "# | `r_momentum_5` | Différence de prix sur 5 périodes | $r_n - r_{n-5}$ |\n",
      "# | `r_momentum_10` | Différence de prix sur 10 périodes | $r_n - r_{n-10}$ |\n",
      "# \n",
      "##### 3. Features Financières Avancées\n",
      "# \n",
      "# En complément, nous utilisons également des indicateurs financiers plus sophistiqués:\n",
      "# \n",
      "# | Feature | Description | Formule |\n",
      "# |---------|-------------|---------|\n",
      "# | `volatility_X` | Volatilité sur X périodes | $\\sqrt{\\frac{1}{X}\\sum_{i=0}^{X-1}(r_i - \\bar{r})^2}$ |\n",
      "# | `sharpe_ratio` | Ratio rendement/risque | $\\frac{\\bar{r}}{\\sigma_r}$ |\n",
      "# | `momentum` | Différence entre rendements récents et anciens | $\\bar{r}_{récent} - \\bar{r}_{ancien}$ |\n",
      "# | `trend_slope` | Pente de la tendance linéaire | Coefficient de régression linéaire sur les rendements |\n",
      "# | `pos_ratio` | Ratio de rendements positifs | $\\frac{\\sum_{i=0}^{n} \\mathbb{1}_{r_i > 0}}{n}$ |\n",
      "# | `neg_ratio` | Ratio de rendements négatifs | $\\frac{\\sum_{i=0}^{n} \\mathbb{1}_{r_i < 0}}{n}$ |\n",
      "# \n",
      "# **Ces dernières features ne sont utilisés que lors de la sélection des features les plus pertinentes et n'entrent pas dans le benchmark.**\n",
      "# --- Markdown Cell ---\n",
      "### 4.1 XGBoost baseline\n",
      "#  \n",
      "# Nous commençons par évaluer les performances du modèle XGBoost sur les données brutes (70%)\n",
      "# --- Code Cell ---\n",
      "print(\"\\nDatasets disponibles:\")\n",
      "for key, info in DATASETS.items():\n",
      "    print(f\"- {key}: {info['description']}\")\n",
      "\n",
      "print(\"\\nModèles disponibles:\")\n",
      "models = get_models()\n",
      "for key, info in models.items():\n",
      "    if 'description' in info:\n",
      "        print(f\"- {key}: {info['description']}\")\n",
      "    else:\n",
      "        print(f\"- {key}\")\n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Baseline XGBoost sur données brutes ---\")\n",
      "baseline_result = run_experiment(dataset_key=\"raw\", model_key=\"xgboost_baseline\", add_feat=False)\n",
      "results_tracker = add_result(results_tracker, baseline_result)\n",
      "\n",
      "# Ajouter la colonne normalize_by_row si elle n'existe pas\n",
      "if 'normalize_by_row' not in results_tracker.columns:\n",
      "    results_tracker['normalize_by_row'] = False\n",
      "\n",
      "print(\"\\nRésultats détaillés de l'expérience baseline:\")\n",
      "display_experiment_result(baseline_result)\n",
      "# --- Markdown Cell ---\n",
      "#### Performance globale\n",
      "# \n",
      "# Accuracy de 31.05%: Cela signifie que le modèle prédit correctement la direction du prix dans environ 31% des cas. Pour un problème à 3 classes où une prédiction aléatoire donnerait ~33%, cette performance est à peine inférieure au hasard.\n",
      "# \n",
      "# F1-Score pondéré de 0.2658: Cette métrique combine précision et rappel. Un score bas indique un déséquilibre entre ces deux mesures.\n",
      "# \n",
      "# Analyse par classe : \n",
      "# \n",
      "# **Classe -1 (baisse de prix):**\n",
      "# \n",
      "# - Precision de 30.14%: Quand le modèle prédit une baisse, il a raison dans 30% des cas.\n",
      "# \n",
      "# - Recall très faible de 11.28%: Le modèle ne détecte que 11% des véritables baisses.\n",
      "# \n",
      "# \n",
      "# **Classe 0 (prix stable):**\n",
      "# \n",
      "# - Precision de 41.17%: Meilleure précision des trois classes.\n",
      "# \n",
      "# - Recall faible de 16.70%: Le modèle manque plus de 83% des cas où le prix reste stable.\n",
      "# \n",
      "# \n",
      "# **Classe 1 (hausse de prix):**\n",
      "# \n",
      "# - Precision  de 28.85%: La plus faible précision des trois classes.\n",
      "# \n",
      "# - Recall très élevé de 72.08%: Le modèle détecte bien les hausses, mais le résultat est biaisé. \n",
      "# \n",
      "# \n",
      "#### Biais du modèle\n",
      "# \n",
      "# Le modèle montre un fort biais vers la classe 1 (hausse). Le modèle prédit \"hausse\" par défaut et la bonne performance du recall sur la classe 1 est due à sa tendance à prédire systématiquement cette classe\n",
      "# Il est particulièrement mauvais pour détecter les baisses (-1)\n",
      "# --- Markdown Cell ---\n",
      "### 4.2 Benchmark XGBoost sur les différentes stratégies d'imputation\n",
      "# --- Markdown Cell ---\n",
      "# **experiment_runner()** exécute une expérience  : charge les données, prépare les variables (avec ajout ou normalisation facultative de caractéristiques), entraîne un modèle choisi, puis évalue ses performances à l’aide de métriques détaillées. On peut choisir de calculer les features ou non, de normaliser ou non, et map et remap les catégories pour s'adapter au XGBoost\n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Comparaison des stratégies d'imputation avec XGBoost ---\")\n",
      "\n",
      "# Liste des stratégies d'imputation à tester\n",
      "imputation_strategies = [\"raw\", \"ffbf\", \"bfff\", \"interp\", \"knn\", \"mice\", \"low_nan\"]\n",
      "imputation_results = []\n",
      "\n",
      "# Tester les datasets standards (sans features ni normalisation)\n",
      "for strategy in imputation_strategies:\n",
      "    print(f\"\\nTest de {strategy} sans features ni normalisation...\")\n",
      "    try:\n",
      "        # Sans feature engineering\n",
      "        result_without_features = run_experiment(\n",
      "            dataset_key=strategy, \n",
      "            model_key=\"xgboost_baseline\", \n",
      "            add_feat=False,\n",
      "            normalize_by_row=False\n",
      "        )\n",
      "        results_tracker = add_result(results_tracker, result_without_features)\n",
      "        imputation_results.append(result_without_features)\n",
      "        print(f\"Accuracy: {result_without_features['accuracy']:.4f}\")\n",
      "    except Exception as e:\n",
      "        print(f\"Erreur lors du traitement de {strategy}: {e}\")\n",
      "\n",
      "# Tester avec normalisation par ligne\n",
      "for strategy in imputation_strategies:\n",
      "    print(f\"\\nTest de {strategy} avec normalisation par ligne...\")\n",
      "    try:\n",
      "\n",
      "        result_normalized = run_experiment(\n",
      "            dataset_key=strategy, \n",
      "            model_key=\"xgboost_baseline\", \n",
      "            add_feat=False,\n",
      "            normalize_by_row=True         # Avec normalisation par ligne\n",
      "        )\n",
      "        results_tracker = add_result(results_tracker, result_normalized)\n",
      "        imputation_results.append(result_normalized)\n",
      "        print(f\"Accuracy: {result_normalized['accuracy']:.4f}\")\n",
      "        \n",
      "        # Calculer l'amélioration due à la normalisation\n",
      "        standard_result = next((r for r in imputation_results \n",
      "                               if r['dataset'] == strategy and not r.get('normalize_by_row', False)), None)\n",
      "        if standard_result:\n",
      "            improvement = result_normalized['accuracy'] - standard_result['accuracy']\n",
      "            print(f\"Amélioration due à la normalisation: {improvement:.4f} ({improvement*100:.2f}%)\")\n",
      "    except Exception as e:\n",
      "        print(f\"Erreur lors de la normalisation de {strategy}: {e}\")\n",
      "\n",
      "#Tester les datasets avec features prétraitées\n",
      "for strategy in imputation_strategies:\n",
      "    if strategy == \"low_nan\":\n",
      "        continue  # Pas de version avec features pour low_nan\n",
      "        \n",
      "    print(f\"\\nTest de {strategy} avec features prétraitées...\")\n",
      "    try:\n",
      "        preprocessed_key = f\"{strategy}_with_features\"\n",
      "        \n",
      "        if preprocessed_key in DATASETS:\n",
      "            # Sans normalisation\n",
      "            result_with_features = run_experiment(\n",
      "                dataset_key=preprocessed_key, \n",
      "                model_key=\"xgboost_baseline\", \n",
      "                add_feat=False,         #On n'utilise pas la fonction de features puisqu'elles sont déjà calculées ici \n",
      "                normalize_by_row=False\n",
      "            )\n",
      "            results_tracker = add_result(results_tracker, result_with_features)\n",
      "            imputation_results.append(result_with_features)\n",
      "            print(f\"Accuracy avec features prétraitées: {result_with_features['accuracy']:.4f}\")\n",
      "            \n",
      "            # Avec normalisation par ligne\n",
      "            result_features_normalized = run_experiment(\n",
      "                dataset_key=preprocessed_key, \n",
      "                model_key=\"xgboost_baseline\", \n",
      "                add_feat=False,\n",
      "                normalize_by_row=True\n",
      "            )\n",
      "            results_tracker = add_result(results_tracker, result_features_normalized)\n",
      "            imputation_results.append(result_features_normalized)\n",
      "            print(f\"Accuracy avec features et normalisation: {result_features_normalized['accuracy']:.4f}\")\n",
      "            \n",
      "            # Comparer avec le dataset standard\n",
      "            standard_result = next((r for r in imputation_results \n",
      "                                   if r['dataset'] == strategy and not r.get('normalize_by_row', False)), None)\n",
      "            if standard_result:\n",
      "                improvement_features = result_with_features['accuracy'] - standard_result['accuracy']\n",
      "                print(f\"Amélioration due aux features: {improvement_features:.4f} ({improvement_features*100:.2f}%)\")\n",
      "            \n",
      "            # Comparer normalisation avec/sans features\n",
      "            improvement_norm = result_features_normalized['accuracy'] - result_with_features['accuracy']\n",
      "            print(f\"Amélioration due à la normalisation: {improvement_norm:.4f} ({improvement_norm*100:.2f}%)\")\n",
      "        else:\n",
      "            print(f\"Le dataset prétraité '{preprocessed_key}' n'existe pas dans le registre.\")\n",
      "    except Exception as e:\n",
      "        print(f\"Erreur lors du traitement de {strategy} avec features: {e}\")\n",
      "# --- Markdown Cell ---\n",
      "#### 4.3 Visualisation des résultats des benchmarks\n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Visualisation des résultats des benchmarks ---\")\n",
      "\n",
      "# Créer un DataFrame pour la visualisation\n",
      "summary_df = results_tracker[[\"dataset\", \"dataset_description\", \"model\", \"normalize_by_row\", \n",
      "                             \"features_added\", \"accuracy\", \"f1_weighted\", \"total_time\"]]\n",
      "summary_df = summary_df.sort_values(by=\"accuracy\", ascending=False)\n",
      "\n",
      "# Afficher un tableau des résultats\n",
      "print(\"Top 10 des meilleures configurations:\")\n",
      "display(summary_df.head(10))\n",
      "\n",
      "# Visualiser les résultats par dataset et normalisation\n",
      "plt.figure(figsize=(14, 8))\n",
      "summary_plot_data = summary_df.copy()\n",
      "summary_plot_data[\"dataset_norm\"] = summary_plot_data[\"dataset\"] + \\\n",
      "                                    summary_plot_data[\"normalize_by_row\"].apply(lambda x: \" (normalisé)\" if x else \"\")\n",
      "\n",
      "# Filtrer pour n'inclure que XGBoost\n",
      "xgb_data = summary_plot_data[summary_plot_data[\"model\"] == \"xgboost_baseline\"]\n",
      "\n",
      "# Barplot des résultats\n",
      "sns.barplot(x=\"dataset_norm\", y=\"accuracy\", data=xgb_data)\n",
      "plt.title('Performances de XGBoost sur différentes stratégies d\\'imputation')\n",
      "plt.xlabel('Dataset (stratégie d\\'imputation)')\n",
      "plt.ylabel('Accuracy')\n",
      "plt.xticks(rotation=45, ha=\"right\")\n",
      "plt.grid(axis='y')\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "# --- Markdown Cell ---\n",
      "# Un résultat un peu surprenant, qu'importe la transformation qu'on applique aux données, la différence est minime malgré. On remarque que les modèles avec les lignes normalisées sont quand même premier, suivi de très près par le dataset de base sans transformation. Les features initiales rajoutées n'ont pas l'air d'imapcter de manière significative non plus. \n",
      "# --- Markdown Cell ---\n",
      "#### 4.4 Régression Logistique : \n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Test avec régression logistique sur ffbf, bfff, interp ---\")\n",
      "\n",
      "# Sélectionner quelques datasets pour la comparaison\n",
      "selected_datasets = [\"ffbf\", \"bfff\", \"interp\"]\n",
      "\n",
      "for dataset_key in selected_datasets:\n",
      "    try:\n",
      "        # Test avec régression logistique\n",
      "        result = run_experiment(\n",
      "            dataset_key=dataset_key,\n",
      "            model_key=\"logistic\",\n",
      "            add_feat=True,\n",
      "            normalize_by_row=False\n",
      "        )\n",
      "        results_tracker = add_result(results_tracker, result)\n",
      "        print(f\"Régression logistique sur {dataset_key}: Accuracy = {result['accuracy']:.4f}\")\n",
      "        \n",
      "        # Comparer avec XGBoost\n",
      "        xgb_result = next((r for r in imputation_results \n",
      "                           if r['dataset'] == dataset_key and not r.get('normalize_by_row', False)), None)\n",
      "        if xgb_result:\n",
      "            diff = result['accuracy'] - xgb_result['accuracy']\n",
      "            print(f\"Différence par rapport à XGBoost: {diff:.4f} ({diff*100:.2f}%)\")\n",
      "    except Exception as e:\n",
      "        print(f\"Erreur avec logistique sur {dataset_key}: {e}\")\n",
      "# --- Markdown Cell ---\n",
      "##### Test supplémentaire avec low_nan \n",
      "# --- Markdown Cell ---\n",
      "# Après les résultats suprenants de la régression logisitque, nous décidons de tester cette dernière sur le dataset classique légèrement retouché.\n",
      "# --- Code Cell ---\n",
      "selected_datasets = [\"low_nan\"]\n",
      "\n",
      "for dataset_key in selected_datasets:\n",
      "    try:\n",
      "        # Test avec régression logistique\n",
      "        result = run_experiment(\n",
      "            dataset_key=dataset_key,\n",
      "            model_key=\"logistic\",\n",
      "            add_feat=True,\n",
      "            normalize_by_row=False\n",
      "        )\n",
      "        results_tracker = add_result(results_tracker, result)\n",
      "        print(f\"Régression logistique sur {dataset_key}: Accuracy = {result['accuracy']:.4f}\")\n",
      "        \n",
      "        # Comparer avec XGBoost\n",
      "        xgb_result = next((r for r in imputation_results \n",
      "                           if r['dataset'] == dataset_key and not r.get('normalize_by_row', False)), None)\n",
      "        if xgb_result:\n",
      "            diff = result['accuracy'] - xgb_result['accuracy']\n",
      "            print(f\"Différence par rapport à XGBoost: {diff:.4f} ({diff*100:.2f}%)\")\n",
      "    except Exception as e:\n",
      "        print(f\"Erreur avec logistique sur {dataset_key}: {e}\")\n",
      "# --- Markdown Cell ---\n",
      "# Remarques : Le résultat de la régression est assez surprenant pour au moins trois raisons. \n",
      "# \n",
      "# - 1 : L'accuracy du modèle est meilleure que celle du XGBoost\n",
      "# - 2 : Nous retrouvons l'accuracy du challenge avec un modèle différent et nous ne le retrouvons pas avec le XGBoost même, bien qu'il ne soit pas optimisé. \n",
      "# - 3 : C'est la seconde fois que nous effectuons ce test, notre second notebook. Le second notebook \"redaction.ipynb\" est disponible sur le GitHub, et malgré un code structuré différemment, le fonds est exactement le même. Nous effectuons une régression logistique via experiment_runner() qui a par défaut row_normalisation à False et add_features à True. Les paramètres sont les mêmes et pourtant nous observons une accuracy à 41,08% sur le ffbf pour 34,60% sur l'autre notebook. \n",
      "# \n",
      "# Enfin, il est important de noter que ce chiffre 41,08% n'est pas anodin. Déjà, que 3 modèles entrainés sur 4 datasets différents aient la même accuracy au centième près est étonnant, mais également, on retrouve ce chiffre dans le notebook MLP.ipynb (GitHub) pour le MLP et Encodeur. Nous n'avons pas trouvé d'explication à ce résultat, sachant que les données utilisées dans MLP.ipynb sont les données brutes (celles directement fournies par le challenge). C'est peut être un hasard, mais un hasard très précis. \n",
      "# --- Markdown Cell ---\n",
      "#### 4.5 Résumé des performances des modèles de référence\n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Résumé des performances des modèles de référence ---\")\n",
      "\n",
      "# Créer un DataFrame pour comparer les modèles\n",
      "model_comparison = summary_df[[\"model\", \"dataset\", \"normalize_by_row\", \"accuracy\", \"f1_weighted\"]]\n",
      "model_comparison = model_comparison.sort_values(by=\"accuracy\", ascending=False)\n",
      "\n",
      "# Visualiser la comparaison entre XGBoost et régression logistique\n",
      "plt.figure(figsize=(14, 8))\n",
      "sns.barplot(x=\"dataset\", y=\"accuracy\", hue=\"model\", data=model_comparison)\n",
      "plt.title('Comparaison des modèles sur différentes stratégies d\\'imputation')\n",
      "plt.xlabel('Dataset (stratégie d\\'imputation)')\n",
      "plt.ylabel('Accuracy')\n",
      "plt.xticks(rotation=45, ha=\"right\")\n",
      "plt.legend(title=\"Modèle\")\n",
      "plt.grid(axis='y')\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "# Meilleur résultat\n",
      "best_result = summary_df.iloc[0]\n",
      "print(f\"\\nMeilleur résultat:\")\n",
      "print(f\"Dataset: {best_result['dataset']} - {best_result['dataset_description']}\")\n",
      "print(f\"Modèle: {best_result['model']}\")\n",
      "print(f\"Normalisation: {best_result['normalize_by_row']}\")\n",
      "print(f\"Features ajoutées: {best_result['features_added']}\")\n",
      "print(f\"Accuracy: {best_result['accuracy']:.4f}\")\n",
      "print(f\"F1 score pondéré: {best_result['f1_weighted']:.4f}\")\n",
      "print(f\"Temps total: {best_result['total_time']:.2f}s\")\n",
      "# --- Markdown Cell ---\n",
      "## 5. Analyse approfondie et optimisation des modèles\n",
      "#  \n",
      "#  Après avoir établi des benchmarks, nous cherchons à améliorer les performances en analysant et optimisant les modèles.\n",
      "# --- Markdown Cell ---\n",
      "### 5.1 Sélection des datasets pour l'analyse approfondie \n",
      "# --- Code Cell ---\n",
      "# Identifier les 3 meilleurs datasets d'après les résultats précédents\n",
      "xgb_summary = summary_df[summary_df['model'] == 'xgboost_baseline']\n",
      "top_datasets = xgb_summary.head(3)\n",
      "\n",
      "print(\"Top 3 des meilleures configurations:\")\n",
      "display(top_datasets)\n",
      "\n",
      "# Récupérer les informations des meilleurs datasets\n",
      "best_configs = []\n",
      "for _, row in top_datasets.iterrows():\n",
      "    config = {\n",
      "        \"dataset\": row[\"dataset\"],\n",
      "        \"normalize\": row[\"normalize_by_row\"],\n",
      "        \"description\": row[\"dataset_description\"]\n",
      "    }\n",
      "    best_configs.append(config)\n",
      "# --- Markdown Cell ---\n",
      "### 5.2 Chargement et préparation des données pour l'analyse des features\n",
      "# --- Code Cell ---\n",
      "# Fonction pour charger un dataset spécifique\n",
      "from utils.data_loading import load_dataset_for_analysis\n",
      "\n",
      "# Utiliser le meilleur dataset pour l'analyse\n",
      "best_dataset = best_configs[0][\"dataset\"]\n",
      "best_normalize = best_configs[0][\"normalize\"]\n",
      "\n",
      "# Charger les données\n",
      "X_train, y_train, X_test, y_test = load_dataset_for_analysis(best_dataset, best_normalize)\n",
      "\n",
      "print(f\"Dataset sélectionné: {best_dataset} (normalize={best_normalize})\")\n",
      "print(f\"Dimensions: {X_train.shape}\")\n",
      "# --- Markdown Cell ---\n",
      "#### 5.3 Analyse en composantes principales (PCA)\n",
      "# --- Code Cell ---\n",
      "pca_results = perform_pca_analysis(dataset_key=best_dataset, sample_size=10000)\n",
      "# --- Markdown Cell ---\n",
      "# Interprétation : \n",
      "# \n",
      "# L'ACP réalisée sur rendements et features révèle plusieurs aspects de la structure des données.\n",
      "# \n",
      "# **Structure de variance**\n",
      "# \n",
      "# Le graphique de variance expliquée montre une décroissance relativement graduelle, sans rupture nette. La première composante explique environ 3,8% de la variance totale, et chacune des composantes suivantes contribue légèrement moins. Cette distribution \"en peigne\" indique qu'aucune dimension ne domine clairement la structure des données. Pour capturer 90% de la variance, il faudrait conserver environ 40 composantes (comme indiqué sur le graphique de variance cumulée), ce qui suggère une forte dimensionnalité intrinsèque des données. On ne peut pas appliquer la \"règle du coude\" dans ce cas précis.\n",
      "# \n",
      "# **Séparation des classes**\n",
      "# \n",
      "# La projection des données sur les deux premières composantes principales (Image 2) ne montre pas de séparation claire entre les trois classes (-1, 0, 1). Les points de toutes les classes se superposent fortement au centre du graphique, avec seulement quelques outliers isolés appartenant majoritairement à la classe -1 (baisse). Cette absence de séparation nette explique en partie pourquoi les modèles de classification ont des performances limitées - les rendements matinaux ne permettent pas de distinguer facilement les mouvements de prix de l'après-midi dans cet espace réduit.\n",
      "# \n",
      "# **Contribution des variables**\n",
      "# \n",
      "# L'analyse des loadings (Image 3) montre des patterns intéressants:\n",
      "# \n",
      "# **Première composante**: Fortement influencée par r10 et r11 (avec des signes opposés), ainsi que r9, ce qui suggère que cette dimension capture principalement les mouvements de prix autour de la période 10h20-10h30 (environ 50-55 minutes après l'ouverture du marché).\n",
      "# \n",
      "# **Deuxième composante**: Dominée par r48 et r45, qui correspondent aux rendements de fin de matinée, juste avant la période à prédire, ainsi que r5 avec un signe opposé. Cette composante semble donc capturer un contraste entre les mouvements de début et de fin de matinée.\n",
      "# \n",
      "# **Composantes suivantes**: Les autres composantes présentent des combinaisons plus variées de variables, avec des contributions de rendements à différents moments de la journée, sans pattern temporel évident.\n",
      "# \n",
      "# Cette structure complexe de loadings, où différentes périodes de temps contribuent à différentes composantes, suggère que les informations prédictives sont dispersées à travers plusieurs moments de la journée de trading, sans qu'une période spécifique ne soit nettement dominante.\n",
      "# Implications pour la modélisation\n",
      "# \n",
      "# Les résultats de l'ACP expliquent pourquoi la sélection de features et l'utilisation d'algorithmes d'ensemble n'améliorent que marginalement les performances prédictives. La nature intrinsèquement complexe et bruitée des données financières, combinée à l'absence de structure claire séparant les classes, rend le problème de prédiction particulièrement difficile. Une grande partie de l'information pertinente est distribuée sur de nombreuses dimensions, et la réduction dimensionnelle agressive risque d'éliminer des signaux prédictifs subtils.\n",
      "# Pour améliorer les performances, des approches qui capturent mieux les interactions non-linéaires entre variables et les dépendances temporelles pourraient être plus adaptées qu'une simple sélection de features basée sur des mesures d'importance individuelles.\n",
      "# --- Markdown Cell ---\n",
      "#### 5.4 Ajout des features financières\n",
      "# --- Code Cell ---\n",
      "# Appliquer les features financières\n",
      "X_train_with_financial = add_financial_features(X_train)\n",
      "X_test_with_financial = add_financial_features(X_test)\n",
      "\n",
      "# Afficher les nouvelles features\n",
      "new_financial_features = [col for col in X_train_with_financial.columns if col not in X_train.columns]\n",
      "print(f\"Features financières ajoutées: {len(new_financial_features)}\")\n",
      "print(\"Top 10 nouvelles features:\", ', '.join(new_financial_features[:10]))\n",
      "# --- Markdown Cell ---\n",
      "#### 5.6 Sélection des features - Approche 1: Garder tous les rendements\n",
      "# --- Markdown Cell ---\n",
      "# Pour la sélection des features, nous allons effectuer deux approches. Une première approche où l'on conserve l'ensemble des rendements et on effectue la sélection sur le reste des features et la seconde où toutes les features sont challengées. La logique derrière est d'observer si conserver l'ensemble des rendements permet de mieux prédire les mouvements de marchés. Il est possible que malgré la faible puissance d'explication de chacun des rendements pris individuellement, peut être que pris conjointement, via la corrélation, on puisse mieux expliquer les mouvements, même si cela implique de conserver plus de features et rendre les modèles plus lourds. \n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Sélection des features - Approche 1: Conserver tous les rendements ---\")\n",
      "\n",
      "# Identifier les features de rendement\n",
      "rendement_cols = [col for col in X_train.columns if col.startswith('r') and col[1:].isdigit()]\n",
      "derived_cols = [col for col in X_train_with_financial.columns if col not in rendement_cols]\n",
      "\n",
      "print(f\"Nombre de features de rendement: {len(rendement_cols)}\")\n",
      "print(f\"Nombre de features dérivées (y compris financières): {len(derived_cols)}\")\n",
      "\n",
      "# Utiliser l'information mutuelle pour sélectionner les features dérivées\n",
      "X_derived = X_train_with_financial[derived_cols]\n",
      "mi_results_derived = select_by_mutual_info(X_derived, y_train, top_n=20, plot=False)\n",
      "selected_derived_features = mi_results_derived['selected_features'][:15]  # Top 15\n",
      "\n",
      "# Afficher les features dérivées sélectionnées\n",
      "print(f\"\\nTop 15 features dérivées sélectionnées:\")\n",
      "for i, feature in enumerate(selected_derived_features):\n",
      "    print(f\"{i+1}. {feature}\")\n",
      "\n",
      "# Combiner les rendements avec les features dérivées sélectionnées\n",
      "approach1_features = rendement_cols + selected_derived_features\n",
      "print(f\"\\nApproche 1: Total de {len(approach1_features)} features ({len(rendement_cols)} rendements + {len(selected_derived_features)} dérivées)\")\n",
      "# --- Markdown Cell ---\n",
      "#### 5.7 Sélection des features - Approche 2: Sélectionner parmi toutes les features\n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Sélection des features - Approche 2: Sélectionner parmi toutes les features ---\")\n",
      "\n",
      "# Utiliser l'information mutuelle sur toutes les features\n",
      "mi_results_all = select_by_mutual_info(X_train_with_financial, y_train, top_n=30, plot=True)\n",
      "approach2_features = mi_results_all['selected_features'][:30]  # Top 30\n",
      "\n",
      "print(f\"\\nApproche 2: Total de {len(approach2_features)} features sélectionnées\")\n",
      "print(\"Top 15 features:\")\n",
      "for i, feature in enumerate(approach2_features[:15]):\n",
      "    print(f\"{i+1}. {feature}\")\n",
      "# --- Markdown Cell ---\n",
      "#### 5.8 Détermination du nombre optimal de features\n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Détermination du nombre optimal de features ---\")\n",
      "\n",
      "# Définir une factory function pour XGBoost\n",
      "def xgboost_factory():\n",
      "    \"\"\"Renvoie une nouvelle instance de XGBoost\"\"\"\n",
      "    return XGBClassifier(\n",
      "        objective=\"multi:softmax\",\n",
      "        num_class=3,\n",
      "        random_state=42\n",
      "    )\n",
      "\n",
      "# Mapping pour les étiquettes de classe\n",
      "mapping = {-1: 0, 0: 1, 1: 2}\n",
      "y_train_mapped = y_train.map(mapping)\n",
      "\n",
      "# Optimisation pour l'approche 2 (généralement plus performante)\n",
      "feature_ranking = mi_results_all['selected_features']\n",
      "print(\"\\nOptimisation du nombre de features pour l'approche 2...\")\n",
      "\n",
      "# Pour éviter d'exécuter une optimisation coûteuse, on limite le nombre d'essais\n",
      "optimization_result = optimize_feature_count(\n",
      "    X_train_with_financial, y_train_mapped,  # Utiliser les classes mappées\n",
      "    model_factory=xgboost_factory,\n",
      "    feature_ranking=feature_ranking,\n",
      "    n_features_range=range(5, min(101, len(feature_ranking)), 5)\n",
      ")\n",
      "\n",
      "# Récupérer le nombre optimal de features et les features correspondantes\n",
      "optimal_n_features = optimization_result['optimal_n_features']\n",
      "optimal_features = optimization_result['optimal_features']\n",
      "\n",
      "print(f\"\\nNombre optimal de features: {optimal_n_features}\")\n",
      "print(f\"Top 10 des features optimales:\")\n",
      "for i, feature in enumerate(optimal_features[:10]):\n",
      "    print(f\"{i+1}. {feature}\")\n",
      "\n",
      "# --- Markdown Cell ---\n",
      "#### 5.9 Optimisation des hyperparamètres de XGBoost\n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Optimisation des hyperparamètres de XGBoost ---\")\n",
      "\n",
      "# Définir la grille de paramètres pour XGBoost\n",
      "xgb_param_grid = {\n",
      "    'n_estimators': [100, 200, 300],\n",
      "    'max_depth': [3, 5, 7],\n",
      "    'learning_rate': [0.01, 0.1, 0.2],\n",
      "    'subsample': [0.5, 0.8, 1.0],\n",
      "    'colsample_bytree': [0.5, 0.8, 1.0],\n",
      "    'gamma': [0, 0.1, 0.2]\n",
      "}\n",
      "\n",
      "# Utiliser les features optimales pour l'optimisation des hyperparamètres\n",
      "X_optimal = X_train_with_financial[optimal_features]\n",
      "X_test_optimal = X_test_with_financial[optimal_features]\n",
      "\n",
      "# Optimiser XGBoost avec les classes mappées\n",
      "optimization_result = optimize_hyperparameters(\n",
      "    xgboost_factory(),\n",
      "    xgb_param_grid,\n",
      "    X_optimal,\n",
      "    y_train_mapped,  # Utiliser les classes mappées\n",
      "    n_iter=10,  # Réduit pour des raisons de temps\n",
      "    use_random=True\n",
      ")\n",
      "\n",
      "# Récupérer le meilleur modèle et ses paramètres\n",
      "best_params = optimization_result[\"best_params\"]\n",
      "best_score = optimization_result[\"best_score\"]\n",
      "\n",
      "print(f\"Meilleur score de validation croisée: {best_score:.4f}\")\n",
      "print(\"Meilleurs paramètres:\")\n",
      "for param, value in best_params.items():\n",
      "    print(f\"- {param}: {value}\")\n",
      "\n",
      "# --- Markdown Cell ---\n",
      "#### 5.9.1 Optimisation des hyperparamètres de XGBoost sur les données brutes\n",
      "# --- Markdown Cell ---\n",
      "# Cette étape est une étape de test afin de regarder si l'optimisation du modèle sans features, donc seulement avec les rendements et day, equity permettent de mieux prédire\n",
      "# --- Code Cell ---\n",
      "raw_dataset_key = \"raw\" \n",
      "print(f\"Utilisation du dataset {raw_dataset_key} pour la comparaison\")\n",
      "\n",
      "# Charger les données brutes\n",
      "X_raw_train, y_raw_train, X_raw_test, y_raw_test = load_dataset_for_analysis(raw_dataset_key, normalize=best_normalize)\n",
      "\n",
      "# Mapping pour les étiquettes de classe\n",
      "mapping = {-1: 0, 0: 1, 1: 2}\n",
      "inverse_mapping = {0: -1, 1: 0, 2: 1}\n",
      "y_raw_train_mapped = y_raw_train.map(mapping)\n",
      "\n",
      "# Optimiser XGBoost avec les classes mappées sur le dataset brut\n",
      "raw_optimization_result = optimize_hyperparameters(\n",
      "    xgboost_factory(),\n",
      "    xgb_param_grid,\n",
      "    X_raw_train,\n",
      "    y_raw_train_mapped,  # Utiliser les classes mappées\n",
      "    n_iter=10,  # Réduit pour des raisons de temps\n",
      "    use_random=True\n",
      ")\n",
      "\n",
      "# Récupérer le meilleur modèle et ses paramètres\n",
      "raw_best_params = raw_optimization_result[\"best_params\"]\n",
      "raw_best_score = raw_optimization_result[\"best_score\"]\n",
      "\n",
      "print(f\"Meilleur score de validation croisée sur dataset {raw_dataset_key}: {raw_best_score:.4f}\")\n",
      "print(f\"Meilleurs paramètres sur dataset {raw_dataset_key}:\")\n",
      "for param, value in raw_best_params.items():\n",
      "    print(f\"- {param}: {value}\")\n",
      "\n",
      "# Créer le modèle XGBoost optimisé sur dataset brut\n",
      "raw_optimized_model = XGBClassifier(\n",
      "    objective=\"multi:softmax\",\n",
      "    num_class=3,\n",
      "    random_state=42,\n",
      "    **raw_best_params\n",
      ")\n",
      "\n",
      "# Entraîner le modèle\n",
      "start_train_time = time.time()\n",
      "raw_optimized_model.fit(X_raw_train, y_raw_train_mapped)  # Utiliser les classes mappées\n",
      "raw_train_time = time.time() - start_train_time\n",
      "\n",
      "# Faire des prédictions\n",
      "start_pred_time = time.time()\n",
      "raw_y_pred_mapped = raw_optimized_model.predict(X_raw_test)\n",
      "raw_pred_time = time.time() - start_pred_time\n",
      "\n",
      "# Reconvertir les prédictions au format original\n",
      "raw_y_pred = pd.Series(raw_y_pred_mapped).map(inverse_mapping)\n",
      "\n",
      "# Évaluer les performances\n",
      "raw_accuracy = accuracy_score(y_raw_test, raw_y_pred)\n",
      "raw_report = classification_report(y_raw_test, raw_y_pred, output_dict=True)\n",
      "\n",
      "print(f\"\\nAccuracy du modèle optimisé sur dataset {raw_dataset_key}: {raw_accuracy:.4f}\")\n",
      "print(f\"F1 score pondéré: {raw_report['weighted avg']['f1-score']:.4f}\")\n",
      "print(f\"Temps d'entraînement: {raw_train_time:.2f}s, Prédiction: {raw_pred_time:.2f}s\")\n",
      "\n",
      "# Ajouter au tracker de résultats\n",
      "raw_result = {\n",
      "    \"dataset\": raw_dataset_key,\n",
      "    \"dataset_description\": f\"Dataset {raw_dataset_key} avec hyperparamètres optimisés\",\n",
      "    \"model\": \"xgboost_raw_optimized\",\n",
      "    \"model_description\": f\"XGBoost optimisé sur dataset {raw_dataset_key}\",\n",
      "    \"features_added\": False,\n",
      "    \"feature_sets\": [\"Aucune\"],\n",
      "    \"normalize_by_row\": best_normalize,\n",
      "    \"accuracy\": raw_accuracy,\n",
      "    \"precision_weighted\": raw_report[\"weighted avg\"][\"precision\"],\n",
      "    \"recall_weighted\": raw_report[\"weighted avg\"][\"recall\"],\n",
      "    \"f1_weighted\": raw_report[\"weighted avg\"][\"f1-score\"],\n",
      "    \"training_time\": raw_train_time,\n",
      "    \"prediction_time\": raw_pred_time,\n",
      "    \"total_time\": raw_train_time + raw_pred_time,\n",
      "    \"notes\": f\"XGBoost optimisé sur le dataset {raw_dataset_key} brut\"\n",
      "}\n",
      "\n",
      "results_tracker = add_result(results_tracker, raw_result)\n",
      "# --- Markdown Cell ---\n",
      "# Accuracy non optimisée : 0.316347\n",
      "# \n",
      "# Accuracy optimisée : 0.3111\n",
      "# --- Markdown Cell ---\n",
      "####  5.10 Évaluation du modèle XGBoost optimisé (Avec Features)\n",
      "# --- Code Cell ---\n",
      "# Créer le modèle XGBoost optimisé\n",
      "optimized_model = XGBClassifier(\n",
      "    objective=\"multi:softmax\",\n",
      "    num_class=3,\n",
      "    random_state=42,\n",
      "    **best_params\n",
      ")\n",
      "\n",
      "# Définir le mapping pour les classes\n",
      "mapping = {-1: 0, 0: 1, 1: 2}\n",
      "inverse_mapping = {0: -1, 1: 0, 2: 1}\n",
      "y_train_mapped = y_train.map(mapping)\n",
      "\n",
      "# Entraîner le modèle\n",
      "start_train_time = time.time()\n",
      "optimized_model.fit(X_optimal, y_train_mapped)  # Utiliser les classes mappées\n",
      "train_time = time.time() - start_train_time\n",
      "\n",
      "# Faire des prédictions\n",
      "start_pred_time = time.time()\n",
      "y_pred_mapped = optimized_model.predict(X_test_optimal)\n",
      "pred_time = time.time() - start_pred_time\n",
      "\n",
      "# Reconvertir les prédictions au format original\n",
      "y_pred = pd.Series(y_pred_mapped).map(inverse_mapping)\n",
      "\n",
      "# Évaluer les performances\n",
      "accuracy = accuracy_score(y_test, y_pred)\n",
      "report = classification_report(y_test, y_pred, output_dict=True)\n",
      "\n",
      "print(f\"Accuracy sur l'ensemble de test: {accuracy:.4f}\")\n",
      "print(f\"F1 score pondéré: {report['weighted avg']['f1-score']:.4f}\")\n",
      "print(f\"Temps d'entraînement: {train_time:.2f}s, Prédiction: {pred_time:.2f}s\")\n",
      "\n",
      "# Ajouter au tracker de résultats\n",
      "result = {\n",
      "    \"dataset\": best_dataset,\n",
      "    \"dataset_description\": f\"{best_configs[0]['description']} avec features optimisées\",\n",
      "    \"model\": \"xgboost_optimized\",\n",
      "    \"model_description\": f\"XGBoost optimisé avec {len(optimal_features)} features\",\n",
      "    \"features_added\": True,\n",
      "    \"feature_sets\": [\"Optimisées\"],\n",
      "    \"normalize_by_row\": best_normalize,\n",
      "    \"accuracy\": accuracy,\n",
      "    \"precision_weighted\": report[\"weighted avg\"][\"precision\"],\n",
      "    \"recall_weighted\": report[\"weighted avg\"][\"recall\"],\n",
      "    \"f1_weighted\": report[\"weighted avg\"][\"f1-score\"],\n",
      "    \"training_time\": train_time,\n",
      "    \"prediction_time\": pred_time,\n",
      "    \"total_time\": train_time + pred_time,\n",
      "    \"notes\": f\"Optimisé avec {optimal_n_features} features et hyperparamètres\"\n",
      "}\n",
      "\n",
      "results_tracker = add_result(results_tracker, result)\n",
      "\n",
      "# Matrice de confusion\n",
      "plt.figure(figsize=(8, 6))\n",
      "conf_matrix = confusion_matrix(y_test, y_pred)\n",
      "sns.heatmap(conf_matrix, annot=True, fmt='d', cmap='Blues',\n",
      "           xticklabels=[-1, 0, 1], yticklabels=[-1, 0, 1])\n",
      "plt.title('Matrice de Confusion - XGBoost Optimisé')\n",
      "plt.xlabel('Prédiction')\n",
      "plt.ylabel('Valeur Réelle')\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "# --- Markdown Cell ---\n",
      "#### 5.11 Analyse SHAP pour interpréter le modèle\n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Analyse SHAP pour l'interprétation du modèle ---\")\n",
      "\n",
      "try:\n",
      "    # Import shap if available\n",
      "    import shap\n",
      "    \n",
      "    # Réduire l'échantillon pour l'analyse SHAP\n",
      "    sample_size = min(500, len(X_optimal))\n",
      "    X_train_sample = X_optimal.sample(sample_size, random_state=42)\n",
      "    \n",
      "    # Analyser le modèle avec SHAP\n",
      "    shap_values, explainer = analyze_with_shap(optimized_model, X_train_sample)\n",
      "    \n",
      "    if shap_values is not None:\n",
      "        # Visualiser le résumé des valeurs SHAP (Bar Plot)\n",
      "        plot_shap_summary(shap_values, X_train_sample, plot_type=\"bar\")\n",
      "        \n",
      "        # Visualiser l'impact détaillé des features (Dot Plot)\n",
      "        plot_shap_summary(shap_values, X_train_sample, plot_type=\"dot\")\n",
      "        \n",
      "        print(\"Analyse SHAP complétée avec succès\")\n",
      "    else:\n",
      "        print(\"Impossible de calculer les valeurs SHAP\")\n",
      "        \n",
      "except ImportError:\n",
      "    print(\"La bibliothèque SHAP n'est pas installée. Utilisez 'pip install shap' pour l'installer.\")\n",
      "except Exception as e:\n",
      "    print(f\"Erreur lors de l'analyse SHAP: {e}\")\n",
      "# --- Markdown Cell ---\n",
      "#### 5.12 Comparaison avec le modèle de référence\n",
      "# --- Code Cell ---\n",
      "# 5.12 Comparaison avec les modèles de référence\n",
      "print(\"\\n--- Comparaison avec les modèles de référence ---\")\n",
      "\n",
      "# Récupérer les performances du modèle de référence baseline\n",
      "benchmark_model = next((r for r in results_tracker.to_dict('records') \n",
      "                        if r['dataset'] == best_dataset and \n",
      "                        r['model'] == 'xgboost_baseline' and \n",
      "                        r['normalize_by_row'] == best_normalize), None)\n",
      "\n",
      "# Récupérer les performances du modèle optimisé sur données brutes\n",
      "raw_optimized_model = next((r for r in results_tracker.to_dict('records') \n",
      "                           if r['dataset'] == raw_dataset_key and \n",
      "                           r['model'] == 'xgboost_raw_optimized' and \n",
      "                           r['normalize_by_row'] == best_normalize), None)\n",
      "\n",
      "if benchmark_model and raw_optimized_model:\n",
      "    benchmark_accuracy = benchmark_model[\"accuracy\"]\n",
      "    raw_opt_accuracy = raw_optimized_model[\"accuracy\"]\n",
      "    \n",
      "    improvement_features = accuracy - benchmark_accuracy\n",
      "    improvement_raw = raw_opt_accuracy - benchmark_accuracy\n",
      "    \n",
      "    print(f\"Modèle de référence (XGBoost baseline): Accuracy = {benchmark_accuracy:.4f}\")\n",
      "    print(f\"Modèle optimisé sur données brutes ({raw_dataset_key}): Accuracy = {raw_opt_accuracy:.4f}\")\n",
      "    print(f\"Modèle optimisé avec sélection de features: Accuracy = {accuracy:.4f}\")\n",
      "    print(f\"Amélioration avec sélection de features: {improvement_features:.4f} ({improvement_features*100:.2f}%)\")\n",
      "    print(f\"Amélioration avec optimisation sur données brutes: {improvement_raw:.4f} ({improvement_raw*100:.2f}%)\")\n",
      "    \n",
      "    # Visualiser la comparaison avec un graphique amélioré\n",
      "    plt.figure(figsize=(10, 6))\n",
      "    comparison_data = pd.DataFrame([\n",
      "        {\"Modèle\": \"XGBoost baseline\", \"Accuracy\": benchmark_accuracy},\n",
      "        {\"Modèle\": f\"XGBoost optimisé\\nsur dataset {raw_dataset_key}\", \"Accuracy\": raw_opt_accuracy},\n",
      "        {\"Modèle\": f\"XGBoost optimisé\\navec {optimal_n_features} features\", \"Accuracy\": accuracy}\n",
      "    ])\n",
      "    \n",
      "    # Créer le barplot avec bordures distinctes\n",
      "    ax = sns.barplot(x=\"Modèle\", y=\"Accuracy\", data=comparison_data, palette=\"Blues_d\")\n",
      "    \n",
      "    # Ajouter une ligne horizontale à l'accuracy du modèle de référence\n",
      "    plt.axhline(y=benchmark_accuracy, color='gray', linestyle='--', alpha=0.7)\n",
      "    \n",
      "    # Ajouter les valeurs sur les barres\n",
      "    for i, row in comparison_data.iterrows():\n",
      "        plt.text(i, row[\"Accuracy\"] + 0.002, f\"{row['Accuracy']:.4f}\", \n",
      "                ha='center', va='bottom', fontweight='bold')\n",
      "    \n",
      "    # Améliorer la présentation du graphique\n",
      "    plt.title('Comparaison des performances des modèles XGBoost', fontsize=14)\n",
      "    plt.xlabel('Modèle', fontsize=12)\n",
      "    plt.ylabel('Accuracy', fontsize=12)\n",
      "    # Définir des limites raisonnables pour l'axe y\n",
      "    min_accuracy = min(benchmark_accuracy, accuracy, raw_opt_accuracy) - 0.01\n",
      "    max_accuracy = max(benchmark_accuracy, accuracy, raw_opt_accuracy) + 0.01\n",
      "    plt.ylim(min_accuracy, max_accuracy)\n",
      "    plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
      "    \n",
      "    plt.tight_layout()\n",
      "    plt.show()\n",
      "else:\n",
      "    print(\"Impossible de trouver un modèle de référence comparable pour la comparaison.\")\n",
      "# --- Markdown Cell ---\n",
      "##### Analyse des résultats de la modélisation prédictive des rendements financiers\n",
      "# \n",
      "# **Sélection de features et importance des variables**\n",
      "# \n",
      "# L'analyse de sélection des features a révélé plusieurs insights importants :\n",
      "# \n",
      "# **Prédominance des variables catégorielles** : Les variables day et equity se démarquent nettement comme les plus informatives (scores d'information mutuelle respectifs de 0.12 et 0.03), loin devant toutes les autres features qui ont des scores inférieurs à 0.004 avec une forte dominance temporelle. Cette prépondérance suggère que les caractéristiques temporelles et les spécificités des actions individuelles influencent fortement le comportement des rendements.\n",
      "# \n",
      "# **Importance des métriques agrégées** : Les ratios de tendance (pos_ratio, neg_ratio) et les indicateurs dérivés comme le momentum et le sharpe_ratio se classent parmi les features les plus importantes, avant même les rendements individuels. Ce résultat n'est pas surprenant mais cela n'implique pas réellement qu'ils permettent de mieux prédire pour autant puisque le XGBoost sans features obtient un meilleur score.\n",
      "# \n",
      "# **Analyse SHAP et interprétabilité**\n",
      "# \n",
      "# L'analyse SHAP confirme et complète les observations précédentes :\n",
      "# \n",
      "# ***Confirmation de l'importance des variables contextuelles*** : La variable **day** domine largement les autres en termes d'impact sur les prédictions, suivie par equity. Cela renforce l'hypothèse que le contexte temporel et les caractéristiques propres à chaque action sont des déterminants majeurs.\n",
      "# \n",
      "# Différenciation par classe : Les variables ont des impacts différents selon les classes de prédiction (baisse, stable, hausse), comme le montre la répartition des couleurs sur le graphique SHAP. Par exemple, certaines features semblent spécifiquement importantes pour prédire la classe 1 (hausse).\n",
      "# \n",
      "# Distribution des effets : Le graphique SHAP en points montre une distribution complexe des effets des features, avec des patterns distinctifs pour les principales variables. Ceci révèle des relations non-linéaires entre les variables et les prédictions.\n",
      "# \n",
      "# **Surapprentissage et performances des modèles**\n",
      "# \n",
      "# Le problème le plus significatif observé est l'écart important entre les performances en validation croisée et sur l'ensemble de test :\n",
      "# \n",
      "# **Écart validation/test important** : Les scores de validation croisée atteignent 0.48 alors que les performances sur l'ensemble de test plafonnent autour de 0.31, indiquant un surapprentissage prononcé.\n",
      "# \n",
      "# Dégradation avec l'optimisation : Contre-intuitivement, l'optimisation des hyperparamètres et la sélection de features n'améliorent pas les performances sur l'ensemble de test, mais les dégradent légèrement (baseline : 0.3185, optimisé : 0.3132, raw optimisé : 0.3111).\n",
      "# \n",
      "# Causes probables :\n",
      "# \n",
      "# La séparation stricte entre les jours et actions des ensembles d'entraînement et de test crée un défi de généralisation majeur\n",
      "# Les hyperparamètres optimisés (max_depth=7, n_estimators=300) favorisent potentiellement la mémorisation des données d'entraînement\n",
      "# L'utilisation excessive des variables day et equity pourrait empêcher le modèle d'apprendre des patterns généralisables\n",
      "# \n",
      "# \n",
      "# Cette analyse suggère plusieurs pistes d'amélioration :\n",
      "# \n",
      "# Réduction de la complexité des modèles : Limiter la profondeur des arbres et augmenter la régularisation pourrait aider à réduire le surapprentissage.\n",
      "# Approaches alternatives de feature engineering :\n",
      "# \n",
      "# Créer des features plus généralisables qui capturent des patterns indépendants du jour ou de l'action spécifique\n",
      "# Explorer des transformations temporelles relatives plutôt qu'absolues\n",
      "# Considérer des variables macroéconomiques ou sectorielles pour enrichir le contexte\n",
      "# \n",
      "# \n",
      "# **Stratégies d'entraînement adaptées :**\n",
      "# \n",
      "# Implémenter une validation temporelle plus représentative du problème réel\n",
      "# Explorer des approches d'ensemble combinant différents niveaux de complexité\n",
      "# Tester l'apprentissage par transfert pour mieux généraliser entre différentes actions\n",
      "# \n",
      "# En conclusion, ce cas illustre parfaitement les défis inhérents à la prédiction financière : la non-stationnarité des données, la difficulté de généralisation entre différents instruments et périodes, et la propension des modèles à capturer du bruit plutôt que du signal. Ces résultats, bien que modestes en termes de performance prédictive, offrent néanmoins des insights précieux sur les limites des approches d'apprentissage automatique dans ce domaine.\n",
      "# --- Markdown Cell ---\n",
      "#### Analyse supplémentaire sans Equity & Day et Top Features \n",
      "# --- Markdown Cell ---\n",
      "# On a choisi d'effectuer un dernier test, cette fois-ci on conserve le dataframe de base (raw) avec des lignes contenant seulement 70%+ de non NaN mais en retirant la composante temporelle et equity afin que le modèle apprennne seulement des relations des rendements et des rendements avec les top features. \n",
      "# --- Code Cell ---\n",
      "import sys \n",
      "import importlib\n",
      "\n",
      "if \"utils.data_loading\" in sys.modules:\n",
      "    del sys.modules[\"utils.data_loading\"]\n",
      "    \n",
      "from utils.data_loading import load_dataset_for_analysis, load_datasets, load_dataset_without_day_id, select_financial_and_rendements, select_optimized_features_no_day_equity\n",
      "\n",
      "# --- Code Cell ---\n",
      "# Charger les données sans day et equity\n",
      "raw_dataset_key = \"low_nan\"  \n",
      "print(f\"\\n--- Test du modèle sans day et equity sur dataset {raw_dataset_key} ---\")\n",
      "X_raw_train_no_day, y_raw_train, X_raw_test_no_day, y_raw_test = load_dataset_without_day_id(raw_dataset_key, normalize=best_normalize)\n",
      "\n",
      "# Mapping pour les étiquettes de classe\n",
      "mapping = {-1: 0, 0: 1, 1: 2}\n",
      "inverse_mapping = {0: -1, 1: 0, 2: 1}\n",
      "y_raw_train_mapped = y_raw_train.map(mapping)\n",
      "\n",
      "# Optimiser XGBoost sans day ni equity\n",
      "no_day_optimization_result = optimize_hyperparameters(\n",
      "    xgboost_factory(),\n",
      "    xgb_param_grid,\n",
      "    X_raw_train_no_day,\n",
      "    y_raw_train_mapped,\n",
      "    n_iter=10,\n",
      "    use_random=True\n",
      ")\n",
      "\n",
      "# Récupérer le meilleur modèle et ses paramètres\n",
      "no_day_best_params = no_day_optimization_result[\"best_params\"]\n",
      "no_day_best_score = no_day_optimization_result[\"best_score\"]\n",
      "\n",
      "print(f\"Meilleur score de validation croisée (sans day ni equity): {no_day_best_score:.4f}\")\n",
      "print(f\"Meilleurs paramètres:\")\n",
      "for param, value in no_day_best_params.items():\n",
      "    print(f\"- {param}: {value}\")\n",
      "\n",
      "# Créer et entraîner le modèle\n",
      "no_day_model = XGBClassifier(\n",
      "    objective=\"multi:softmax\",\n",
      "    num_class=3,\n",
      "    random_state=42,\n",
      "    **no_day_best_params\n",
      ")\n",
      "\n",
      "start_train_time = time.time()\n",
      "no_day_model.fit(X_raw_train_no_day, y_raw_train_mapped)\n",
      "no_day_train_time = time.time() - start_train_time\n",
      "\n",
      "# Faire des prédictions\n",
      "start_pred_time = time.time()\n",
      "no_day_y_pred_mapped = no_day_model.predict(X_raw_test_no_day)\n",
      "no_day_pred_time = time.time() - start_pred_time\n",
      "\n",
      "# Reconvertir les prédictions\n",
      "no_day_y_pred = pd.Series(no_day_y_pred_mapped).map(inverse_mapping)\n",
      "\n",
      "# Évaluer les performances\n",
      "no_day_accuracy = accuracy_score(y_raw_test, no_day_y_pred)\n",
      "no_day_report = classification_report(y_raw_test, no_day_y_pred, output_dict=True)\n",
      "\n",
      "print(f\"\\nAccuracy du modèle sans day ni ID: {no_day_accuracy:.4f}\")\n",
      "print(f\"F1 score pondéré: {no_day_report['weighted avg']['f1-score']:.4f}\")\n",
      "print(f\"Temps d'entraînement: {no_day_train_time:.2f}s, Prédiction: {no_day_pred_time:.2f}s\")\n",
      "\n",
      "# Ajouter au tracker de résultats\n",
      "no_day_result = {\n",
      "    \"dataset\": raw_dataset_key,\n",
      "    \"dataset_description\": f\"Dataset {raw_dataset_key} sans day ni equity\",\n",
      "    \"model\": \"xgboost_no_day_id\",\n",
      "    \"model_description\": \"XGBoost optimisé sans day ni ID\",\n",
      "    \"features_added\": False,\n",
      "    \"feature_sets\": [\"Sans day/ID\"],\n",
      "    \"normalize_by_row\": best_normalize,\n",
      "    \"accuracy\": no_day_accuracy,\n",
      "    \"precision_weighted\": no_day_report[\"weighted avg\"][\"precision\"],\n",
      "    \"recall_weighted\": no_day_report[\"weighted avg\"][\"recall\"],\n",
      "    \"f1_weighted\": no_day_report[\"weighted avg\"][\"f1-score\"],\n",
      "    \"training_time\": no_day_train_time,\n",
      "    \"prediction_time\": no_day_pred_time,\n",
      "    \"total_time\": no_day_train_time + no_day_pred_time,\n",
      "    \"notes\": \"XGBoost sans variables contextuelles day et equity\"\n",
      "}\n",
      "\n",
      "results_tracker = add_result(results_tracker, no_day_result)\n",
      "# --- Code Cell ---\n",
      "# Charger les données\n",
      "raw_dataset_key = \"raw\"\n",
      "print(f\"\\n--- Test du modèle avec rendements + features financières sur dataset {raw_dataset_key} ---\")\n",
      "X_raw_train_full, y_raw_train, X_raw_test_full, y_raw_test = load_dataset_for_analysis(raw_dataset_key, normalize=best_normalize)\n",
      "\n",
      "# Ajouter les features financières\n",
      "X_raw_train_with_financial = add_financial_features(X_raw_train_full)\n",
      "X_raw_test_with_financial = add_financial_features(X_raw_test_full)\n",
      "\n",
      "# Sélectionner les features pertinentes\n",
      "X_raw_train_selected, X_raw_test_selected = select_financial_and_rendements(\n",
      "    X_raw_train_with_financial, \n",
      "    X_raw_test_with_financial\n",
      ")\n",
      "\n",
      "# Mapping pour les étiquettes de classe\n",
      "mapping = {-1: 0, 0: 1, 1: 2}\n",
      "inverse_mapping = {0: -1, 1: 0, 2: 1}\n",
      "y_raw_train_mapped = y_raw_train.map(mapping)\n",
      "\n",
      "# Optimiser XGBoost avec les features sélectionnées\n",
      "fin_features_optimization_result = optimize_hyperparameters(\n",
      "    xgboost_factory(),\n",
      "    xgb_param_grid,\n",
      "    X_raw_train_selected,\n",
      "    y_raw_train_mapped,\n",
      "    n_iter=10,\n",
      "    use_random=True\n",
      ")\n",
      "\n",
      "# Récupérer le meilleur modèle et ses paramètres\n",
      "fin_features_best_params = fin_features_optimization_result[\"best_params\"]\n",
      "fin_features_best_score = fin_features_optimization_result[\"best_score\"]\n",
      "\n",
      "print(f\"Meilleur score de validation croisée (features financières): {fin_features_best_score:.4f}\")\n",
      "print(f\"Meilleurs paramètres:\")\n",
      "for param, value in fin_features_best_params.items():\n",
      "    print(f\"- {param}: {value}\")\n",
      "\n",
      "# Créer et entraîner le modèle\n",
      "fin_features_model = XGBClassifier(\n",
      "    objective=\"multi:softmax\",\n",
      "    num_class=3,\n",
      "    random_state=42,\n",
      "    **fin_features_best_params\n",
      ")\n",
      "\n",
      "start_train_time = time.time()\n",
      "fin_features_model.fit(X_raw_train_selected, y_raw_train_mapped)\n",
      "fin_features_train_time = time.time() - start_train_time\n",
      "\n",
      "# Faire des prédictions\n",
      "start_pred_time = time.time()\n",
      "fin_features_y_pred_mapped = fin_features_model.predict(X_raw_test_selected)\n",
      "fin_features_pred_time = time.time() - start_pred_time\n",
      "\n",
      "# Reconvertir les prédictions\n",
      "fin_features_y_pred = pd.Series(fin_features_y_pred_mapped).map(inverse_mapping)\n",
      "\n",
      "# Évaluer les performances\n",
      "fin_features_accuracy = accuracy_score(y_raw_test, fin_features_y_pred)\n",
      "fin_features_report = classification_report(y_raw_test, fin_features_y_pred, output_dict=True)\n",
      "\n",
      "print(f\"\\nAccuracy du modèle avec features financières: {fin_features_accuracy:.4f}\")\n",
      "print(f\"F1 score pondéré: {fin_features_report['weighted avg']['f1-score']:.4f}\")\n",
      "print(f\"Temps d'entraînement: {fin_features_train_time:.2f}s, Prédiction: {fin_features_pred_time:.2f}s\")\n",
      "\n",
      "# Visualiser l'importance des features\n",
      "plt.figure(figsize=(12, 8))\n",
      "features_importance = fin_features_model.feature_importances_\n",
      "importance_df = pd.DataFrame({\n",
      "    'Feature': X_raw_train_selected.columns,\n",
      "    'Importance': features_importance\n",
      "}).sort_values('Importance', ascending=False)\n",
      "\n",
      "sns.barplot(x='Importance', y='Feature', data=importance_df.head(15))\n",
      "plt.title('Top 15 features importantes - Modèle avec features financières')\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "# Ajouter au tracker de résultats\n",
      "fin_features_result = {\n",
      "    \"dataset\": raw_dataset_key,\n",
      "    \"dataset_description\": f\"Dataset {raw_dataset_key} avec features financières\",\n",
      "    \"model\": \"xgboost_financial_features\",\n",
      "    \"model_description\": \"XGBoost optimisé avec rendements et features financières\",\n",
      "    \"features_added\": True,\n",
      "    \"feature_sets\": [\"Rendements + Financières\"],\n",
      "    \"normalize_by_row\": best_normalize,\n",
      "    \"accuracy\": fin_features_accuracy,\n",
      "    \"precision_weighted\": fin_features_report[\"weighted avg\"][\"precision\"],\n",
      "    \"recall_weighted\": fin_features_report[\"weighted avg\"][\"recall\"],\n",
      "    \"f1_weighted\": fin_features_report[\"weighted avg\"][\"f1-score\"],\n",
      "    \"training_time\": fin_features_train_time,\n",
      "    \"prediction_time\": fin_features_pred_time,\n",
      "    \"total_time\": fin_features_train_time + fin_features_pred_time,\n",
      "    \"notes\": \"XGBoost avec rendements et features financières sélectionnées\"\n",
      "}\n",
      "\n",
      "results_tracker = add_result(results_tracker, fin_features_result)\n",
      "# --- Code Cell ---\n",
      "# Comparaison des différentes approches\n",
      "print(\"\\n--- Comparaison des différentes approches de modélisation ---\")\n",
      "\n",
      "# Sélectionner les modèles pertinents pour la comparaison\n",
      "comparison_models = [\n",
      "    {\"model\": \"xgboost_baseline\", \"name\": \"XGBoost Baseline\", \"description\": \"Modèle de base avec toutes les features\"},\n",
      "    {\"model\": \"xgboost_raw_optimized\", \"name\": \"XGBoost Raw Optimisé\", \"description\": \"Modèle optimisé sur dataset brut\"},\n",
      "    {\"model\": \"xgboost_optimized\", \"name\": \"XGBoost Features Optimisées\", \"description\": \"Modèle avec 20 features optimales\"},\n",
      "    {\"model\": \"xgboost_no_day_id\", \"name\": \"XGBoost Sans Day/ID\", \"description\": \"Modèle sans day ni ID\"},\n",
      "    {\"model\": \"xgboost_financial_features\", \"name\": \"XGBoost Features Financières\", \"description\": \"Modèle avec rendements et features financières\"}\n",
      "]\n",
      "\n",
      "# Extraire les résultats correspondants\n",
      "comparison_results = []\n",
      "for model_info in comparison_models:\n",
      "    model_key = model_info[\"model\"]\n",
      "    # Chercher le modèle dans les résultats\n",
      "    model_result = next((r for r in results_tracker.to_dict('records') if r['model'] == model_key), None)\n",
      "    if model_result:\n",
      "        comparison_results.append({\n",
      "            \"Modèle\": model_info[\"name\"],\n",
      "            \"Description\": model_info[\"description\"],\n",
      "            \"Accuracy\": model_result[\"accuracy\"],\n",
      "            \"F1 Score\": model_result[\"f1_weighted\"],\n",
      "            \"Temps total (s)\": model_result[\"total_time\"] if \"total_time\" in model_result else None\n",
      "        })\n",
      "\n",
      "# Créer un DataFrame pour la comparaison\n",
      "comparison_df = pd.DataFrame(comparison_results)\n",
      "comparison_df = comparison_df.sort_values(\"Accuracy\", ascending=False)\n",
      "\n",
      "print(\"Résultats de performance:\")\n",
      "display(comparison_df)\n",
      "\n",
      "# Visualiser la comparaison\n",
      "plt.figure(figsize=(12, 6))\n",
      "sns.barplot(x=\"Modèle\", y=\"Accuracy\", data=comparison_df)\n",
      "plt.title('Comparaison des performances des modèles')\n",
      "plt.xlabel('Modèle')\n",
      "plt.ylabel('Accuracy')\n",
      "plt.xticks(rotation=45, ha=\"right\")\n",
      "plt.grid(axis='y')\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "# Visualiser la comparaison des temps d'exécution\n",
      "plt.figure(figsize=(12, 6))\n",
      "sns.barplot(x=\"Modèle\", y=\"Temps total (s)\", data=comparison_df)\n",
      "plt.title('Comparaison des temps d\\'exécution')\n",
      "plt.xlabel('Modèle')\n",
      "plt.ylabel('Temps total (secondes)')\n",
      "plt.xticks(rotation=45, ha=\"right\")\n",
      "plt.grid(axis='y')\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "print(\"\\n--- Analyse des performances en fonction des approches de modélisation ---\")\n",
      "print(f\"Meilleur modèle: {comparison_df.iloc[0]['Modèle']} avec une accuracy de {comparison_df.iloc[0]['Accuracy']:.4f}\")\n",
      "\n",
      "baseline_accuracy = next((r['Accuracy'] for r in comparison_results if r['Modèle'] == \"XGBoost Baseline\"), None)\n",
      "if baseline_accuracy:\n",
      "    for i, row in comparison_df.iterrows():\n",
      "        if row['Modèle'] != \"XGBoost Baseline\":\n",
      "            diff = row['Accuracy'] - baseline_accuracy\n",
      "            print(f\"{row['Modèle']}: {diff:.4f} ({diff*100:.2f}% par rapport à la baseline)\")\n",
      "\n",
      "\n",
      "# --- Markdown Cell ---\n",
      "# Le fait de retirer la composante temporelle a permis au modèle de contrôler le sur-apprentissage et mieux s'adapter à de nouvelles données, même sans l'utilisation de nouvelles features. \n",
      "# \n",
      "# Il est important de souligner qu'avec l'analyse avec les features financières et des rendements qu'on observe que les features les plus importantes sont les rendements de fin de journée et que ces dernières ont plus de poids explicatif que des métriques agrégées. Cependant, il reste assez important de souligner, que la création de features, dans le cas du XGBoost, n'améliore pas, voire dégrade les performances du modèle. \n",
      "# \n",
      "# Nous conserverons quand même les features par la suite. \n",
      "# --- Markdown Cell ---\n",
      "## 6. Modèles non supervisés\n",
      "# \n",
      "# Explorons maintenant des approches non supervisées pour améliorer la classification.\n",
      "# --- Markdown Cell ---\n",
      "###  6.1 Préparation des données\n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Préparation des données pour les modèles non supervisés ---\")\n",
      "\n",
      "# Charger les données\n",
      "raw_dataset_key = \"raw\"\n",
      "X_raw_train_full, y_raw_train, X_raw_test_full, y_raw_test = load_dataset_for_analysis(raw_dataset_key, normalize=best_normalize)\n",
      "\n",
      "# Sélectionner les features optimisées sans day ni equity\n",
      "X_optimized, X_test_optimized = select_optimized_features_no_day_equity(X_raw_train_full, X_raw_test_full)\n",
      "\n",
      "# --- Markdown Cell ---\n",
      "### 6.2 Préparation des deux approches de clustering\n",
      "# --- Code Cell ---\n",
      "# Normaliser les données\n",
      "scaler = StandardScaler()\n",
      "X_optimized_scaled = scaler.fit_transform(X_optimized)\n",
      "X_test_optimized_scaled = scaler.transform(X_test_optimized)\n",
      "\n",
      "# PCA\n",
      "n_components = min(15, X_optimized.shape[1])\n",
      "pca = PCA(n_components=n_components)\n",
      "X_pca = pca.fit_transform(X_optimized_scaled)\n",
      "X_test_pca = pca.transform(X_test_optimized_scaled)\n",
      "\n",
      "# Analyser la variance expliquée\n",
      "explained_variance = pca.explained_variance_ratio_\n",
      "cumulative_variance = np.cumsum(explained_variance)\n",
      "\n",
      "# Nombre de composantes pour 90% de variance\n",
      "n_components_90 = np.argmax(cumulative_variance >= 0.9) + 1\n",
      "print(f\"Number of components to reach 90% variance: {n_components_90}\")\n",
      "\n",
      "# Visualiser la variance expliquée\n",
      "plt.figure(figsize=(12, 5))\n",
      "\n",
      "# Variance expliquée par chaque composante\n",
      "plt.subplot(1, 2, 1)\n",
      "plt.bar(range(1, len(explained_variance) + 1), explained_variance, alpha=0.8)\n",
      "plt.title('Explained variance by component')\n",
      "plt.xlabel('Principal component')\n",
      "plt.ylabel('Explained variance ratio')\n",
      "plt.grid(True)\n",
      "\n",
      "# Variance expliquée cumulée\n",
      "plt.subplot(1, 2, 2)\n",
      "plt.plot(range(1, len(cumulative_variance) + 1), cumulative_variance, 'o-', markersize=8)\n",
      "plt.axhline(y=0.9, color='r', linestyle='--', label='90% of variance')\n",
      "plt.title('Cumulative explained variance')\n",
      "plt.xlabel('Number of components')\n",
      "plt.ylabel('Cumulative explained variance ratio')\n",
      "plt.grid(True)\n",
      "plt.legend()\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "# --- Markdown Cell ---\n",
      "###  6.3 Comparaison PCA et Features Optimisées - K means \n",
      "# --- Code Cell ---\n",
      "# Déterminer le nombre optimal de clusters pour les deux approches\n",
      "inertia_values_pca = []\n",
      "inertia_values_direct = []\n",
      "silhouette_scores_pca = []\n",
      "silhouette_scores_direct = []\n",
      "k_range = range(2, 10)\n",
      "\n",
      "# Calculer les métriques pour les deux approches\n",
      "from sklearn.metrics import silhouette_score\n",
      "\n",
      "for k in k_range:\n",
      "    # Approche PCA\n",
      "    kmeans_pca = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
      "    kmeans_pca.fit(X_pca)\n",
      "    inertia_values_pca.append(kmeans_pca.inertia_)\n",
      "    silhouette_scores_pca.append(silhouette_score(X_pca, kmeans_pca.labels_))\n",
      "    \n",
      "    # Approche directe\n",
      "    kmeans_direct = KMeans(n_clusters=k, random_state=42, n_init=10)\n",
      "    kmeans_direct.fit(X_optimized_scaled)\n",
      "    inertia_values_direct.append(kmeans_direct.inertia_)\n",
      "    silhouette_scores_direct.append(silhouette_score(X_optimized_scaled, kmeans_direct.labels_))\n",
      "\n",
      "# Visualiser les métriques\n",
      "plt.figure(figsize=(15, 7))\n",
      "plt.subplot(1, 2, 1)\n",
      "plt.plot(k_range, inertia_values_pca, 'o-', markersize=8, label='PCA')\n",
      "plt.plot(k_range, inertia_values_direct, 's-', markersize=8, label='Features Optimisées')\n",
      "plt.title('Méthode du coude: PCA vs Features Optimisées')\n",
      "plt.xlabel('Nombre de clusters (k)')\n",
      "plt.ylabel('Inertie')\n",
      "plt.legend()\n",
      "plt.grid(True)\n",
      "\n",
      "plt.subplot(1, 2, 2)\n",
      "plt.plot(k_range, silhouette_scores_pca, 'o-', markersize=8, label='PCA')\n",
      "plt.plot(k_range, silhouette_scores_direct, 's-', markersize=8, label='Features Optimisées')\n",
      "plt.title('Score silhouette: PCA vs Features Optimisées')\n",
      "plt.xlabel('Nombre de clusters (k)')\n",
      "plt.ylabel('Score silhouette')\n",
      "plt.legend()\n",
      "plt.grid(True)\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "# Déterminer le nombre optimal de clusters pour chaque approche\n",
      "optimal_k_pca = k_range[np.argmax(silhouette_scores_pca)]\n",
      "optimal_k_direct = k_range[np.argmax(silhouette_scores_direct)]\n",
      "\n",
      "print(f\"Nombre optimal de clusters (PCA): {optimal_k_pca}\")\n",
      "print(f\"Nombre optimal de clusters (Features Optimisées): {optimal_k_direct}\")\n",
      "\n",
      "# Appliquer K-means avec le nombre optimal de clusters\n",
      "kmeans_pca = KMeans(n_clusters=optimal_k_pca, random_state=42, n_init=10)\n",
      "kmeans_pca.fit(X_pca)\n",
      "cluster_labels_pca = kmeans_pca.labels_\n",
      "\n",
      "kmeans_direct = KMeans(n_clusters=optimal_k_direct, random_state=42, n_init=10)\n",
      "kmeans_direct.fit(X_optimized_scaled)\n",
      "cluster_labels_direct = kmeans_direct.labels_ \n",
      "\n",
      "# --- Markdown Cell ---\n",
      "### 6.4 Visualisation des clusters et relation avec les classes\n",
      "# --- Code Cell ---\n",
      "# Visualisation pour l'approche PCA\n",
      "plt.figure(figsize=(20, 10))\n",
      "plt.subplot(2, 2, 1)\n",
      "for cluster in range(optimal_k_pca):\n",
      "    plt.scatter(X_pca[cluster_labels_pca == cluster, 0], X_pca[cluster_labels_pca == cluster, 1], \n",
      "                label=f'Cluster {cluster}', alpha=0.7)\n",
      "plt.title('K-means sur PCA: Clusters')\n",
      "plt.xlabel('Première composante principale')\n",
      "plt.ylabel('Deuxième composante principale')\n",
      "plt.legend()\n",
      "plt.grid(True)\n",
      "\n",
      "plt.subplot(2, 2, 2)\n",
      "for cls in sorted(np.unique(y_raw_train)):\n",
      "    plt.scatter(X_pca[y_raw_train == cls, 0], X_pca[y_raw_train == cls, 1], \n",
      "                label=f'Classe {cls}', alpha=0.7)\n",
      "plt.title('K-means sur PCA: Classes réelles')\n",
      "plt.xlabel('Première composante principale')\n",
      "plt.ylabel('Deuxième composante principale')\n",
      "plt.legend()\n",
      "plt.grid(True)\n",
      "\n",
      "# Visualisation pour l'approche directe (réduction de dimension pour visualisation uniquement)\n",
      "# Utiliser PCA pour visualiser les données hautes dimensions\n",
      "pca_viz = PCA(n_components=2)\n",
      "X_viz = pca_viz.fit_transform(X_optimized_scaled)\n",
      "\n",
      "plt.subplot(2, 2, 3)\n",
      "for cluster in range(optimal_k_direct):\n",
      "    plt.scatter(X_viz[cluster_labels_direct == cluster, 0], X_viz[cluster_labels_direct == cluster, 1], \n",
      "                label=f'Cluster {cluster}', alpha=0.7)\n",
      "plt.title('K-means sur Features Optimisées: Clusters')\n",
      "plt.xlabel('Première composante (visualisation)')\n",
      "plt.ylabel('Deuxième composante (visualisation)')\n",
      "plt.legend()\n",
      "plt.grid(True)\n",
      "\n",
      "plt.subplot(2, 2, 4)\n",
      "for cls in sorted(np.unique(y_raw_train)):\n",
      "    plt.scatter(X_viz[y_raw_train == cls, 0], X_viz[y_raw_train == cls, 1], \n",
      "                label=f'Classe {cls}', alpha=0.7)\n",
      "plt.title('K-means sur Features Optimisées: Classes réelles')\n",
      "plt.xlabel('Première composante (visualisation)')\n",
      "plt.ylabel('Deuxième composante (visualisation)')\n",
      "plt.legend()\n",
      "plt.grid(True)\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "# --- Markdown Cell ---\n",
      "### 6.5 Comparaison des tables de contingence\n",
      "# --- Code Cell ---\n",
      "\n",
      "print(\"\\n--- Comparaison des correspondances entre clusters et classes ---\")\n",
      "\n",
      "# Table de contingence pour l'approche PCA\n",
      "contingency_pca = pd.DataFrame(\n",
      "    confusion_matrix(y_raw_train, cluster_labels_pca),\n",
      "    index=[f'Classe {cls}' for cls in sorted(np.unique(y_raw_train))],\n",
      "    columns=[f'Cluster {i}' for i in range(optimal_k_pca)]\n",
      ")\n",
      "\n",
      "print(\"Table de contingence - K-means sur PCA:\")\n",
      "display(contingency_pca)\n",
      "\n",
      "plt.figure(figsize=(15, 6))\n",
      "plt.subplot(1, 2, 1)\n",
      "sns.heatmap(contingency_pca, annot=True, fmt='d', cmap='Blues')\n",
      "plt.title('Correspondance clusters-classes: K-means sur PCA')\n",
      "\n",
      "# Table de contingence pour l'approche directe\n",
      "contingency_direct = pd.DataFrame(\n",
      "    confusion_matrix(y_raw_train, cluster_labels_direct),\n",
      "    index=[f'Classe {cls}' for cls in sorted(np.unique(y_raw_train))],\n",
      "    columns=[f'Cluster {i}' for i in range(optimal_k_direct)]\n",
      ")\n",
      "\n",
      "print(\"\\nTable de contingence - K-means sur Features Optimisées:\")\n",
      "display(contingency_direct)\n",
      "\n",
      "plt.subplot(1, 2, 2)\n",
      "sns.heatmap(contingency_direct, annot=True, fmt='d', cmap='Blues')\n",
      "plt.title('Correspondance clusters-classes: K-means sur Features Optimisées')\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "# --- Markdown Cell ---\n",
      "### 6.6 Comparaison des performances prédictives\n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Comparaison des performances prédictives entre les deux approches ---\")\n",
      "\n",
      "# Mapping pour les étiquettes de classe\n",
      "mapping = {-1: 0, 0: 1, 1: 2}\n",
      "inverse_mapping = {0: -1, 1: 0, 2: 1}\n",
      "y_raw_train_mapped = y_raw_train.map(mapping)\n",
      "\n",
      "# Approche 1: K-means sur PCA\n",
      "# Prédire les clusters pour les données de test\n",
      "cluster_pca_test = kmeans_pca.predict(X_test_pca)\n",
      "\n",
      "# Ajouter les clusters comme features supplémentaires\n",
      "X_with_clusters_pca = np.column_stack((X_optimized_scaled, cluster_labels_pca))\n",
      "X_test_clusters_pca = np.column_stack((X_test_optimized_scaled, cluster_pca_test))\n",
      "\n",
      "# Entraîner XGBoost avec les clusters PCA\n",
      "xgb_pca = XGBClassifier(objective=\"multi:softmax\", num_class=3, random_state=42)\n",
      "xgb_pca.fit(X_with_clusters_pca, y_raw_train_mapped)\n",
      "\n",
      "# Prédire\n",
      "y_pred_pca_mapped = xgb_pca.predict(X_test_clusters_pca)\n",
      "y_pred_pca = pd.Series(y_pred_pca_mapped).map(inverse_mapping)\n",
      "\n",
      "# Évaluer\n",
      "accuracy_pca = accuracy_score(y_raw_test, y_pred_pca)\n",
      "report_pca = classification_report(y_raw_test, y_pred_pca, output_dict=True)\n",
      "\n",
      "print(f\"Accuracy avec K-means sur PCA: {accuracy_pca:.4f}\")\n",
      "print(f\"F1 score pondéré: {report_pca['weighted avg']['f1-score']:.4f}\")\n",
      "\n",
      "# Approche 2: K-means direct sur features optimisées\n",
      "# Prédire les clusters pour les données de test\n",
      "cluster_direct_test = kmeans_direct.predict(X_test_optimized_scaled)\n",
      "\n",
      "# Ajouter les clusters comme features supplémentaires\n",
      "X_with_clusters_direct = np.column_stack((X_optimized_scaled, cluster_labels_direct))\n",
      "X_test_clusters_direct = np.column_stack((X_test_optimized_scaled, cluster_direct_test))\n",
      "\n",
      "# Entraîner XGBoost avec les clusters directs\n",
      "xgb_direct = XGBClassifier(objective=\"multi:softmax\", num_class=3, random_state=42)\n",
      "xgb_direct.fit(X_with_clusters_direct, y_raw_train_mapped)\n",
      "\n",
      "# Prédire\n",
      "y_pred_direct_mapped = xgb_direct.predict(X_test_clusters_direct)\n",
      "y_pred_direct = pd.Series(y_pred_direct_mapped).map(inverse_mapping)\n",
      "\n",
      "# Évaluer\n",
      "accuracy_direct = accuracy_score(y_raw_test, y_pred_direct)\n",
      "report_direct = classification_report(y_raw_test, y_pred_direct, output_dict=True)\n",
      "\n",
      "print(f\"Accuracy avec K-means sur Features Optimisées: {accuracy_direct:.4f}\")\n",
      "print(f\"F1 score pondéré: {report_direct['weighted avg']['f1-score']:.4f}\")\n",
      "\n",
      "# Comparaison visuelle\n",
      "plt.figure(figsize=(10, 6))\n",
      "comparison_df = pd.DataFrame([\n",
      "    {\"Approche\": \"K-means sur PCA\", \"Accuracy\": accuracy_pca, \"F1 Score\": report_pca['weighted avg']['f1-score']},\n",
      "    {\"Approche\": \"K-means sur Features Optimisées\", \"Accuracy\": accuracy_direct, \"F1 Score\": report_direct['weighted avg']['f1-score']}\n",
      "])\n",
      "\n",
      "sns.barplot(x=\"Approche\", y=\"Accuracy\", data=comparison_df)\n",
      "plt.title('Comparaison des performances avec clusters comme feature')\n",
      "plt.grid(axis='y')\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "# Ajouter les résultats au tracker\n",
      "result_kmeans_pca = {\n",
      "    \"dataset\": raw_dataset_key,\n",
      "    \"dataset_description\": f\"{raw_dataset_key} avec features optimisées + PCA\",\n",
      "    \"model\": \"xgboost_kmeans_pca\",\n",
      "    \"model_description\": \"XGBoost avec clusters K-means (via PCA)\",\n",
      "    \"features_added\": True,\n",
      "    \"feature_sets\": [\"Optimisées + K-means PCA\"],\n",
      "    \"normalize_by_row\": best_normalize,\n",
      "    \"accuracy\": accuracy_pca,\n",
      "    \"precision_weighted\": report_pca[\"weighted avg\"][\"precision\"],\n",
      "    \"recall_weighted\": report_pca[\"weighted avg\"][\"recall\"],\n",
      "    \"f1_weighted\": report_pca[\"weighted avg\"][\"f1-score\"],\n",
      "    \"notes\": f\"K-means sur PCA ({optimal_k_pca} clusters)\"\n",
      "}\n",
      "\n",
      "result_kmeans_direct = {\n",
      "    \"dataset\": raw_dataset_key,\n",
      "    \"dataset_description\": f\"{raw_dataset_key} avec features optimisées sans PCA\",\n",
      "    \"model\": \"xgboost_kmeans_direct\",\n",
      "    \"model_description\": \"XGBoost avec clusters K-means (sans PCA)\",\n",
      "    \"features_added\": True,\n",
      "    \"feature_sets\": [\"Optimisées + K-means direct\"],\n",
      "    \"normalize_by_row\": best_normalize,\n",
      "    \"accuracy\": accuracy_direct,\n",
      "    \"precision_weighted\": report_direct[\"weighted avg\"][\"precision\"],\n",
      "    \"recall_weighted\": report_direct[\"weighted avg\"][\"recall\"],\n",
      "    \"f1_weighted\": report_direct[\"weighted avg\"][\"f1-score\"],\n",
      "    \"notes\": f\"K-means sur features optimisées ({optimal_k_direct} clusters)\"\n",
      "}\n",
      "\n",
      "results_tracker = add_result(results_tracker, result_kmeans_pca)\n",
      "results_tracker = add_result(results_tracker, result_kmeans_direct)\n",
      "\n",
      "# --- Markdown Cell ---\n",
      "### 6.7 Analyse DBSCAN - Également avec les deux approches\n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Analyse DBSCAN: Comparaison PCA vs Features Optimisées ---\")\n",
      "\n",
      "from sklearn.neighbors import NearestNeighbors\n",
      "\n",
      "# Fonction pour déterminer eps optimal \n",
      "def determine_optimal_eps(X, k=15):\n",
      "    neigh = NearestNeighbors(n_neighbors=k)\n",
      "    neigh.fit(X)\n",
      "    distances, indices = neigh.kneighbors(X)\n",
      "    sorted_distances = np.sort(distances[:, k-1])\n",
      "    \n",
      "    # Visualisation pour déterminer eps\n",
      "    plt.figure(figsize=(10, 6))\n",
      "    plt.plot(range(len(sorted_distances)), sorted_distances, 'o-', markersize=3)\n",
      "    plt.title(f'Méthode du coude pour déterminer eps (k={k})')\n",
      "    plt.xlabel('Points triés par distance')\n",
      "    plt.ylabel(f'Distance au {k}ème voisin')\n",
      "    plt.grid(True)\n",
      "    plt.show()\n",
      "    \n",
      "    # Estimer eps à environ 90% des points\n",
      "    eps = np.percentile(sorted_distances, 90)\n",
      "    return eps, sorted_distances\n",
      "\n",
      "# Déterminer eps pour les deux approches\n",
      "eps_pca, distances_pca = determine_optimal_eps(X_pca)\n",
      "eps_direct, distances_direct = determine_optimal_eps(X_optimized_scaled)\n",
      "\n",
      "print(f\"DBSCAN - eps optimal pour l'approche PCA: {eps_pca:.4f}\")\n",
      "print(f\"DBSCAN - eps optimal pour l'approche directe: {eps_direct:.4f}\")\n",
      "\n",
      "# Appliquer DBSCAN\n",
      "min_samples = 5  # Valeur standard\n",
      "\n",
      "dbscan_pca = DBSCAN(eps=eps_pca, min_samples=min_samples)\n",
      "dbscan_direct = DBSCAN(eps=eps_direct, min_samples=min_samples)\n",
      "\n",
      "dbscan_labels_pca = dbscan_pca.fit_predict(X_pca)\n",
      "dbscan_labels_direct = dbscan_direct.fit_predict(X_optimized_scaled)\n",
      "\n",
      "# Analyser les résultats DBSCAN\n",
      "n_clusters_pca = len(set(dbscan_labels_pca)) - (1 if -1 in dbscan_labels_pca else 0)\n",
      "n_noise_pca = list(dbscan_labels_pca).count(-1)\n",
      "\n",
      "n_clusters_direct = len(set(dbscan_labels_direct)) - (1 if -1 in dbscan_labels_direct else 0)\n",
      "n_noise_direct = list(dbscan_labels_direct).count(-1)\n",
      "\n",
      "print(f\"\\nRésultats DBSCAN sur PCA:\")\n",
      "print(f\"- Nombre de clusters: {n_clusters_pca}\")\n",
      "print(f\"- Points de bruit: {n_noise_pca} ({n_noise_pca/len(dbscan_labels_pca)*100:.2f}%)\")\n",
      "\n",
      "print(f\"\\nRésultats DBSCAN sur Features Optimisées:\")\n",
      "print(f\"- Nombre de clusters: {n_clusters_direct}\")\n",
      "print(f\"- Points de bruit: {n_noise_direct} ({n_noise_direct/len(dbscan_labels_direct)*100:.2f}%)\")\n",
      "\n",
      "# Visualisation des clusters DBSCAN\n",
      "plt.figure(figsize=(15, 12))\n",
      "\n",
      "# DBSCAN sur PCA\n",
      "plt.subplot(2, 1, 1)\n",
      "colors_pca = plt.cm.rainbow(np.linspace(0, 1, n_clusters_pca + 1))\n",
      "\n",
      "# Points de bruit en noir\n",
      "plt.scatter(X_pca[dbscan_labels_pca == -1, 0], X_pca[dbscan_labels_pca == -1, 1], \n",
      "            c='black', marker='x', label='Bruit', alpha=0.7)\n",
      "\n",
      "# Clusters\n",
      "for i, color in zip(range(n_clusters_pca), colors_pca):\n",
      "    plt.scatter(X_pca[dbscan_labels_pca == i, 0], X_pca[dbscan_labels_pca == i, 1], \n",
      "                c=color.reshape(1, -1), label=f'Cluster {i}', alpha=0.7)\n",
      "\n",
      "plt.title('DBSCAN sur PCA')\n",
      "plt.xlabel('Première composante')\n",
      "plt.ylabel('Deuxième composante')\n",
      "if n_clusters_pca < 10:  # Limite pour la lisibilité de la légende\n",
      "    plt.legend()\n",
      "plt.grid(True)\n",
      "\n",
      "# DBSCAN sur Features Optimisées (visualisé avec PCA)\n",
      "plt.subplot(2, 1, 2)\n",
      "colors_direct = plt.cm.rainbow(np.linspace(0, 1, n_clusters_direct + 1))\n",
      "\n",
      "# Points de bruit en noir\n",
      "plt.scatter(X_viz[dbscan_labels_direct == -1, 0], X_viz[dbscan_labels_direct == -1, 1], \n",
      "            c='black', marker='x', label='Bruit', alpha=0.7)\n",
      "\n",
      "# Clusters\n",
      "for i, color in zip(range(n_clusters_direct), colors_direct):\n",
      "    plt.scatter(X_viz[dbscan_labels_direct == i, 0], X_viz[dbscan_labels_direct == i, 1], \n",
      "                c=color.reshape(1, -1), label=f'Cluster {i}', alpha=0.7)\n",
      "\n",
      "plt.title('DBSCAN sur Features Optimisées')\n",
      "plt.xlabel('Première composante (visualisation)')\n",
      "plt.ylabel('Deuxième composante (visualisation)')\n",
      "if n_clusters_direct < 10:  # Limite pour la lisibilité de la légende\n",
      "    plt.legend()\n",
      "plt.grid(True)\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "# --- Markdown Cell ---\n",
      "### 6.8 Analyse finale et récapitulatif\n",
      "# --- Code Cell ---\n",
      "\n",
      "print(\"\\n--- Récapitulatif de l'analyse non supervisée ---\")\n",
      "\n",
      "print(\"Comparaison des performances:\")\n",
      "print(f\"1. K-means sur PCA: Accuracy = {accuracy_pca:.4f}, F1 = {report_pca['weighted avg']['f1-score']:.4f}\")\n",
      "print(f\"2. K-means sur Features Optimisées: Accuracy = {accuracy_direct:.4f}, F1 = {report_direct['weighted avg']['f1-score']:.4f}\")\n",
      "\n",
      "difference = abs(accuracy_direct - accuracy_pca)\n",
      "better = \"avec\" if accuracy_direct > accuracy_pca else \"sans\"\n",
      "print(f\"\\nDifférence d'accuracy: {difference:.4f} ({difference*100:.2f}%) en faveur de l'approche {better} PCA\")\n",
      "\n",
      "print(\"\\nConclusions sur les approches non supervisées:\")\n",
      "# --- Markdown Cell ---\n",
      "## 7. Modèles supervisés \n",
      "# --- Markdown Cell ---\n",
      "### 7.1 SVM sur échantillon  \n",
      "# --- Markdown Cell ---\n",
      "# Pour le SVM, l’utilisation d’un échantillon réduit la taille du dataset, ce qui accélère grandement le temps de calcul puisque c'est un algorithme très couteux en ressources. Cela nous permet d’itérer plus rapidement sur les réglages et la validation du modèle. On évite ainsi de saturer la mémoire et de dépasser les limites computationnelles qui nous sont TRES limitées. Nous avons déjà eu un problème similaire lors de nos premiers essais avec les random forest. Le résultat ne sera pas le plus précis mais nous donne une première idée.\n",
      "# --- Code Cell ---\n",
      "mapping = {-1: 0, 0: 1, 1: 2}\n",
      "inverse_mapping = {0: -1, 1: 0, 2: 1}\n",
      "y_train_mapped = y_raw_train.map(mapping)\n",
      "\n",
      "# 7.2 SVM optimisé\n",
      "print(\"\\n--- Modèle supervisé: SVM optimisé ---\")\n",
      "\n",
      "# Définir la grille de paramètres pour SVM\n",
      "svm_param_grid = {\n",
      "    'C': [0.1, 1, 10, 100],\n",
      "    'gamma': ['scale', 'auto', 0.1, 0.01],\n",
      "    'kernel': ['rbf', 'poly', 'sigmoid'],\n",
      "    'class_weight': ['balanced', None]\n",
      "}\n",
      "\n",
      "# Échantillonnage pour SVM \n",
      "sample_size = min(10000, len(X_optimized))\n",
      "np.random.seed(42)\n",
      "\n",
      "# Randomisation pour l'échantillonnage\n",
      "sample_indices = np.random.choice(len(X_optimized), sample_size, replace=False)\n",
      "\n",
      "X_sample = X_optimized.iloc[sample_indices]\n",
      "y_sample = y_raw_train.iloc[sample_indices]\n",
      "y_sample_mapped = y_sample.map(mapping)\n",
      "\n",
      "print(f\"Optimisation des hyperparamètres SVM sur un échantillon de {sample_size} exemples...\")\n",
      "svm_opt_result = optimize_hyperparameters(\n",
      "    SVC(random_state=42, probability=True),\n",
      "    svm_param_grid,\n",
      "    X_sample,\n",
      "    y_sample_mapped,\n",
      "    n_iter=10,\n",
      "    use_random=True\n",
      ")\n",
      "\n",
      "# Extraire les meilleurs paramètres\n",
      "svm_best_params = svm_opt_result[\"best_params\"]\n",
      "svm_best_score = svm_opt_result[\"best_score\"]\n",
      "\n",
      "print(f\"Meilleur score de validation croisée SVM: {svm_best_score:.4f}\")\n",
      "print(\"Meilleurs paramètres SVM:\")\n",
      "for param, value in svm_best_params.items():\n",
      "    print(f\"- {param}: {value}\")\n",
      "\n",
      "# Créer et entraîner le modèle SVM\n",
      "svm_model = SVC(random_state=42, probability=True, **svm_best_params)\n",
      "\n",
      "start_time = time.time()\n",
      "svm_model.fit(X_optimized, y_raw_train)\n",
      "svm_train_time = time.time() - start_time\n",
      "\n",
      "# Faire des prédictions\n",
      "start_time = time.time()\n",
      "svm_pred = svm_model.predict(X_test_optimized)\n",
      "svm_pred_time = time.time() - start_time\n",
      "\n",
      "# Évaluer les performances\n",
      "svm_accuracy = accuracy_score(y_raw_test, svm_pred)\n",
      "svm_report = classification_report(y_raw_test, svm_pred, output_dict=True)\n",
      "\n",
      "print(f\"\\nPerformances du modèle SVM:\")\n",
      "print(f\"Accuracy: {svm_accuracy:.4f}\")\n",
      "print(f\"F1 score pondéré: {svm_report['weighted avg']['f1-score']:.4f}\")\n",
      "print(f\"Temps d'entraînement: {svm_train_time:.2f}s, Prédiction: {svm_pred_time:.2f}s\")\n",
      "\n",
      "# Ajouter au tracker de résultats\n",
      "result_svm = {\n",
      "    \"dataset\": raw_dataset_key,\n",
      "    \"dataset_description\": f\"Dataset optimisé sans day/equity\",\n",
      "    \"model\": \"svm_optimized\",\n",
      "    \"model_description\": \"SVM optimisé\",\n",
      "    \"features_added\": True,\n",
      "    \"feature_sets\": [\"Optimisées sans day/equity\"],\n",
      "    \"normalize_by_row\": best_normalize,\n",
      "    \"accuracy\": svm_accuracy,\n",
      "    \"precision_weighted\": svm_report[\"weighted avg\"][\"precision\"],\n",
      "    \"recall_weighted\": svm_report[\"weighted avg\"][\"recall\"],\n",
      "    \"f1_weighted\": svm_report[\"weighted avg\"][\"f1-score\"],\n",
      "    \"training_time\": svm_train_time,\n",
      "    \"prediction_time\": svm_pred_time,\n",
      "    \"total_time\": svm_train_time + svm_pred_time,\n",
      "    \"notes\": f\"SVM optimisé sur features sans day/equity\"\n",
      "}\n",
      "\n",
      "results_tracker = add_result(results_tracker, result_svm)\n",
      "# --- Markdown Cell ---\n",
      "### 7.3 XGBoost optimisé (pour référence dans cette section)\n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- XGBoost optimisé sur les mêmes données ---\")\n",
      "\n",
      "# Utiliser des paramètres XGBoost standard si non définis précédemment\n",
      "if 'best_params' not in globals():\n",
      "    xgb_params = {\n",
      "        'n_estimators': 200,\n",
      "        'max_depth': 5,\n",
      "        'learning_rate': 0.1,\n",
      "        'subsample': 0.8,\n",
      "        'colsample_bytree': 0.8\n",
      "    }\n",
      "else:\n",
      "    xgb_params = best_params\n",
      "\n",
      "# Créer et entraîner le modèle XGBoost\n",
      "xgb_model = XGBClassifier(\n",
      "    objective=\"multi:softmax\",\n",
      "    num_class=3,\n",
      "    random_state=42,\n",
      "    **xgb_params\n",
      ")\n",
      "\n",
      "start_time = time.time()\n",
      "xgb_model.fit(X_optimized, y_train_mapped)\n",
      "xgb_train_time = time.time() - start_time\n",
      "\n",
      "# Faire des prédictions\n",
      "start_time = time.time()\n",
      "xgb_pred_mapped = xgb_model.predict(X_test_optimized)\n",
      "xgb_pred_time = time.time() - start_time\n",
      "\n",
      "# Reconvertir les prédictions\n",
      "xgb_pred = pd.Series(xgb_pred_mapped).map(inverse_mapping)\n",
      "\n",
      "# Évaluer les performances\n",
      "xgb_accuracy = accuracy_score(y_raw_test, xgb_pred)\n",
      "xgb_report = classification_report(y_raw_test, xgb_pred, output_dict=True)\n",
      "\n",
      "print(f\"Accuracy XGBoost optimisé: {xgb_accuracy:.4f}\")\n",
      "print(f\"F1 score pondéré: {xgb_report['weighted avg']['f1-score']:.4f}\")\n",
      "print(f\"Temps d'entraînement: {xgb_train_time:.2f}s\")\n",
      "# --- Markdown Cell ---\n",
      "### 7.4 Modèle ensembliste 1: Stacking\n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Modèle ensembliste: Stacking ---\")\n",
      "\n",
      "# Définir le meta-classifier\n",
      "meta_classifier = LogisticRegression(max_iter=1000, random_state=42)\n",
      "\n",
      "# Définir les estimateurs de base (XGBoost et SVM)\n",
      "base_estimators = [\n",
      "    ('xgb', XGBClassifier(objective=\"multi:softmax\", num_class=3, random_state=42, **xgb_params)),\n",
      "    ('svm', SVC(probability=True, random_state=42, **svm_best_params))\n",
      "]\n",
      "\n",
      "# Créer le modèle stacking\n",
      "stacking_model = StackingClassifier(\n",
      "    estimators=base_estimators,\n",
      "    final_estimator=meta_classifier,\n",
      "    cv=5,\n",
      "    stack_method='predict_proba',\n",
      "    n_jobs=-1\n",
      ")\n",
      "\n",
      "# Entraîner le modèle\n",
      "start_time = time.time()\n",
      "stacking_model.fit(X_optimized, y_raw_train)\n",
      "stacking_train_time = time.time() - start_time\n",
      "\n",
      "# Faire des prédictions\n",
      "start_time = time.time()\n",
      "stacking_pred = stacking_model.predict(X_test_optimized)\n",
      "stacking_pred_time = time.time() - start_time\n",
      "\n",
      "# Évaluer les performances\n",
      "stacking_accuracy = accuracy_score(y_raw_test, stacking_pred)\n",
      "stacking_report = classification_report(y_raw_test, stacking_pred, output_dict=True)\n",
      "\n",
      "print(f\"\\nPerformances du modèle Stacking:\")\n",
      "print(f\"Accuracy: {stacking_accuracy:.4f}\")\n",
      "print(f\"F1 score pondéré: {stacking_report['weighted avg']['f1-score']:.4f}\")\n",
      "print(f\"Temps d'entraînement: {stacking_train_time:.2f}s, Prédiction: {stacking_pred_time:.2f}s\")\n",
      "\n",
      "# Ajouter au tracker de résultats\n",
      "result_stacking = {\n",
      "    \"dataset\": raw_dataset_key,\n",
      "    \"dataset_description\": f\"Dataset optimisé sans day/equity\",\n",
      "    \"model\": \"stacking_ensemble\",\n",
      "    \"model_description\": \"Stacking (XGBoost + SVM)\",\n",
      "    \"features_added\": True,\n",
      "    \"feature_sets\": [\"Optimisées sans day/equity\"],\n",
      "    \"normalize_by_row\": best_normalize,\n",
      "    \"accuracy\": stacking_accuracy,\n",
      "    \"precision_weighted\": stacking_report[\"weighted avg\"][\"precision\"],\n",
      "    \"recall_weighted\": stacking_report[\"weighted avg\"][\"recall\"],\n",
      "    \"f1_weighted\": stacking_report[\"weighted avg\"][\"f1-score\"],\n",
      "    \"training_time\": stacking_train_time,\n",
      "    \"prediction_time\": stacking_pred_time,\n",
      "    \"total_time\": stacking_train_time + stacking_pred_time,\n",
      "    \"notes\": f\"Stacking de XGBoost et SVM\"\n",
      "}\n",
      "\n",
      "results_tracker = add_result(results_tracker, result_stacking)\n",
      "\n",
      "# --- Markdown Cell ---\n",
      "### 7.5 Modèle ensembliste 2: Voting\n",
      "# --- Code Cell ---\n",
      "print(\"\\n--- Modèle ensembliste: Voting ---\")\n",
      "\n",
      "# Créer le modèle de vote\n",
      "voting_model = VotingClassifier(\n",
      "    estimators=base_estimators,\n",
      "    voting='soft',  # Utiliser les probabilités pour le vote\n",
      "    n_jobs=-1\n",
      ")\n",
      "\n",
      "# Entraîner le modèle\n",
      "start_time = time.time()\n",
      "voting_model.fit(X_optimized, y_raw_train)\n",
      "voting_train_time = time.time() - start_time\n",
      "\n",
      "# Faire des prédictions\n",
      "start_time = time.time()\n",
      "voting_pred = voting_model.predict(X_test_optimized)\n",
      "voting_pred_time = time.time() - start_time\n",
      "\n",
      "# Évaluer les performances\n",
      "voting_accuracy = accuracy_score(y_raw_test, voting_pred)\n",
      "voting_report = classification_report(y_raw_test, voting_pred, output_dict=True)\n",
      "\n",
      "print(f\"\\nPerformances du modèle Voting:\")\n",
      "print(f\"Accuracy: {voting_accuracy:.4f}\")\n",
      "print(f\"F1 score pondéré: {voting_report['weighted avg']['f1-score']:.4f}\")\n",
      "print(f\"Temps d'entraînement: {voting_train_time:.2f}s, Prédiction: {voting_pred_time:.2f}s\")\n",
      "\n",
      "# Ajouter au tracker de résultats\n",
      "result_voting = {\n",
      "    \"dataset\": raw_dataset_key,\n",
      "    \"dataset_description\": f\"Dataset optimisé sans day/equity\",\n",
      "    \"model\": \"voting_ensemble\",\n",
      "    \"model_description\": \"Voting (XGBoost + SVM)\",\n",
      "    \"features_added\": True,\n",
      "    \"feature_sets\": [\"Optimisées sans day/equity\"],\n",
      "    \"normalize_by_row\": best_normalize,\n",
      "    \"accuracy\": voting_accuracy,\n",
      "    \"precision_weighted\": voting_report[\"weighted avg\"][\"precision\"],\n",
      "    \"recall_weighted\": voting_report[\"weighted avg\"][\"recall\"],\n",
      "    \"f1_weighted\": voting_report[\"weighted avg\"][\"f1-score\"],\n",
      "    \"training_time\": voting_train_time,\n",
      "    \"prediction_time\": voting_pred_time,\n",
      "    \"total_time\": voting_train_time + voting_pred_time,\n",
      "    \"notes\": f\"Voting ensemble de XGBoost et SVM\"\n",
      "}\n",
      "\n",
      "results_tracker = add_result(results_tracker, result_voting)\n",
      "# --- Markdown Cell ---\n",
      "### 7.6 Comparaison des modèles supervisés\n",
      "# --- Code Cell ---\n",
      "\n",
      "print(\"\\n--- Comparaison des modèles supervisés avancés ---\")\n",
      "\n",
      "# Créer un DataFrame pour la comparaison\n",
      "comparison_sup_df = pd.DataFrame([\n",
      "    {\"Modèle\": \"XGBoost optimisé\", \"Accuracy\": xgb_accuracy, \"F1 score\": xgb_report['weighted avg']['f1-score'], \n",
      "     \"Temps d'entraînement\": xgb_train_time, \"Temps total\": xgb_train_time + xgb_pred_time},\n",
      "    {\"Modèle\": \"SVM\", \"Accuracy\": svm_accuracy, \"F1 score\": svm_report['weighted avg']['f1-score'], \n",
      "     \"Temps d'entraînement\": svm_train_time, \"Temps total\": svm_train_time + svm_pred_time},\n",
      "    {\"Modèle\": \"Stacking\", \"Accuracy\": stacking_accuracy, \"F1 score\": stacking_report['weighted avg']['f1-score'], \n",
      "     \"Temps d'entraînement\": stacking_train_time, \"Temps total\": stacking_train_time + stacking_pred_time},\n",
      "    {\"Modèle\": \"Voting\", \"Accuracy\": voting_accuracy, \"F1 score\": voting_report['weighted avg']['f1-score'], \n",
      "     \"Temps d'entraînement\": voting_train_time, \"Temps total\": voting_train_time + voting_pred_time}\n",
      "])\n",
      "\n",
      "# Trier par accuracy décroissante\n",
      "comparison_sup_df = comparison_sup_df.sort_values(\"Accuracy\", ascending=False)\n",
      "\n",
      "# Afficher le tableau de comparaison\n",
      "print(\"Comparaison des performances:\")\n",
      "display(comparison_sup_df)\n",
      "\n",
      "# Visualiser la comparaison\n",
      "plt.figure(figsize=(14, 10))\n",
      "\n",
      "plt.subplot(2, 1, 1)\n",
      "sns.barplot(x=\"Modèle\", y=\"Accuracy\", data=comparison_sup_df)\n",
      "plt.title('Comparaison des Accuracy')\n",
      "plt.ylim(0.3, 0.35)  # Ajuster selon les valeurs réelles\n",
      "plt.xticks(rotation=45, ha=\"right\")\n",
      "plt.grid(axis='y')\n",
      "\n",
      "plt.subplot(2, 1, 2)\n",
      "sns.barplot(x=\"Modèle\", y=\"Temps total\", data=comparison_sup_df)\n",
      "plt.title('Comparaison des temps d\\'exécution (secondes)')\n",
      "plt.xticks(rotation=45, ha=\"right\")\n",
      "plt.yscale('log')  # Échelle logarithmique pour mieux visualiser les différences\n",
      "plt.grid(axis='y')\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "# 7.7 Analyse et conclusions\n",
      "print(\"\\n--- Analyse des résultats des modèles supervisés avancés ---\")\n",
      "\n",
      "# Trouver le meilleur modèle\n",
      "best_model = comparison_sup_df.iloc[0]\n",
      "print(f\"Meilleur modèle: {best_model['Modèle']} avec une accuracy de {best_model['Accuracy']:.4f}\")\n",
      "\n",
      "# Comparer avec le XGBoost\n",
      "xgb_row = comparison_sup_df[comparison_sup_df['Modèle'] == 'XGBoost optimisé']\n",
      "if not xgb_row.empty:\n",
      "    xgb_accuracy = xgb_row.iloc[0]['Accuracy']\n",
      "    \n",
      "    # Comparer chaque modèle avec XGBoost\n",
      "    for i, row in comparison_sup_df.iterrows():\n",
      "        if row['Modèle'] != 'XGBoost optimisé':\n",
      "            diff = row['Accuracy'] - xgb_accuracy\n",
      "            print(f\"{row['Modèle']} vs XGBoost: {diff:.4f} ({diff*100:.2f}%)\")\n",
      "\n",
      "print(\"\\nConclusions sur les modèles supervisés avancés:\")\n",
      "print(\"1. Performance: Les approches ensemblistes \" + \n",
      "      (\"améliorent\" if max(stacking_accuracy, voting_accuracy) > xgb_accuracy else \"n'améliorent pas\") + \n",
      "      \" les performances par rapport à XGBoost seul\")\n",
      "print(\"2. Efficacité computationnelle: SVM est significativement plus lent que les autres approches, \" +\n",
      "      f\"avec un temps d'entraînement {svm_train_time/xgb_train_time:.1f}x plus long que XGBoost\")\n",
      "\n",
      "print(\"3. Compromis performances/coût: \" + \n",
      "      (\"Les modèles ensemblistes offrent le meilleur compromis\" \n",
      "       if (stacking_accuracy > xgb_accuracy and stacking_train_time < svm_train_time) or\n",
      "          (voting_accuracy > xgb_accuracy and voting_train_time < svm_train_time) \n",
      "       else \"XGBoost reste le meilleur compromis\") + \n",
      "      \" entre performances et coût computationnel\")\n",
      "\n",
      "print(\"4. Variabilité des prédictions: L'utilisation de plusieurs modèles dans les approches \" +\n",
      "      \"ensemblistes permet de réduire la variance des prédictions, \" +\n",
      "      \"ce qui peut être bénéfique pour la robustesse en production\")\n",
      "\n",
      "# Analyser les performances par classe\n",
      "print(\"\\nAnalyse des performances par classe:\")\n",
      "for model_name, report_var in [(\"XGBoost\", xgb_report), (\"SVM\", svm_report), \n",
      "                               (\"Stacking\", stacking_report), (\"Voting\", voting_report)]:\n",
      "    print(f\"\\n{model_name}:\")\n",
      "    for cls in [\"-1\", \"0\", \"1\"]:\n",
      "        if cls in report_var:\n",
      "            cls_metrics = report_var[cls]\n",
      "            print(f\"  Classe {cls}: Precision={cls_metrics['precision']:.4f}, \" +\n",
      "                  f\"Recall={cls_metrics['recall']:.4f}, F1={cls_metrics['f1-score']:.4f}\")\n",
      "\n",
      "# Recommandations finales\n",
      "print(\"\\nRecommandations pour le déploiement:\")\n",
      "best_approach = best_model['Modèle']\n",
      "print(f\"1. Modèle recommandé: {best_approach} offre les meilleures performances prédictives\")\n",
      "\n",
      "# Déterminer la meilleure approche considérant le rapport performance/coût\n",
      "perf_cost_scores = []\n",
      "for i, row in comparison_sup_df.iterrows():\n",
      "    # Score simple basé sur l'accuracy divisée par le log du temps (pour réduire l'impact des différences extrêmes)\n",
      "    perf_cost_score = row['Accuracy'] / np.log1p(row['Temps total'])\n",
      "    perf_cost_scores.append((row['Modèle'], perf_cost_score))\n",
      "\n",
      "best_perf_cost = max(perf_cost_scores, key=lambda x: x[1])\n",
      "print(f\"2. Meilleur compromis performance/coût: {best_perf_cost[0]}\")\n",
      "\n",
      "print(\"3. Production: Privilégier les approches ensemblistes pour leur robustesse face \" +\n",
      "      \"aux variations des données en environnement réel\")\n",
      "\n",
      "print(\"4. Maintenance: XGBoost reste le modèle le plus simple à maintenir et mettre à jour \" +\n",
      "      \"si le coût computationnel est une contrainte\")\n",
      "\n",
      "# --- Markdown Cell ---\n",
      "## 8. Deep Learning\n",
      "# \n",
      "# Explorons maintenant des approches de Deep Learning pour la classification.\n",
      "# --- Code Cell ---\n",
      "## 8. Deep Learning\n",
      "\n",
      "# 8.1 Importation des librairies et préparation des données\n",
      "print(\"\\n--- Préparation des données pour le Deep Learning ---\")\n",
      "\n",
      "# Importer Keras\n",
      "import keras\n",
      "from keras.models import Sequential, Model\n",
      "from keras.layers import Dense, Dropout, BatchNormalization, Input\n",
      "from keras.optimizers import Adam\n",
      "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
      "from keras.utils import to_categorical\n",
      "\n",
      "# --- Code Cell ---\n",
      "\n",
      "# Réutiliser les données déjà chargées dans les parties précédentes\n",
      "print(f\"Données d'entraînement: {X_optimized.shape}\")\n",
      "print(f\"Données de test: {X_test_optimized.shape}\")\n",
      "\n",
      "# Normaliser les données\n",
      "scaler = StandardScaler()\n",
      "X_train_dl = scaler.fit_transform(X_optimized)\n",
      "X_test_dl = scaler.transform(X_test_optimized)\n",
      "\n",
      "# Conversion des labels pour le format one-hot encoding\n",
      "mapping_dl = {-1: 0, 0: 1, 1: 2}\n",
      "y_train_mapped = np.array([mapping_dl.get(label, label) for label in y_raw_train])\n",
      "y_test_mapped = np.array([mapping_dl.get(label, label) for label in y_raw_test])\n",
      "\n",
      "# Convertir en one-hot encoding\n",
      "y_train_cat = to_categorical(y_train_mapped)\n",
      "y_test_cat = to_categorical(y_test_mapped)\n",
      "\n",
      "print(f\"Dimensions des données d'entraînement: {X_train_dl.shape}\")\n",
      "print(f\"Dimensions des labels d'entraînement (one-hot): {y_train_cat.shape}\")\n",
      "\n",
      "# --- Code Cell ---\n",
      "\n",
      "# 8.2 Définition du modèle MLP\n",
      "print(\"\\n--- Définition du modèle de réseau de neurones MLP ---\")\n",
      "\n",
      "# Pour reproductibilité\n",
      "np.random.seed(42)\n",
      "keras.utils.set_random_seed(42)\n",
      "\n",
      "# Définir le modèle MLP\n",
      "def create_mlp_model(input_dim, dropout_rate=0.3):\n",
      "    model = Sequential([\n",
      "        # Première couche cachée\n",
      "        Dense(128, input_dim=input_dim, activation='relu'),\n",
      "        BatchNormalization(),\n",
      "        Dropout(dropout_rate),\n",
      "        \n",
      "        # Deuxième couche cachée\n",
      "        Dense(64, activation='relu'),\n",
      "        BatchNormalization(),\n",
      "        Dropout(dropout_rate),\n",
      "        \n",
      "        # Troisième couche cachée\n",
      "        Dense(32, activation='relu'),\n",
      "        BatchNormalization(),\n",
      "        Dropout(dropout_rate),\n",
      "        \n",
      "        # Couche de sortie (3 classes)\n",
      "        Dense(3, activation='softmax')\n",
      "    ])\n",
      "    \n",
      "    # Compiler le modèle\n",
      "    model.compile(\n",
      "        optimizer=Adam(learning_rate=0.001),\n",
      "        loss='categorical_crossentropy',\n",
      "        metrics=['accuracy']\n",
      "    )\n",
      "    \n",
      "    return model\n",
      "\n",
      "# Créer le modèle\n",
      "mlp_model = create_mlp_model(input_dim=X_train_dl.shape[1])\n",
      "\n",
      "# Résumé du modèle\n",
      "mlp_model.summary()\n",
      "\n",
      "# --- Code Cell ---\n",
      "\n",
      "# 8.3 Entraînement du modèle\n",
      "print(\"\\n--- Entraînement du modèle MLP ---\")\n",
      "\n",
      "# Définir les callbacks\n",
      "early_stopping = EarlyStopping(\n",
      "    monitor='val_loss',\n",
      "    patience=10,\n",
      "    restore_best_weights=True,\n",
      "    verbose=1\n",
      ")\n",
      "\n",
      "reduce_lr = ReduceLROnPlateau(\n",
      "    monitor='val_loss',\n",
      "    factor=0.5,\n",
      "    patience=5,\n",
      "    min_lr=0.0001,\n",
      "    verbose=1\n",
      ")\n",
      "\n",
      "# Entraîner le modèle\n",
      "start_time = time.time()\n",
      "history = mlp_model.fit(\n",
      "    X_train_dl,\n",
      "    y_train_cat,\n",
      "    validation_split=0.2,\n",
      "    epochs=50,\n",
      "    batch_size=64,\n",
      "    callbacks=[early_stopping, reduce_lr],\n",
      "    verbose=1\n",
      ")\n",
      "mlp_train_time = time.time() - start_time\n",
      "\n",
      "# --- Code Cell ---\n",
      "\n",
      "# 8.4 Évaluation du modèle\n",
      "print(\"\\n--- Évaluation du modèle MLP ---\")\n",
      "\n",
      "# Évaluer le modèle sur les données de test\n",
      "start_time = time.time()\n",
      "mlp_loss, mlp_accuracy = mlp_model.evaluate(X_test_dl, y_test_cat, verbose=0)\n",
      "mlp_pred_time = time.time() - start_time\n",
      "\n",
      "print(f\"Accuracy du modèle MLP: {mlp_accuracy:.4f}\")\n",
      "print(f\"Temps d'entraînement: {mlp_train_time:.2f} secondes\")\n",
      "print(f\"Temps de prédiction: {mlp_pred_time:.2f} secondes\")\n",
      "\n",
      "# Obtenir les prédictions\n",
      "mlp_pred_proba = mlp_model.predict(X_test_dl)\n",
      "mlp_pred_classes = np.argmax(mlp_pred_proba, axis=1)\n",
      "\n",
      "# Reconvertir les classes prédites au format original (-1, 0, 1)\n",
      "inverse_mapping = {0: -1, 1: 0, 2: 1}\n",
      "mlp_predictions = np.array([inverse_mapping.get(label, label) for label in mlp_pred_classes])\n",
      "\n",
      "# Calculer les métriques\n",
      "mlp_eval_accuracy = accuracy_score(y_raw_test, mlp_predictions)\n",
      "mlp_report = classification_report(y_raw_test, mlp_predictions, output_dict=True)\n",
      "\n",
      "print(f\"\\nPerformances détaillées:\")\n",
      "print(f\"Accuracy: {mlp_eval_accuracy:.4f}\")\n",
      "print(f\"F1 score pondéré: {mlp_report['weighted avg']['f1-score']:.4f}\")\n",
      "\n",
      "# Afficher la matrice de confusion\n",
      "plt.figure(figsize=(8, 6))\n",
      "mlp_conf_matrix = confusion_matrix(y_raw_test, mlp_predictions)\n",
      "sns.heatmap(mlp_conf_matrix, annot=True, fmt='d', cmap='Blues', \n",
      "           xticklabels=[-1, 0, 1], yticklabels=[-1, 0, 1])\n",
      "plt.title('Matrice de Confusion - MLP')\n",
      "plt.xlabel('Prédiction')\n",
      "plt.ylabel('Valeur Réelle')\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "# Ajouter au tracker de résultats\n",
      "result_mlp = {\n",
      "    \"dataset\": raw_dataset_key,\n",
      "    \"dataset_description\": f\"Dataset optimisé sans day/equity\",\n",
      "    \"model\": \"mlp_deep_learning\",\n",
      "    \"model_description\": \"Réseau de neurones MLP\",\n",
      "    \"features_added\": True,\n",
      "    \"feature_sets\": [\"Optimisées sans day/equity\"],\n",
      "    \"normalize_by_row\": best_normalize,\n",
      "    \"accuracy\": mlp_eval_accuracy,\n",
      "    \"precision_weighted\": mlp_report[\"weighted avg\"][\"precision\"],\n",
      "    \"recall_weighted\": mlp_report[\"weighted avg\"][\"recall\"],\n",
      "    \"f1_weighted\": mlp_report[\"weighted avg\"][\"f1-score\"],\n",
      "    \"training_time\": mlp_train_time,\n",
      "    \"prediction_time\": mlp_pred_time,\n",
      "    \"total_time\": mlp_train_time + mlp_pred_time,\n",
      "    \"notes\": f\"MLP avec 3 couches cachées (128, 64, 32)\"\n",
      "}\n",
      "\n",
      "results_tracker = add_result(results_tracker, result_mlp)\n",
      "\n",
      "# --- Code Cell ---\n",
      "\n",
      "# 8.5 Visualisation des courbes d'apprentissage\n",
      "print(\"\\n--- Visualisation des courbes d'apprentissage ---\")\n",
      "\n",
      "# Visualiser l'évolution de l'accuracy et de la loss\n",
      "plt.figure(figsize=(12, 5))\n",
      "\n",
      "plt.subplot(1, 2, 1)\n",
      "plt.plot(history.history['accuracy'], label='Train')\n",
      "plt.plot(history.history['val_accuracy'], label='Validation')\n",
      "plt.title('Évolution de l\\'accuracy')\n",
      "plt.xlabel('Époque')\n",
      "plt.ylabel('Accuracy')\n",
      "plt.legend()\n",
      "plt.grid(True)\n",
      "\n",
      "plt.subplot(1, 2, 2)\n",
      "plt.plot(history.history['loss'], label='Train')\n",
      "plt.plot(history.history['val_loss'], label='Validation')\n",
      "plt.title('Évolution de la loss')\n",
      "plt.xlabel('Époque')\n",
      "plt.ylabel('Loss')\n",
      "plt.legend()\n",
      "plt.grid(True)\n",
      "\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "# --- Code Cell ---\n",
      "\n",
      "# 8.6 Modèle Deep Learning avec autoencoder\n",
      "print(\"\\n--- Modèle Deep Learning avec autoencoder ---\")\n",
      "\n",
      "# Définir le modèle autoencoder\n",
      "def create_autoencoder(input_dim, encoding_dim=15):\n",
      "    # Encoder\n",
      "    input_layer = Input(shape=(input_dim,))\n",
      "    encoded = Dense(64, activation='relu')(input_layer)\n",
      "    encoded = Dense(32, activation='relu')(encoded)\n",
      "    encoded = Dense(encoding_dim, activation='relu')(encoded)\n",
      "    \n",
      "    # Decoder\n",
      "    decoded = Dense(32, activation='relu')(encoded)\n",
      "    decoded = Dense(64, activation='relu')(decoded)\n",
      "    decoded = Dense(input_dim, activation='linear')(decoded)\n",
      "    \n",
      "    # Autoencoder complet\n",
      "    autoencoder = Model(inputs=input_layer, outputs=decoded)\n",
      "    autoencoder.compile(optimizer='adam', loss='mse')\n",
      "    \n",
      "    # Encoder seul (pour extraire les features)\n",
      "    encoder = Model(inputs=input_layer, outputs=encoded)\n",
      "    \n",
      "    return autoencoder, encoder\n",
      "\n",
      "# Créer l'autoencoder\n",
      "autoencoder, encoder = create_autoencoder(input_dim=X_train_dl.shape[1])\n",
      "\n",
      "# Entraîner l'autoencoder\n",
      "start_time = time.time()\n",
      "autoencoder.fit(\n",
      "    X_train_dl, \n",
      "    X_train_dl,\n",
      "    epochs=30,\n",
      "    batch_size=64,\n",
      "    validation_split=0.2,\n",
      "    callbacks=[early_stopping],\n",
      "    verbose=1\n",
      ")\n",
      "autoencoder_train_time = time.time() - start_time\n",
      "\n",
      "# Extraire les features encodées\n",
      "X_train_encoded = encoder.predict(X_train_dl)\n",
      "X_test_encoded = encoder.predict(X_test_dl)\n",
      "\n",
      "print(f\"Dimensions des features encodées: {X_train_encoded.shape}\")\n",
      "\n",
      "# --- Code Cell ---\n",
      "\n",
      "# 8.7 Classification avec les features encodées\n",
      "print(\"\\n--- Classification avec les features encodées de l'autoencoder ---\")\n",
      "\n",
      "# Créer un modèle de classification\n",
      "ae_classifier = Sequential([\n",
      "    Dense(32, input_dim=X_train_encoded.shape[1], activation='relu'),\n",
      "    BatchNormalization(),\n",
      "    Dropout(0.3),\n",
      "    Dense(16, activation='relu'),\n",
      "    BatchNormalization(),\n",
      "    Dropout(0.3),\n",
      "    Dense(3, activation='softmax')\n",
      "])\n",
      "\n",
      "# Compiler le modèle\n",
      "ae_classifier.compile(\n",
      "    optimizer=Adam(learning_rate=0.001),\n",
      "    loss='categorical_crossentropy',\n",
      "    metrics=['accuracy']\n",
      ")\n",
      "\n",
      "# Entraîner le modèle\n",
      "start_time = time.time()\n",
      "ae_history = ae_classifier.fit(\n",
      "    X_train_encoded,\n",
      "    y_train_cat,\n",
      "    validation_split=0.2,\n",
      "    epochs=50,\n",
      "    batch_size=64,\n",
      "    callbacks=[early_stopping, reduce_lr],\n",
      "    verbose=1\n",
      ")\n",
      "ae_train_time = time.time() - start_time + autoencoder_train_time  # Inclure le temps d'entraînement de l'autoencoder\n",
      "\n",
      "# Évaluer le modèle\n",
      "start_time = time.time()\n",
      "ae_loss, ae_accuracy = ae_classifier.evaluate(X_test_encoded, y_test_cat, verbose=0)\n",
      "ae_pred_time = time.time() - start_time\n",
      "\n",
      "print(f\"Accuracy du modèle avec autoencoder: {ae_accuracy:.4f}\")\n",
      "print(f\"Temps d'entraînement total (autoencoder + classifier): {ae_train_time:.2f} secondes\")\n",
      "print(f\"Temps de prédiction: {ae_pred_time:.2f} secondes\")\n",
      "\n",
      "# Obtenir les prédictions\n",
      "ae_pred_proba = ae_classifier.predict(X_test_encoded)\n",
      "ae_pred_classes = np.argmax(ae_pred_proba, axis=1)\n",
      "\n",
      "# Reconvertir les classes prédites au format original (-1, 0, 1)\n",
      "ae_predictions = np.array([inverse_mapping.get(label, label) for label in ae_pred_classes])\n",
      "\n",
      "# Calculer les métriques\n",
      "ae_eval_accuracy = accuracy_score(y_raw_test, ae_predictions)\n",
      "ae_report = classification_report(y_raw_test, ae_predictions, output_dict=True)\n",
      "\n",
      "print(f\"\\nPerformances détaillées:\")\n",
      "print(f\"Accuracy: {ae_eval_accuracy:.4f}\")\n",
      "print(f\"F1 score pondéré: {ae_report['weighted avg']['f1-score']:.4f}\")\n",
      "\n",
      "# Ajouter au tracker de résultats\n",
      "result_ae = {\n",
      "    \"dataset\": raw_dataset_key,\n",
      "    \"dataset_description\": f\"Dataset optimisé sans day/equity\",\n",
      "    \"model\": \"autoencoder_deep_learning\",\n",
      "    \"model_description\": \"Autoencoder + MLP\",\n",
      "    \"features_added\": True,\n",
      "    \"feature_sets\": [\"Optimisées + Autoencoder\"],\n",
      "    \"normalize_by_row\": best_normalize,\n",
      "    \"accuracy\": ae_eval_accuracy,\n",
      "    \"precision_weighted\": ae_report[\"weighted avg\"][\"precision\"],\n",
      "    \"recall_weighted\": ae_report[\"weighted avg\"][\"recall\"],\n",
      "    \"f1_weighted\": ae_report[\"weighted avg\"][\"f1-score\"],\n",
      "    \"training_time\": ae_train_time,\n",
      "    \"prediction_time\": ae_pred_time,\n",
      "    \"total_time\": ae_train_time + ae_pred_time,\n",
      "    \"notes\": f\"Autoencoder (encoding_dim={X_train_encoded.shape[1]}) + classifier\"\n",
      "}\n",
      "\n",
      "results_tracker = add_result(results_tracker, result_ae)\n",
      "\n",
      "# --- Code Cell ---\n",
      "\n",
      "# 8.8 Comparaison des modèles Deep Learning avec les autres modèles\n",
      "print(\"\\n--- Comparaison des modèles Deep Learning avec les autres approches ---\")\n",
      "\n",
      "# Créer un DataFrame pour la comparaison\n",
      "dl_comparison_df = pd.DataFrame([\n",
      "    {\"Modèle\": \"XGBoost optimisé\", \"Accuracy\": xgb_accuracy, \"F1 score\": xgb_report['weighted avg']['f1-score'],\n",
      "     \"Catégorie\": \"Supervisé\"},\n",
      "    {\"Modèle\": \"SVM\", \"Accuracy\": svm_accuracy, \"F1 score\": svm_report['weighted avg']['f1-score'],\n",
      "     \"Catégorie\": \"Supervisé\"},\n",
      "    {\"Modèle\": \"Stacking\", \"Accuracy\": stacking_accuracy, \"F1 score\": stacking_report['weighted avg']['f1-score'],\n",
      "     \"Catégorie\": \"Supervisé\"},\n",
      "    {\"Modèle\": \"K-means + XGBoost\", \"Accuracy\": accuracy_pca, \"F1 score\": report_pca['weighted avg']['f1-score'],\n",
      "     \"Catégorie\": \"Non supervisé\"},\n",
      "    {\"Modèle\": \"MLP\", \"Accuracy\": mlp_eval_accuracy, \"F1 score\": mlp_report['weighted avg']['f1-score'],\n",
      "     \"Catégorie\": \"Deep Learning\"},\n",
      "    {\"Modèle\": \"Autoencoder + MLP\", \"Accuracy\": ae_eval_accuracy, \"F1 score\": ae_report['weighted avg']['f1-score'],\n",
      "     \"Catégorie\": \"Deep Learning\"}\n",
      "])\n",
      "\n",
      "# Trier par accuracy décroissante\n",
      "dl_comparison_df = dl_comparison_df.sort_values(\"Accuracy\", ascending=False)\n",
      "\n",
      "# Afficher le tableau de comparaison\n",
      "print(\"Comparaison des performances:\")\n",
      "display(dl_comparison_df)\n",
      "\n",
      "# Visualiser la comparaison\n",
      "plt.figure(figsize=(14, 8))\n",
      "sns.barplot(x=\"Modèle\", y=\"Accuracy\", hue=\"Catégorie\", data=dl_comparison_df)\n",
      "plt.title('Comparaison des performances des différentes approches')\n",
      "plt.xticks(rotation=45, ha=\"right\")\n",
      "plt.ylim(0.3, 0.35)  # Ajuster selon les valeurs réelles\n",
      "plt.grid(axis='y')\n",
      "plt.tight_layout()\n",
      "plt.show()\n",
      "\n",
      "# 8.9 Bilan des modèles Deep Learning\n",
      "print(\"\\n--- Bilan des modèles Deep Learning ---\")\n",
      "\n",
      "# Comparer spécifiquement les deux approches Deep Learning\n",
      "dl_specific_comparison = dl_comparison_df[dl_comparison_df[\"Catégorie\"] == \"Deep Learning\"]\n",
      "display(dl_specific_comparison)\n",
      "\n",
      "print(\"\\nAvantages et inconvénients des modèles Deep Learning:\")\n",
      "print(\"Avantages:\")\n",
      "print(\"- Capacité à capturer des relations complexes et non linéaires\")\n",
      "print(\"- Performances compétitives avec les autres approches\")\n",
      "print(\"- Flexibilité dans l'architecture et la représentation des données\")\n",
      "\n",
      "print(\"\\nInconvénients:\")\n",
      "print(\"- Temps d'entraînement plus long\")\n",
      "print(\"- Nécessite plus de paramétrage et d'optimisation\")\n",
      "print(\"- Risque de surapprentissage plus élevé\")\n",
      "\n",
      "# Meilleur modèle global\n",
      "best_model_overall = dl_comparison_df.iloc[0]\n",
      "print(f\"\\nMeilleur modèle global: {best_model_overall['Modèle']}\")\n",
      "print(f\"Accuracy: {best_model_overall['Accuracy']:.4f}\")\n",
      "print(f\"F1 score: {best_model_overall['F1 score']:.4f}\")\n",
      "print(f\"Catégorie: {best_model_overall['Catégorie']}\")## 8. Deep Learning\n",
      "\n",
      "# --- Markdown Cell ---\n",
      "## 9. Résumé et conclusion\n",
      "# \n",
      "# Dans cette étude, nous avons exploré différentes approches pour prédire la direction des prix des actions sur le marché américain pendant les deux dernières heures de trading.\n",
      "# --- Code Cell ---\n",
      "# 9.1 Compilation des résultats finaux\n",
      "# --- Code Cell ---\n",
      "\n",
      "# --- Code Cell ---\n",
      "# PUTE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def extract_cells_from_notebook(notebook_path, include_code=True, include_markdown=True, output_path=None):\n",
    "    \"\"\"\n",
    "    Extracts code and/or markdown cells from a Jupyter notebook and returns them as a single text block.\n",
    "    \n",
    "    Parameters:\n",
    "        notebook_path (str): Path to the input .ipynb file\n",
    "        include_code (bool): Whether to include code cells\n",
    "        include_markdown (bool): Whether to include markdown cells\n",
    "        output_path (str or None): Path to save output (e.g., .py or .txt), or None to just return string\n",
    "\n",
    "    Returns:\n",
    "        str: Combined source content of selected cell types\n",
    "    \"\"\"\n",
    "    with open(notebook_path, 'r', encoding='utf-8') as f:\n",
    "        notebook = json.load(f)\n",
    "\n",
    "    extracted_lines = []\n",
    "\n",
    "    for cell in notebook.get('cells', []):\n",
    "        cell_type = cell.get('cell_type')\n",
    "        if cell_type == 'code' and include_code:\n",
    "            extracted_lines.append(\"# --- Code Cell ---\\n\")\n",
    "            extracted_lines.extend(cell.get('source', []))\n",
    "            extracted_lines.append('\\n')\n",
    "        elif cell_type == 'markdown' and include_markdown:\n",
    "            extracted_lines.append(\"# --- Markdown Cell ---\\n\")\n",
    "            # Convert Markdown to commented lines (optional)\n",
    "            md_lines = cell.get('source', [])\n",
    "            commented_md = ['# ' + line if not line.startswith('#') else line for line in md_lines]\n",
    "            extracted_lines.extend(commented_md)\n",
    "            extracted_lines.append('\\n')\n",
    "\n",
    "    output = ''.join(extracted_lines)\n",
    "\n",
    "    if output_path:\n",
    "        with open(output_path, 'w', encoding='utf-8') as f:\n",
    "            f.write(output)\n",
    "\n",
    "    return output\n",
    "\n",
    "# Example usage\n",
    "code_and_md = extract_cells_from_notebook(\n",
    "    notebook_path=\"redaction_v2.ipynb\",\n",
    "    include_code=True,\n",
    "    include_markdown=True,\n",
    "    output_path=\"redaction_v2.txt\"\n",
    ")\n",
    "\n",
    "print(code_and_md)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8031884c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nbformat\n",
    "from nbformat.v4 import new_notebook, new_code_cell, new_markdown_cell\n",
    "\n",
    "def py_to_notebook(py_path, ipynb_path):\n",
    "    with open(py_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    notebook_cells = []\n",
    "    current_lines = []\n",
    "    current_type = \"code\"  # default cell type\n",
    "\n",
    "    def add_cell(cell_lines, cell_type):\n",
    "        content = ''.join(cell_lines).strip('\\n')\n",
    "        if content:\n",
    "            if cell_type == 'code':\n",
    "                notebook_cells.append(new_code_cell(source=content))\n",
    "            elif cell_type == 'markdown':\n",
    "                notebook_cells.append(new_markdown_cell(source=content))\n",
    "\n",
    "    for line in lines:\n",
    "        if line.strip().startswith(\"# --- Code Cell\"):\n",
    "            add_cell(current_lines, current_type)\n",
    "            current_lines = []\n",
    "            current_type = 'code'\n",
    "        elif line.strip().startswith(\"# --- Markdown Cell\"):\n",
    "            add_cell(current_lines, current_type)\n",
    "            current_lines = []\n",
    "            current_type = 'markdown'\n",
    "        else:\n",
    "            current_lines.append(line)\n",
    "\n",
    "    # Add the last cell\n",
    "    add_cell(current_lines, current_type)\n",
    "\n",
    "    # Create notebook object\n",
    "    nb = new_notebook(cells=notebook_cells, metadata={\"kernelspec\": {\n",
    "        \"name\": \"python3\",\n",
    "        \"language\": \"python\",\n",
    "        \"display_name\": \"Python 3\"\n",
    "    }})\n",
    "\n",
    "    # Write to .ipynb\n",
    "    with open(ipynb_path, 'w', encoding='utf-8') as f:\n",
    "        nbformat.write(nb, f)\n",
    "\n",
    "    print(f\"Notebook created: {ipynb_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "289e6017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notebook created: redaction_claude.ipynb\n"
     ]
    }
   ],
   "source": [
    "py_to_notebook(\"redaction_claude.py.\", \"redaction_claude.ipynb\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
