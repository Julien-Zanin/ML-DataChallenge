{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Génération de data set afin d'essayer différentes méthodes d'imputation et leur impact. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\julie\\Documents\\Python\\Machine Learning - Projet FInal\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "\n",
    "from utils.data_standardize import standardize, inverse_standardize\n",
    "from utils.fill_data import mixed_directional_fill, linear_interpolation\n",
    "from utils.knn_impute import impute_group \n",
    "import os\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(r'input_training.csv')\n",
    "X.sort_values(by=\"ID\",inplace=True)\n",
    "\n",
    "y = pd.read_csv(r'output\\output_training_gmEd6Zt.csv')\n",
    "\n",
    "data_test = pd.read_csv(r'input_test.csv')\n",
    "data_test.sort_values(by=\"ID\",inplace=True)\n",
    "\n",
    "y_test = pd.read_csv(r\"output\\output_test_random.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de lignes après suppression des lignes avec moins de 39 valeurs non NaN : 730784\n",
      "Nombre de lignes après suppression des lignes avec moins de 39 valeurs non NaN : 857641\n"
     ]
    }
   ],
   "source": [
    "# On les merge pour pouvoir les manipuler ensemble et les séparer après les traitements (30% de NaN) \n",
    "X_train = pd.merge(X,y,on=\"ID\").copy()\n",
    "data_test.sort_values(by=\"ID\",inplace=True)\n",
    "X_test = pd.merge(data_test,y_test,on=\"ID\").copy()\n",
    "\n",
    "threshold = int(0.7 * X_train.shape[1]) # 70% des valeurs non NaN pour garder la ligne\n",
    "\n",
    "X_train_70 = X_train.dropna(thresh=threshold).copy(deep=True)\n",
    "y_70 = X_train_70[\"reod\"].copy(deep=True)\n",
    "print(f\"Nombre de lignes après suppression des lignes avec moins de {threshold} valeurs non NaN : {len(X_train_70)}\")\n",
    "\n",
    "X_test_70 = X_test.dropna(thresh=threshold).copy(deep=True)\n",
    "y_test_70 = X_test_70[\"reod\"].copy(deep=True)\n",
    "print(f\"Nombre de lignes après suppression des lignes avec moins de {threshold} valeurs non NaN : {len(X_test_70)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_cols = [\"ID\",\"day\",\"equity\",\"reod\"]\n",
    "features_cols = [f'r{i}' for i in range(53)]\n",
    "\n",
    "X_train_70_features = X_train_70[features_cols].copy(deep=True)\n",
    "X_test_70_features = X_test_70[features_cols].copy(deep=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN IMPUTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation globale des valeurs manquantes sur le train set \n",
    "X_train_70_features_std , global_stats = standardize(X_train_70_features)\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_train_70_features_std = imputer.fit_transform(X_train_70_features_std)\n",
    "X_train_70_features_std = pd.DataFrame(X_train_70_features_std, columns=features_cols)\n",
    "\n",
    "X_train_70_features = inverse_standardize(X_train_70_features_std, global_stats)\n",
    "\n",
    "X_global_inmputed = pd.concat([X_train_70[id_cols],X_train_70_features],axis=1)\n",
    "X_global_inmputed.to_csv(\"training_global_knn_imputed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imputation globale des valeurs manquantes sur le test set \n",
    "X_test_70_features_std , global_stats = standardize(X_test_70_features)\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "X_test_70_features_std = imputer.fit_transform(X_test_70_features_std)\n",
    "X_test_70_features_std = pd.DataFrame(X_test_70_features_std, columns=features_cols)\n",
    "\n",
    "X_test_70_features = inverse_standardize(X_test_70_features_std, global_stats)\n",
    "\n",
    "X_global_inmputed_test = pd.concat([X_test_70[id_cols],X_train_70_features],axis=1)\n",
    "X_global_inmputed_test.to_csv(\"test_global_knn_imputed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KNN Imputation par groupe (ne sera pas fait)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "impute_group() got an unexpected keyword argument 'features_cols'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_group_imputed \u001b[38;5;241m=\u001b[39m X_train_70_features\u001b[38;5;241m.\u001b[39mgroupby(X_train_70[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mequity\u001b[39m\u001b[38;5;124m\"\u001b[39m], group_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\u001b[38;5;241m.\u001b[39mapply(\u001b[43mimpute_group\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures_cols\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfeatures_cols\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m      2\u001b[0m df_group_imputed\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_group_knn_imputed.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m,index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: impute_group() got an unexpected keyword argument 'features_cols'"
     ]
    }
   ],
   "source": [
    "df_group_imputed = X_train_70_features.groupby(X_train_70[\"equity\"], group_keys=False).apply(impute_group(features_cols=features_cols))\n",
    "df_group_imputed.to_csv(\"training_group_knn_imputed.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixed fill (Backward / Forward fill - Forward / Backward fill)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 1. FORWARD-BACKWARD FILL ====================\n",
    "# Using axis=1 to fill across time periods within each row\n",
    "X_train_ffbf = mixed_directional_fill(X_train_70, features_cols, 'ffill_then_bfill', axis=1)\n",
    "X_test_ffbf = mixed_directional_fill(X_test_70, features_cols, 'ffill_then_bfill', axis=1)\n",
    "\n",
    "# Export to CSV\n",
    "X_train_ffbf.to_csv('processed_data/X_train_ffbf.csv', index=False)\n",
    "X_test_ffbf.to_csv('processed_data/X_test_ffbf.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==================== 2. BACKWARD-FORWARD FILL ====================\n",
    "X_train_bfff = mixed_directional_fill(X_train_70, features_cols, 'bfill_then_ffill', axis=1)\n",
    "X_test_bfff = mixed_directional_fill(X_test_70, features_cols, 'bfill_then_ffill', axis=1)\n",
    "\n",
    "# Export to CSV\n",
    "X_train_bfff.to_csv('processed_data/X_train_bfff.csv', index=False)\n",
    "X_test_bfff.to_csv('processed_data/X_test_bfff.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpolation linéaire par ligne "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying linear interpolation...\n"
     ]
    }
   ],
   "source": [
    "# ==================== 3. LINEAR INTERPOLATION ====================\n",
    "print(\"Applying linear interpolation...\")\n",
    "\n",
    "X_train_interp = linear_interpolation(X_train_70, features_cols, axis=1)\n",
    "X_test_interp = linear_interpolation(X_test_70, features_cols, axis=1)\n",
    "\n",
    "# Export to CSV\n",
    "X_train_interp.to_csv('processed_data/X_train_interp.csv', index=False)\n",
    "X_test_interp.to_csv('processed_data/X_test_interp.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Process training data\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "\n",
    "mice_train_imputer = IterativeImputer(\n",
    "    max_iter=10,\n",
    "    random_state=42,\n",
    "    initial_strategy='mean'\n",
    ")\n",
    "\n",
    "X_train_mice = X_train_70.copy()\n",
    "X_train_mice_features = mice_train_imputer.fit_transform(X_train_70_features)\n",
    "X_train_mice[features_cols] = X_train_mice_features\n",
    "\n",
    "# Process test data separately\n",
    "mice_test_imputer = IterativeImputer(\n",
    "    max_iter=10,\n",
    "    random_state=42,\n",
    "    initial_strategy='mean'\n",
    ")\n",
    "\n",
    "X_test_mice = X_test_70.copy()\n",
    "X_test_mice_features = mice_test_imputer.fit_transform(X_test_70_features)\n",
    "X_test_mice[features_cols] = X_test_mice_features\n",
    "\n",
    "# Export to CSV\n",
    "X_train_mice.to_csv('processed_data/X_train_mice.csv', index=False)\n",
    "X_test_mice.to_csv('processed_data/X_test_mice.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
